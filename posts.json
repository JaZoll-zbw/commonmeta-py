{"items":[{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/continuous-publishing","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"Earlier this week Bj\u00f6rn Brembs wrote in a blog post ([What Is The Difference Between Text, Data And Code?](http://bjoern.brembs.net/2014/03/what-is-the-difference-between-text-data-and-code/)):\n\n> To sum it up: our intellectual output today manifests itself in code, data and text.\n\nThe post is about the importance of publication of data and software where currently *the rewards are stacked disproportionately in favor of text publications*. The intended audience is probably mainly other scientists (Bj\u00f6rn is a neurobiologist) who are reluctant to publish data and/or code, but there is another interesting aspect to this.\n\nJust as scientific publication increasingly means more than just text and includes data and software, we are also increasingly seeing tools and methodologies common in software development applied to scientific publishing. This in particular includes the ideas behind Open Source software (which shares many commonalities with Open Access and Open Science), but also tools like the git version control system ([We Need a Github of Science](http://marciovm.com/i-want-a-github-of-science/)) or the markdown markdown language ([A Call for Scholarly Markdown](https://blog.front-mattetr.io/posts/a-call-for-scholarly-markdown/)).\n\nContinuous Delivery is another concept increasingly popular in software development that has many implications on how research can be performed and reported. Martin Fowler describes it as:\n\n> Continuous Delivery is a software development discipline where you build software in such a way that the software can be released to production at any time.\n\nThe concept of frequent small releases is of course familiar to everyone practicing [Open Notebook Science](http://usefulchem.wikispaces.com/), writing science blogs, presenting preliminary data at conferences or publishing [preprints](http://arxiv.org/), and is even relevant to [CrossMark](http://www.crossref.org/crossmark/), a service that tracks corrections, enhancements and other changes of scholarly documents.\n\nWhen you read the definition given by Martin Fowler carefully, you see that Continuous Delivery is about more than the frequency of software updates -- it is in fact about improving the process of releasing software. The scientific publication is the corresponding event in science, and I think that nobody would argue with me that the experience publishing a paper is too complex, time-consuming and often frustrating. The focus here is not on the time it takes to do peer review, or the multiple revisions needed before a manuscript is accepted. I am talking about the pain submitting a manuscript, the back and forth regarding file formats, citation styles and other technical requirements, the reformatting of manuscripts, and also the time it takes from accepting a manuscript to finally publishing it online.\n\nI would argue that the main reason publishing is so painful for everyone involved is that it is still very much a manual process. Just as software development is creative work, but still can benefit tremendously from tools such as automated tests and build tools, we can apply the same principles to scientific publishing. This means that everything that can be automated should be automated so that we can focus on those areas that need human judgement. The mistake that I think is commonly made is that automation for many publishers means automation for the publisher, with even more work for the author who submits a manuscript. A good example is that authors are increasingly asked to submit publication-ready manuscripts even though typesetting and desktop publishing is not their area of expertise and the manuscript text will be very different after one or more rounds of revision. The pain of processing manuscripts into something that can be published was summarized perfectly by typesetter and friend Kaveh Bazargan at the [SpotOn London 2012 Conference](http://www.youtube.com/watch?feature=player_embedded&v=CGkcsvofjdg) (via [Ross Mounce's blog](http://rossmounce.co.uk/2012/11/19/yet-another-solo12-recap-part2/)):\n\n> It's madness really. I'm here to say I shouldn't be in business.\n\nThe promise of Continuous Delivery for publishing is to develop tools and best practices that make the process of publication faster, with better quality, and less frustrating. Continuous Integration ([again Martin Fowler](http://martinfowler.com/articles/continuousIntegration.html)) is an important part of Continuous Delivery and means frequently merging all developer working copies of a software project into a central repository, combined with running automated unit tests and software builds using an integration server.\n\nWe can apply Continuous Integration to scholarly documents - instead of automated tests and software builds we can automate the transformation of documents into [JATS XML](https://blog.front-matter.io/posts/from-markdown-to-jats-xml-in-one-step/) and other output formats, and we can automate the process of checking for required metadata, correct file formats for images, etc. And we can use the same software tools for this, many of which are freely available to Open Source projects.\n\nAs an example of how this can be done [I have integrated](https://github.com/mfenner/jekyll-travis) the [Travis CI](https://travis-ci.org/) Continuous Integration server with the book project [Opening Science](http://book.openingscience.org/). The recently published book is a dynamic book that hopefully is updated frequently in the coming months. Every time an editor approves a correction to the text - [hosted in markdown format on Github](https://github.com/openingscience/book) - the Travis CI server is automatically triggered to build a new HTML version of the book and to push the new version to the book website. The Travis server is running the [Pandoc](http://johnmacfarlane.net/pandoc/) document converter to not only convert the changed document from markdown to HTML, but Pandoc will also insert and format references, and the [Jekyll](http://jekyllrb.com/) site generator will build a nice website around the markdown files. Over time this build process can be extended to do other things as well, from [auto-generating links to data and resources](https://blog.front-matter.io/posts/auto-generating-links-to-data-and-resources/) to transforming the document into [other file formats](https://blog.front-matter.io/posts/from-markdown-to-jats-xml-in-one-step/) besides HTML.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw0g","guid":"62d42bbd41e317003df48d6b","id":"5e8c5f4d-b651-4173-a52a-241d262d738f","image":"https://blog.front-matter.io/content/images/2022/08/Agile-vs-iterative-flow.jpg","indexed_at":1,"language":"en","published_at":1394466240,"reference":[],"relationships":[],"summary":"Earlier this week Bj\u00f6rn Brembs wrote in a blog post (What Is The Difference Between Text, Data And Code?):To sum it up: our intellectual output today manifests itself in code, data and text.\n","tags":["Feature"],"title":"Continuous Publishing","updated_at":1660839824,"url":"https://blog.front-matter.io/posts/continuous-publishing"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/dont-reinvent-the-wheel","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"In a [post last week](https://blog.front-matter.io/posts/build-roads-not-stagecoaches/) I talked about roads and stagecoaches, and how work on scholarly infrastructure can often be more important than building customer-facing apps. One important aspect of that infrastructure work is to not duplicate efforts.\n\n<figure class=\"kg-card kg-image-card kg-card-hascaption\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/5673321593_e6a7faa36d_z.jpg\" class=\"kg-image\" loading=\"lazy\" width=\"478\" height=\"640\" />\n<figcaption>Image by Cocoabiscuit <a href=\"https://www.flickr.com/photos/jfgallery/5673321593/\">on Flickr</a></figcaption>\n</figure>\n\nA good example is information (or metadata) about scholarly publications. I am the technical lead for the open source [article-level metrics (ALM) software](http://articlemetrics.github.io/). This software can be used in different ways, but most people use it for tracking the metrics of scholarly articles, with articles that have DOIs issued by CrossRef. The ALM software needs three pieces of information for every article: ****DOI****, ****publication date****, and ****title****. This information can be entered via a web interface, but that is of course not very practical for adding dozens or hundreds of articles at a time. The ALM software has therefore long supported the import of multiple articles via a text file and the command line.\n\nThis approach is working fine for the ALM software [running at PLOS since 2009](http://articlemetrics.github.io/plos/), but is for example a problem if the ALM software runs as a service for multiple publishers. A more flexible approach is to provide an API to upload articles, and I've [added an API](http://articlemetrics.github.io/docs/api/) for creating, updating and deleting articles in January 2014.\n\nWhile the API is an improvement, it still requires the integration into a number of possibly very different publisher workflows, and you have to deal with setting up the permissions, e.g. so that publisher A can't delete an article from publisher B.\n\nThe next ALM release (3.3) will therefore add a third approach to importing articles: using the [CrossRef API](http://api.crossref.org/) to look up article information. Article-level metrics is about tracking already published works, so we really only care about articles that have DOIs registered with CrossRef and are therefore published. ALM is now talking to a single API, and this makes it much easier to do this for a number of publishers without writing custom code. Since ALM is an open source application already used by several publishers that aspect is important. And because we are importing, we have don't have to worry about permissions. The only requirement is that CrossRef has the correct article information, and has this information as soon as possible after publication.\n\nAt this point I have a confession to make: I regularly use other CrossRef APIs, but wasn't aware of ****api.crossref.org**** until fairly recently. That is sort of understandable since the reference platform was deployed only September last year. The documentation to get you started is on [Github](https://github.com/CrossRef/rest-api-doc/blob/master/rest_api.md) and the version history shows frequent API updates (now at v22). The API will return all kinds of information, e.g.\n\n-   how many articles has publisher x published in 2012\n-   percentage of DOIs of publisher Y that include at least one ORCID identifier\n-   list all books with a Creative Commons CC-BY license that were published this year\n\nFunder (via FundRef) information is also included, but is still incomplete. Another interesting result is the number of [component DOIs](https://blog.front-matter.io/posts/direct-links-to-figures-and-tables-using-component-dois/) (DOIs for figures, tables or other parts of a document) per year.\n\nFor my specific use case I wanted an API call that returns all articles published by PLOS (or any other publisher) in the last day which I can then run regularly. To get all DOIs from a specific publisher, use their CrossRef member ID - DOI prefixes don't work, as publishers can own more than one DOI prefix. To make this task a little easier I built a CrossRef member search interface into the ALM application:\n\n<figure class=\"kg-card kg-image-card\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/crossref_api.png\" class=\"kg-image\" loading=\"lazy\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/crossref_api.png 600w, https://blog.front-matter.io/content/images/size/w1000/2022/08/crossref_api.png 1000w, https://blog.front-matter.io/content/images/2022/08/crossref_api.png 1170w\" sizes=\"(min-width: 720px) 720px\" width=\"1170\" height=\"774\" />\n</figure>\n\nWe can filter API responses by publication date, but it is a better idea to use the update date, as it is possible that the metadata have changed, e.g. a correction of the title. We also want to increase the number of results per page (using the `rows` parameter). The final API call for all DOIs updated by PLOS since the beginning of the week would be\n\n    http://api.crossref.org/members/340/works?filter=from-update-date:2014-07-21,until-update-date:2014-07-24&rows=1000\n\nThe next step is of course to parse the JSON of the API response, and you will notice that CrossRef is using [Citeproc JSON](http://gsl-nagoya-u.net/http/pub/citeproc-doc.html). This is a standard JSON format for bibliographic information used internally by several reference managers for citation styles, but increasingly also by APIs and other places where you encounter bibliographic information.\n\nCiteproc JSON is helpful for one particular problem with CrossRef metadata: the exact publication date for an article is not always known, and CrossRef (and similarly DataCite) only requires the publication year. Citeproc JSON can nicely handle partial dates, e.g. year-month:\n\n    issued: {\n      date-parts: [\n        [\n          2014,\n          7\n        ]\n      ]\n    },\n\nI think that a similar approach will work for many other systems that require bibliographic information about scholarly content with CrossRef DOIs. If are not already using ****api.crossref.org****, consider integrating with it, I find the API fast, well documented, easy to use - and CrossRef is very responsive to feedback. As you can always wish for more, I would like to see the following: fix the problem were some journal articles are missing the publication date (a required field, even if only the year), and consider adding the canonical URL to the article metadata (which ALM currently has to look up itself, and which is needed to track social media coverage of an article).\n\n*Update July 24, 2014: added chart with number of component DOIs per year*\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw0d","guid":"62d42bbd41e317003df48d68","id":"701d7955-e54a-45af-a8b0-4ce7bf4dc88b","image":"https://blog.front-matter.io/content/images/2022/08/4AxDk-component-dois-per-year.png","indexed_at":1,"language":"en","published_at":1406215980,"reference":[],"relationships":[],"summary":"In a post last week I talked about roads and stagecoaches, and how work on scholarly infrastructure can often be more important than building customer-facing apps. One important aspect of that infrastructure work is to not duplicate efforts.Image by Cocoabiscuit on Flickr A good example is information (or metadata) about scholarly publications. I am the technical lead for the open source article-level metrics (ALM) software.\n","tags":["Feature"],"title":"Don't Reinvent the Wheel","updated_at":1660839529,"url":"https://blog.front-matter.io/posts/dont-reinvent-the-wheel"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/introducing-rakali","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"In July and August I attended the [Open Knowledge\nFestival](http://2014.okfestival.org/) and\n[Wikimania](http://wikimania2014.wikimedia.org/wiki/Programme). At both\nevents I had many interesting discussions around open source tools for\nopen access scholarly publishing, and I was part of a\n[panel](http://wikimania2014.wikimedia.org/wiki/Submissions/The_Full_OA_Stack_-_Open_Access_and_Open_Source)\non that topic at Wikimania last Sunday. Some of my thoughts were\nsummarized in a blog post a few weeks ago ([Build Roads not\nStagecoaches](https://blog.front-matter.io/posts/roads-not-stagecoaches/)).\nToday I am happy to announce the first public release of a tool that\nhopefully contributes to making publishing of open content a bit easier.\n\n<figure class=\"kg-card kg-image-card kg-card-hascaption\">\n<img\nsrc=\"https://blog.front-matter.io/content/images/2022/08/lego_discussion-1-1.jpg\"\nclass=\"kg-image\" loading=\"lazy\"\nsrcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/lego_discussion-1-1.jpg 600w, https://blog.front-matter.io/content/images/2022/08/lego_discussion-1-1.jpg 700w\"\nwidth=\"700\" height=\"600\"\nalt=\"LEGO Researchers are excited that they don\u2019t have to use Microsoft Word for manuscript writing anymore.\" />\n<figcaption aria-hidden=\"true\">LEGO Researchers are excited that they\ndon\u2019t have to use Microsoft Word for manuscript writing\nanymore.</figcaption>\n</figure>\n\n[Rakali](https://github.com/rakali/rakali.rb) is a Ruby gem that acts as\na wrapper for the [Pandoc](https://pandoc.org) universal document\nconverter. Pandoc is a wonderful tool to convert documents between file\nformats and supports many file formats and features important for\nscholarly publishing. Pandoc 1.13 was\n[released](http://johnmacfarlane.net/pandoc/releases.html) last Friday,\nand one of the most exciting new features is a reader for Microsoft Word\n(`docx`) documents. Pandoc has supported the conversion to `docx` for a\nwhile, but now you can use the most popular file format for writing\nscholarly documents and turn your `docx` files into HTML, PDF, LateX,\nmarkdown, or a number of other formats, making it much easier to\ncollaborate, and to use `docx` with Pandoc in scholarly publishing\nworkflows. A good example would be arXiv, which [doesn't\nsupport](http://arxiv.org/help/submit#text) `docx` for text submissions.\nInstead of turning it into PDF the manuscript can now be converted to\nLaTeX - the preferred file format at arXiv - before submission.\n\nI built ****Rakali**** to make it easier to use Pandoc to convert large\nnumbers of documents in an automated way:\n\n- bulk conversion of all files in a folder with a specific extension,\n  e.g. `md`.\n- input via a configuration file in yaml format instead of via the\n  command line\n- validation of documents via [JSON Schema](http://json-schema.org/),\n  using the [json-schema](https://github.com/hoxworth/json-schema) Ruby\n  gem.\n- Logging via `stdout` and `stderr`.\n\nOne interesting way to use Rakali and Pandoc is as part of a [continuous\npublishing](https://blog.front-matter.io/posts/continuous-publishing/)\nworkflow that involves git and Github, automatically converting all\nfiles in a folder when something is pushed to the repository using a\ncontinuous integration tool, and exiting the continuous integration run\nwhen one of the files doesn't validate. Look into the Rakali\n[repo](https://github.com/rakali/rakali.rb) for an example.\n\nThe most interesting aspect of Rakali is probably validation via JSON\nSchema. File conversion with Pandoc is a two-step process, the\nintermediate format is an internal representation of the document in\nsomething called the [abstract syntax\ntree](https://blog.front-matter.io/posts/the-grammar-of-scholarly-communication/)\nor AST. Pandoc makes the AST accessible in JSON format, making it\nstraightforward to manipulate a document before the conversion into the\ntarget format with something called [JSON\nfilters](http://johnmacfarlane.net/pandoc/scripting.html).\n\nValidation of XML documents using\n[DTDs](https://en.wikipedia.org/wiki/Document_type_definition), [RELAX\nNG](http://relaxng.org/) and other standards has of course been around\nfor a long time, but validation of JSON documents is still relatively\nnew. Since many Pandoc document conversion workflows don't involve any\nXML I thought it would make more sense to validate against the AST, and\nwe can use JSON Schema for that. I have started a [Github\nrepository](https://github.com/rakali/pandoc-schemata) with schemata for\nthe Pandoc AST, and hope to evolve them over time using Rakali as a\ntool. An example log output (from the Rakali test suite, stopping file\nconversion because title and layout metadata are missing) looks like\nthis:\n\n    Validation Error: The property '#/0/unMeta' did not contain a required property of 'title' in schema 9b6d454d-e609-537b-b761-9599b6c01072# for file empty.md\n    Validation Error: The property '#/0/unMeta' did not contain a required property of 'layout' in schema 9b6d454d-e609-537b-b761-9599b6c01072# for file empty.md\n    Fatal: Conversion of file empty.md failed.\n\nAs I had argued before, the challenge for building open source tools for\nscience is to [not duplicate the work of\nothers](https://blog.front-matter.io/posts/dont-reinvent-the-wheel/),\nand to integrate well with existing tools by focussing on one aspect and\ndoing that aspect well. It also helps to think about infrastructure\n([the\nroads](https://blog.front-matter.io/posts/roads-not-stagecoaches/))\ninstead of only focussing on the user-facing aspects. There are\nobviously many document conversion tools out there, but Pandoc is\ncertainly one of the oldest and most established ones for scholarly\ncontent. Rakali therefore builds on top of Pandoc and tries to play well\nwith other existing tools and services, e.g. by using the UNIX `stdout`\nand `stderr` for reporting, and by using a file-based approach that\nworks well with version control systems such as git. And since Rakali is\na Ruby gem it can not only be used as a standalone command line tool,\nbut can also be easily integrated into other Ruby applications.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw08","guid":"62d42bbd41e317003df48d63","id":"dc70f3f3-90e1-4229-b994-1ee20ed94b08","image":"https://blog.front-matter.io/content/images/2022/08/lego_discussion-1-1.jpg","indexed_at":1,"language":"en","published_at":1408374960,"reference":[],"relationships":[],"summary":"In July and August I attended the Open Knowledge Festival and Wikimania. At both events I had many interesting discussions around open source tools for open access scholarly publishing, and I was part of a panel on that topic at Wikimania last Sunday.\n","tags":["News"],"title":"Introducing Rakali","updated_at":1660839226,"url":"https://blog.front-matter.io/posts/introducing-rakali"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/using-microsoft-word-with-git","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"One of the major challenges of writing a journal article is to keep\ntrack of versions - both the different versions you create as the\ndocument progresses, and to merge in the changes made by your\ncollaborators. For most academics Microsoft Word is the default writing\ntool, and it is both very good and very bad in this. Very good because\nthe *track changes* feature makes it easy to see what has changed since\nthe last version and who made the changes. Very bad because this feature\nis built around keeping everything in a single Word document, so that\nonly one person can work on on a manuscript at a time. This usually\nmeans sending manuscripts around by email, and being very careful about\nnot confusing different versions of the document, which requires\n[creativity](http://www.phdcomics.com/comics/archive.php?comicid=1531).\n\nApproaches to overcome these challenges are to a) integrate the Word\ndocuments into collaboration tools such as Sharepoint and Office 365, or\ndocument sharing services such as Dropbox and Google Docs (if you use it\njust for that), or b) use a different authoring tool altogether. If\nneither of these approaches works for you, you have a third option: use\nthe version control system ****git****.\n\n[Git](http://www.mulvany.net/presentations/WikimaniaOpenScholarshipTalk.slides.html#/3)\nis software that helps with [tracking changes to\nfiles](https://git-scm.com/book/en/Getting-Started-About-Version-Control)\nso that you can recall specific versions later. Git is typically used to\ntrack changes of software source code (and was originally developed by\nLinus Torvalds for Linux kernel development in 2005), but in fact git\ncan be used for any file where we need to keep track of versions over\ntime. Git is open source software that runs locally on your computer, so\nplease go ahead and start tracking changes to your manuscripts (or other\ncomplex documents) with git. Any time you want to store a version, do a\n`git commit` with a little description and an optional tag.\n\nThis approach is not ideal, as git was written with source code in text\nformat in mind and for example doesn't understand what has changed\nbetween two revisions of a Word document. Some people will tell you to\nnever store binary files in a version control system, but don't listen\nto them. Instead give git a tool to convert Word documents into plain\ntext, and git will then happily tell you what has changed between\nrevisions. Several tools can do this, but since earlier this month\nPandoc can read Word documents in `docx` format. Do the following to\nhave Pandoc convert Word documents into markdown, and to compare the\nrevisions by word and not by line (which makes more sense):\n\n    # .gitattributes file in root folder of your git project\n    *.docx diff=pandoc\n\n    # .gitconfig file in your home folder\n    [diff \"pandoc\"]\n      textconv=pandoc --to=markdown\n      prompt = false\n    [alias]\n      wdiff = diff --word-diff=color --unified=1\n\nYou can then use `git wdiff important_file.docx` to see the changes\n(with deletions in red and insertions in green), or\n`git log -p --word-diff=color important_file.docx` to see all changes\nover time.\n\nWhile you can now track revisions of a Word document and see the\nchanges, you also want to be able to merge different versions of a Word\ndocument together so that you and your collaborators can work on the\nmanuscript in parallel. Git can't merge binary files together, so you\nneed to first convert the Word document into a format that git\nunderstands. Just as in the previous example we can use Pandoc for that,\nwith markdown as the textual format. This would also work with HTML or\nLaTeX, but the simplicity of markdown makes it better suited for version\ncontrol which doesn't know about the markup of these formats.\n\nOne of the reasons that git became so popular with software developers\nis that it is a ****distributed version control system**** instead of a\ncentralized system such as Subversion. This means that you can track all\nrevisions locally on your computer, but can still synchronize your\nrevisions with another user. ****Github**** is a popular service that\nfacilitates this synchronization and adds some nice features on top. One\nway to collaborate with your co-authors is therefore to set up a Github\nrepository (public or private) for your manuscript, and store the master\nversion of the manuscript in markdown format. Instead of working on the\nmaster version directly, you would use Pandoc to convert back and forth\nbetween this master version in markdown format and your Word document,\nand would continue to use Word as authoring tool.\n[Rakali](https://blog.front-matter.io/posts/introducing-rakali/) is a\nPandoc tool that I released last week that can help automate this\ndocument conversion. Github has a a number of features to facilitate\ncollaboration that can be used here, e.g. Github issues for discussion\nand task management.\n\nThere are still a few rough edges in the workflow described above (e.g.\nonly partial support of Word track changes), but it is an interesting\napproach to collaborate using Microsoft Word and git. And this workflow\ncan of course be enhanced to also include authors that write in LaTeX or\none of the other formats that Pandoc supports. One nice side effect of\nusing markdown is that Github will automatically render a webpage for\nthe document (which it will not do for HTML without extra effort).\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw07","guid":"62d42bbd41e317003df48d62","id":"6fb5ed70-2b97-435f-8ae8-4c0b67242c52","image":"https://blog.front-matter.io/content/images/2022/08/data_versioning.jpeg","indexed_at":1,"language":"en","published_at":1408979520,"reference":[],"relationships":[],"summary":"One of the major challenges of writing a journal article is to keep track of versions - both the different versions you create as the document progresses, and to merge in the changes made by your collaborators. For most academics Microsoft Word is the default writing tool, and it is both very good and very bad in this.\n","tags":["Science Hack"],"title":"Using Microsoft Word with git","updated_at":1660838880,"url":"https://blog.front-matter.io/posts/using-microsoft-word-with-git"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/lets-do-an-unconference","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"This year's [SpotOn London\nconference](http://blogs.nature.com/ofschemesandmemes/2014/10/09/how-to-get-a-ticket-for-this-years-spoton-london)\ntakes place November 14-15 and the registration has opened this Monday.\nI am helping organize this conference since 2009, and I again look\nforward to the sessions, and - more importantly - the discussions with\npeople in and between sessions this year.\n\nThe name (ScienceBlogging London, ScienceOnline London, SpotOn London),\nthe location (Royal Institution, British Library, Wellcome Conference\nCenter), the people organizing (too many to mention, but Nature\nPublishing Group always at the core), and the fringe events (lots of\ncool things from [science\ntours](http://blog.mendeley.com/academic-life/science-blogging-2008-part-i/)\nto [Story\nCollider](http://www.nature.com/spoton/event/spoton-london-2012-fringe-event-the-story-collider-2/))\nand the format have always changed slightly over the years, and this\nyear again is a bit different. The biggest change is obviously that [Lou\nWoodley](https://twitter.com/louwoodley) is no longer an organizer (as\nshe announced at last year's conference), but this is also the first\nSpotOn conference with a theme:\n\n> The challenges of balancing the public and the private in the digital\n> age\n\nThis is obviously a very broad topic, but nicely encompasses many\nimportant issues that we are dealing with in scholarly communication\ntoday. The draft program is posted\n[here](http://blogs.nature.com/ofschemesandmemes/2014/10/13/spoton-london-2014-draft-programme),\nand I'm helping organize the sessions on ****sharing sensitive data****\nand ****open peer review****. More details will follow for all these\nsessions.\n\n<figure class=\"kg-card kg-image-card kg-card-hascaption\">\n<img\nsrc=\"https://blog.front-matter.io/content/images/2022/08/2817131778_e8e04ed68e_o.jpg\"\nclass=\"kg-image\" loading=\"lazy\"\nsrcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/2817131778_e8e04ed68e_o.jpg 600w, https://blog.front-matter.io/content/images/size/w1000/2022/08/2817131778_e8e04ed68e_o.jpg 1000w, https://blog.front-matter.io/content/images/size/w1600/2022/08/2817131778_e8e04ed68e_o.jpg 1600w, https://blog.front-matter.io/content/images/2022/08/2817131778_e8e04ed68e_o.jpg 2048w\"\nsizes=\"(min-width: 720px) 720px\" width=\"2000\" height=\"1500\" />\n<figcaption><a\nhref=\"https://www.flickr.com/photos/dullhunk/2817131778/\">Flickr photo\nby Duncan Hull</a></figcaption>\n</figure>\n\nThe second day of the conference will be in unconference (or barcamp)\nformat and the program drafted by the delegates in the morning. This\nformat is popular in the science communications community (I first heard\nabout the project that became my current job at [SciBarCamp in\n2009](https://blog.front-matter.io/lets-do-an-unconference/i-was-at-scibarcamp-palo-alto)),\nand SpotOn London has used this format in the first conference in 2008\n(and again in 2009):\n\nFor people not familiar with this format the idea of a conference (day)\nwithout predetermined topics or speakers sounds scary. As it turns out,\nthe problem is usually not the lack of ideas or people wanting to talk,\nbut rather how to coordinate this in a way that everyone who wants to\nget involved can do so, and it doesn't become a discussion among those\nwith the loudest voices (and biggest egos). My experience with SpotOn\nLondon and other conferences I enjoyed is that the best sessions are\nusually those that allow for a good discussion, and not those with the\nmost polished PowerPoint slides. Some suggestions for when you attend an\nunconference for the first time:\n\n- go to sessions with topics you know little about, but want to learn\n  more\n- when suggesting a session, do this together with others\n- suggest topics that are focussed and unusual, not the obvious ones we\n  always talk about\n- don't even think about doing a PowerPoint presentation\n- when moderating a session, be a good moderator, not a good speaker\n\n## Further reading\n\n- [Wikipedia: SciFoo](http://en.wikipedia.org/wiki/Science_Foo_Camp)\n- [Ian Mulvany: BarCamp Cambridge\n  2007](http://blogs.nature.com/nascent/2007/08/barcamb_cambridge.html)\n- [Eva Amsen: SciBarCamp Toronto\n  2008](http://science.easternblot.net/?p=613)\n- [Me: BibCamp Hannover\n  2010](https://blog.front-matter.io/posts/action_points)\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw03","guid":"62d42bbd41e317003df48d5e","id":"46065fc6-8fbf-470d-86bb-b28cfd1e0877","image":"https://blog.front-matter.io/content/images/2022/08/photo-1448906654166-444d494666b3.jpeg","indexed_at":1,"language":"en","published_at":1413298920,"reference":[],"relationships":[],"summary":"This year\u2019s SpotOn London conference takes place November 14-15 and the registration has opened this Monday. I am helping organize this conference since 2009, and I again look forward to the sessions, and - more importantly - the discussions with people in and between sessions this year.\n","tags":["Meeting Report"],"title":"Let's do an unconference","updated_at":1660838555,"url":"https://blog.front-matter.io/posts/lets-do-an-unconference"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/data-citation-support-in-reference-managers","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"This is the title of an upcoming workshop next Sunday organized by Ian\nMulvany and myself. The workshop is a [pre-conference\nevent](https://www.force11.org/meetings/force2015/pre-conference-meeting-list)\nof the [Force15](https://www.force11.org/meetings/force2015) conference\nin Oxford. This blog post summarizes some of the issues and work that\nneeds to be done.\n\nData Citation is one of the big themes of the Force15 conference, and a\nlot of progress has been made, including the Joint Declaration of Data\nCitation Principles (Data Citation Synthesis Group 2014) that start with\nthe following paragraph on ****Importance****:\n\n> Data should be considered legitimate, citable products of research.\n> Data citations should be accorded the same importance in the scholarly\n> record as citations of other research objects, such as publications.\n\nConvincing researchers, funders, university administrators and others\nthat data citation is important is crucial. But for researchers to\nactually adopt data citation to the same degree as citations of the\nscholarly literature, more needs to be done:\n\n- incentives (both carrots and sticks) by funders, institutions, and\n  scholarly societies\n- training in data management\n- data repositories and other tools and services for the public sharing\n  of data\n- tools and services that help citing those datasets\n\nThe focus of the workshop is on the last bullet point, and I would argue\nthat more work still needs to be done here compared to the first three\nbullet points.\n\n## Reference Managers\n\nResearchers use reference managers to handle the citations in the\nmanuscripts they write. This is both a common practice that everybody\nunderstands, and there are a plethora of tools - both free and paid -\navailable. Most reference managers were originally built to handle\ncitations of journal articles and maybe books or book chapters, and many\nof them also help with managing the associated PDF files. In the last 15\nyears we have seen an dramatic increase of non-article citations in\nreference lists, mainly to web resources (Klein et al., 2014):\n\n<figure class=\"kg-card kg-image-card kg-card-hascaption\">\n<img\nsrc=\"https://blog.front-matter.io/content/images/2022/08/journal.pone.0115253.g002-1.png\"\nclass=\"kg-image\" loading=\"lazy\"\nsrcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/journal.pone.0115253.g002-1.png 600w, https://blog.front-matter.io/content/images/size/w1000/2022/08/journal.pone.0115253.g002-1.png 1000w, https://blog.front-matter.io/content/images/size/w1600/2022/08/journal.pone.0115253.g002-1.png 1600w, https://blog.front-matter.io/content/images/size/w2400/2022/08/journal.pone.0115253.g002-1.png 2400w\"\nsizes=\"(min-width: 720px) 720px\" width=\"2000\" height=\"1864\" />\n<figcaption>From Fig. 2: STM articles and URI references per publication\nyear - Elsevier corpus (Klein et al. 2014)</figcaption>\n</figure>\n\nReferences managers have started to adapt to these changes in citation\npatterns. Similarly they have become better in handling non-textual\nresources such as slide decks, datasets, or movies. Nobody should type\nin references by hand in 2015, as reference managers have come up with\nseveral ways of importing metadata about citations:\n\n- import references stored in a file using a format such as BibTex or\n  RIS\n- import references by talking to an external API\n- import references via a bookmarklet that grabs information from the\n  current webpage in the browser\n\nEndnote and Papers typically use the second approach whereas Mendeley,\nZotero (and others) work almost exclusively via bookmarklets (and there\nare of course combinations of both). Bookmarklets in general work better\nfor web resources and other content that is not indexed in a central\nservice such as Web of Science or Scopus. This is also true for research\ndata, as there are currently few central research data indexing\nservices - the Thomson Reuters [Data Citation\nIndex](http://wokinfo.com/products_tools/multidisciplinary/dci/) and\n[DataCite](https://www.datacite.org/) are two examples in this category.\nBut there are also thousands of data repositories, many of them listed\nin re3data (Pampel et al., 2013).\n\nThe reference manager [Zotero](https://www.zotero.org/) has built a\nlarge open source ecosystem around bookmarklets (what they call [web\ntranslators](https://github.com/zotero/translators)), making it\nstraightforward to add support for a new resource, as I have done for\n[GenBank nucleotide sequence\ndatasets](https://github.com/zotero/translators/blob/master/NCBI%20Nucleotide.js)\nin November after learning the basics in a\n[webinar](https://blog.front-matter.io/posts/webinar-on-writing-zotero-translators/)\ngiven by Sebastian Karcher, a frequent contributor to Zotero web\ntranslators.\n\nThere is no technical reason that reference managers can't support a\nbroad range of objects to cite, including datasets. And integration of\ndata citation into the reference manager workflow is not only the\neasiest and most natural way for the author of a paper, but also makes\nit easier to discover these citations - reference lists are simply much\nbetter for that than links in the text, in particular if the content is\nbehind subscription walls. There is a long tradition in the life\nsciences to put identifiers for genetic sequences used in a publication\nright into the text (usually into the methods section). Links in the\nbody text are worse than references in reference lists, [identifiers\nwithout a\nlink](https://blog.front-matter.io/posts/auto-generating-links-to-data-and-resources/)\nare even worse, as they are very hard to find in an automated way\n(Kafkas, Kim, & McEntyre, 2013).\n\nPlease come to our workshop on Sunday afternoon if you are in Oxford and\nare interested in this topic.\n[Registration](https://www.eventbrite.com/e/data-citation-support-in-reference-managers-tickets-15136593960)\nis free, and the workshop will include both presentations about the\ncurrent state of data citation support in the reference managers\nEndnote, Papers, Mendeley and Zotero, and work in smaller groups on\npractical implementations.\n\n## References\n\nKafkas, \u015e., Kim, J.-H., & McEntyre, J. R. (2013). Database Citation in\nFull Text Biomedical Articles. *PLoS ONE*.\nhttps://doi.org/[10.1371/journal.pone.0063184](https://doi.org/10.1371/journal.pone.0063184)\n\nKlein, M., Van de Sompel, H., Sanderson, R., Shankar, H., Balakireva,\nL., Zhou, K., & Tobin, R. (2014). Scholarly context not found: one in\nfive articles suffers from reference rot. *PLoS ONE*, *9*(12), e115253.\nhttps://doi.org/[10.1371/journal.pone.0115253](https://doi.org/10.1371/journal.pone.0115253)\n\nPampel, H., Vierkant, P., Scholze, F., Bertelmann, R., Kindling, M.,\nKlump, J., ... Dierolf, U. (2013). Making Research Data Repositories\nVisible: The re3data.org Registry. *PLoS ONE*, *8*(11), e78080.\nhttps://doi.org/[10.1371/journal.pone.0078080](https://doi.org/10.1371/journal.pone.0078080)\n\nData Citation Synthesis Group. (2014). *Joint Declaration of Data\nCitation Principles*. Force11. <https://doi.org/10.25490/A97F-EGYK>\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw01","guid":"62d42bbd41e317003df48d5c","id":"52cc631a-fba9-4d9b-815e-f868ddddbbcf","image":"https://blog.front-matter.io/content/images/2022/08/journal.pone.0115253.g002.png","indexed_at":1,"language":"en","published_at":1420469700,"reference":[{"doi":"https://doi.org/10.1371/journal.pone.0063184","key":"ref1"},{"doi":"https://doi.org/10.1371/journal.pone.0115253","key":"ref2"},{"doi":"https://doi.org/10.1371/journal.pone.0078080","key":"ref3"},{"doi":"https://doi.org/10.25490/A97F-EGYK","key":"ref4"}],"relationships":[],"summary":"This is the title of an upcoming workshop next Sunday organized by Ian Mulvany and myself. The workshop is a pre-conference event of the Force15 conference in Oxford. This blog post summarizes some of the issues and work that needs to be done.\n","tags":["Meeting Report"],"title":"Data Citation Support in Reference Managers","updated_at":1660838398,"url":"https://blog.front-matter.io/posts/data-citation-support-in-reference-managers"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/manifests-and-reference-lists","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"Last month at the [Force15\nconference](https://www.force11.org/meetings/force2015/pre-conference-meeting-list)\nin Oxford [Ian Mulvany](https://twitter.com/IanMulvany) and I ran a\nworkshop on [data citation support in reference\nmanagers](https://blog.front-matter.io/posts/data-citation-support-in-reference-managers/).\nThe report of that workshop isn't done yet, but I can say that it was a\nsuccess - we now have a pretty good idea what the problems are and what\nneeds to be done to fix them. The short summary of the workshop is in\n[this](https://speakerdeck.com/mfenner/workshop-summary-reference-managers-and-data-citation)\nslide deck of the presentation that summarized the workshop for the\nother Force15 attendees.\n\nThe whole idea of the workshop was to treat data citation as similar as\npossible to the citation of journal articles, i.e. to allow authors to\nuse the same tools (reference managers) and conventions (citation\nstyles). Putting a data citation into a reference list makes it easier\nto find that data citation because reference lists contain more\nmetadata, are more structured, and more accessible than data citations\nin the form of identifiers or links within the body text of the article.\n\nBut I have to admit that there is one problem with reference lists:\nalthough there is always some self-citation, reference lists usually\ncontain references to articles (and other resources) created by other\npeople and before the article was published. It feels a little bit odd\nto put a dataset created by the same group of people and published at\nthe same time into the reference list. And although we could use a\nseparate reference list or highlight the data associated with the\narticle in some other way, what we really want is something slightly\ndifferent, a manifest file.\n\nThe journal article has been a (mainly) textual document for many\ncenturies not because this is the essence of science communication, but\nrather because there was no practical way to include all the other\ninformation (raw data, tools used for experiments, etc.). Very few of\nthese limitations remain with the digital journal article that we have\nsince the 1990s, but we have for the most part failed to change the\nformat other than going from paper to PDF. One of many examples: figures\nin publications typically still are has limited as they were decades ago\nwith no way to see the data underlying the figure, options for selecting\nwhat data points are shown, or animation for time-based information.\n\nSo what we really care about is the sum of artifacts and resources that\ntogether make what Carol Goble and others call [research\nobject](https://doi.org/10.1038/npre.2010.4626.1), the journal article\nis an important part, but clearly doesn't include everything that is\nneeded to understand and reproduce the work. Reference lists can help\nwith linking to some of the resources not included in the article text,\nbut they typically don't link to supplementary information or other\nplaces where the underlying data are made available, or to the figures\nof the article. Although some publishers provide navigation tools for\nreaders to get to this information, what we really need is a\nmachine-readable list of all the resources used in an article.\n\nAs it happens, this is exactly what the ePub format for electronic books\nis doing, as every ePub must include a manifest file that lists all the\nfiles that are part of the publication, defined in the [Open Packaging\nFormat (OPF)](http://www.idpf.org/epub/20/spec/OPF_2.0.1_draft.htm). I\nneed to do more research to figure out how to do this with\n[JATS](http://jats.nlm.nih.gov/archiving/tag-library/1.0/index.html),\nthe standard for scholarly articles, and how to generate something\nsimilar to the manifest file when using different formats, e.g. html or\nmarkdown. This has to be linked to some of the information we are\ncollecting already, e.g. described in\n[JATS](https://doi.org/10.3998/3336451.0014.106), or the\n`relatedIdentifier` in the [DataCite\nmetadata](https://doi.org/10.5438/0010).\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw00","guid":"62d42bbd41e317003df48d5b","id":"42ea11d8-a09b-47c5-a6b9-451ea7356157","image":"https://blog.front-matter.io/content/images/2022/08/photo-1567966181174-55151ffbd185.jpeg","indexed_at":1,"language":"en","published_at":1423137780,"reference":[],"relationships":[],"summary":"Last month at the Force15 conference in Oxford Ian Mulvany and I ran a workshop on data citation support in reference managers. The report of that workshop isn\u2019t done yet, but I can say that it was a success - we now have a pretty good idea what the problems are and what needs to be done to fix them. The short summary of the workshop is in this slide deck of the presentation that summarized the workshop for the other Force15 attendees.\n","tags":["Meeting Report"],"title":"Manifests and Reference Lists","updated_at":1660837965,"url":"https://blog.front-matter.io/posts/manifests-and-reference-lists"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/metrics-for-scientific-software","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"One of the challenges of collecting metrics for scholarly outputs is\npersistent identifiers. For journal articles the Digital Object\nIdentifier (DOI) has become the de-facto standard, other popular\nidentifiers are the pmid from PubMed, the identifiers used by Scopus and\nWeb of Science, and the arxiv ID for ArXiV preprints.\n\nFor other research outputs the picture is less clear. DOIs are also used\nfor datasets, but so are many other identifiers, in particular in the\nlife sciences.\n\nTo collect metrics for research outputs, the requirements are slightly\ndifferent. We need identifiers understood by the services collecting the\nmetrics, not by the data repository or other service that is holding the\nresearch output (the only exception is usage stats, which are generated\nlocally). For many services, in particular social media such as\nFacebook, Twitter or Reddit, the primary identifier for a resource is a\nURL. This means that we should have one or more URLs for every research\noutput where we want to track the metrics - typically the publisher or\ndata repository landing page. Since URLs can be messy, Google, Facebook\nand others have come up with the concept of a [canonical\nURL](http://googlewebmastercentral.blogspot.de/2009/02/specify-your-canonical.html),\nand some care should go into constructing proper canonical URLs (see\n[this blog\npost](https://blog.front-matter.io/posts/challenges-in-automated-doi-resolution)\nfor examples of what can go wrong).\n\nThe Den Haag Manifesto is the result of a ****Knowledge Exchange****\nworkshop held in June 2011 and tries to bring Persistent Identifiers and\nLinked Open Data together. The first principle is very much in line with\nwhat I said above:\n\n> Make sure PIDs can be referred to as HTTP URI's, including support for\n> content negotiation.\n\nOr, to put this differently: URLs are good enough to start collecting\nmetrics for scholarly outputs. Scientific software is a good example\nwhere persistent identifiers are not commonly used (despite efforts such\nas [this one](https://guides.github.com/activities/citable-code/)), but\nwe can still collect many meaningful metrics using the repository URL\n(and the open source software\n[lagotto](https://github.com/articlemetrics/lagotto)):\n\n<figure class=\"kg-card kg-image-card kg-card-hascaption\">\n<img\nsrc=\"https://blog.front-matter.io/content/images/2022/08/software.lagotto.io-1.png\"\nclass=\"kg-image\" loading=\"lazy\"\nsrcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/software.lagotto.io-1.png 600w, https://blog.front-matter.io/content/images/size/w1000/2022/08/software.lagotto.io-1.png 1000w, https://blog.front-matter.io/content/images/2022/08/software.lagotto.io-1.png 1468w\"\nsizes=\"(min-width: 720px) 720px\" width=\"1468\" height=\"686\"\nalt=\"Number of software repositories (out of 1,404) with at least one event. Data from software.lagotto.io\" />\n<figcaption aria-hidden=\"true\">Number of software repositories (out of\n1,404) with at least one event. Data from\nsoftware.lagotto.io</figcaption>\n</figure>\n\nThe last three rows are citations in the scholarly literature found via\nfulltext search of BioMed Central, Europe PMC and PLOS. URLs (in\ncontrast to persistent identifiers represented as strings and/or\nnumbers) are easy to find, the main limitation is not so much using a\nURL rather than a DOI, but that scientific software typically is\nmentioned in the text without appearing in the reference list. This\nmakes it hard to impossible to find articles mentioning the software\nthat are not open access, which unfortunately is still the majority of\nthem.\n\nWe are of course also tracking the discussion of the software in social\nmedia, and are collecting the number of stars and forks in Github and\nBitbucket. Overall there is quite a lot of activity, here are some\nexamples:\n\n- [Windowed Adaptive Trimming for fastq files using\n  quality](https://github.com/najoshi/sickle)\n- [Reads simulator](https://github.com/lh3/wgsim)\n- [Toolkit for processing sequences in FASTA/Q\n  formats](http://software.lagotto.io/works/url/https://github.com/lh3/seqtk)\n\nAll three software repos have been cited in the scholarly literature at\nleast ten times. What is missing is infrastructure that tracks the\ncitations of scientific software, so that we can give proper scientific\ncredit to the authors of the software, and can discover other research\nprojects using the same tools. software.lagotto.io uses a list of\nsoftware repos collected by Jure Triglav for ScienceToolbox, and a\nscientific software index is indeed one of the important missing pieces.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cvzz","guid":"62d42bbd41e317003df48d5a","id":"3aaab156-9821-4333-8fd1-41e84e680a20","image":"https://blog.front-matter.io/content/images/2022/08/software.lagotto.io.png","indexed_at":1,"language":"en","published_at":1424347200,"reference":[],"relationships":[],"summary":"One of the challenges of collecting metrics for scholarly outputs is persistent identifiers. For journal articles the Digital Object Identifier (DOI) has become the de-facto standard, other popular identifiers are the pmid from PubMed, the identifiers used by Scopus and Web of Science, and the arxiv ID for ArXiV preprints. For other research outputs the picture is less clear.\n","tags":["Feature"],"title":"Metrics for scientific software","updated_at":1660837486,"url":"https://blog.front-matter.io/posts/metrics-for-scientific-software"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/metadata-in-microsoft-word-documents","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"Metadata such as author, title, journal or persistent identifier are\nessential for scholarly documents, and some of us are spending a\nsignificant part of our time adding or fixing metadata. Unfortunately we\nsometimes don't pay enough attention to the flow of metadata, i.e. we\nignore already existing metadata, or reinvent the wheel in how we\ndescribe or store them.\n\nStoring metadata in text-based formats is usually straightforward. This\nblog post is written in markdown with a [YAML\nheader](http://yaml.org/) - think of YAML as the more human-readable\nversion of JSON - at the beginning of the document:\n\n    ---\n    title: Metadata in Microsoft Word documents\n    ---\n\nThis is then translated into this HTML when the blog post is published:\n\n    <meta property=\"dc:title\" content=\"Metadata in Microsoft Word documents\" />\n\nXML is of course a very natural format for metadata, here for example\n[JATS](http://jats.nlm.nih.gov/publishing/tag-library/1.0/index.html)\nused for scholarly articles:\n\n    <article-title>Metadata in Microsoft Word documents</article-title>\n\nMany scholarly documents start out as Microsoft Word documents. And\nwhile the `docx` format introduced by Microsoft in Microsoft Office 2007\n[is XML-based](http://officeopenxml.com/), few users are aware of this\nfact. And probably even fewer users (including myself) ever go to the\n`Properties\u2026` settings of a `docx` document and add a `title`,\n`keywords` or other metadata (the `author` is usually set\nautomatically).\n\nThis is very unfortunate, as these metadata are very often required,\ne.g. in a journal article submission, and then need to be collected\nagain, usually either by asking the author to fill out a web form,\nand/or by extracting the metadata (e.g. title) from the document.\n\nThe best place for metadata is with the document (not *in* the\ndocument), and if the file format (`docx` in this case) supports it, we\nshould take advantage of this. The main benefit: metadata stay with the\ntext when the document is sent to co-authors via email, or put on a file\nserver, or into Dropbox.\n\nIn the case of `docx`, the metadata support is actually pretty good,\nusing the standard [Dublin Core](http://dublincore.org/), and storing\nthe metadata in a separate file called `core.xml`. You can see this file\nif you unzip your `docx` file (e.g. after giving it a `zip` extension).\nThe `core.xml` file for this blog post (after converting the markdown\nfile to `docx` using [Pandoc](https://pandoc.org)) looks like this:\n\n    <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n    <cp:coreProperties xmlns:cp=\"http://schemas.openxmlformats.org/package/2006/metadata/core-properties\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:dcterms=\"http://purl.org/dc/terms/\" xmlns:dcmitype=\"http://purl.org/dc/dcmitype/\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"><dc:title>Metadata in Microsoft Word documents</dc:title><dc:creator></dc:creator></cp:coreProperties>\n\nBecause `docx` is XML, we can read/write this file not only in Microsoft\nWord, e.g. using macros, but also outside of Microsoft Word, e.g. in\nworkflows that converts `docx` documents into other formats, or tools\nthat check `docx` files for required metadata (e.g. by using\n[rakali](https://blog.front-matter.io/posts/introducing-rakali/) that I\nwrote last year). So please encourage authors to use the Microsoft Word\n`Properties\u2026` settings, and update existing tools to take advantage of\nthe Dublin Core metadata stored in every `docx` file.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cvzw","guid":"62d42bbd41e317003df48d57","id":"f6a575ec-4ff8-4563-9d4d-2f55d91428ab","image":"https://blog.front-matter.io/content/images/2022/08/IC164149.gif","indexed_at":1,"language":"en","published_at":1426852320,"reference":[],"relationships":[],"summary":"Metadata such as author, title, journal or persistent identifier are essential for scholarly documents, and some of us are spending a significant part of our time adding or fixing metadata. Unfortunately we sometimes don\u2019t pay enough attention to the flow of metadata, i.e. we ignore already existing metadata, or reinvent the wheel in how we describe or store them. Storing metadata in text-based formats is usually straightforward.\n","tags":["Science Hack"],"title":"Metadata in Microsoft Word documents","updated_at":1660837386,"url":"https://blog.front-matter.io/posts/metadata-in-microsoft-word-documents"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/blogging-beyond-jekyll","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"This blog has been on four different platforms since starting in 2007: a\ncustom blogging engine and then [Movable Type](https://movabletype.org/)\non [Nature Network](http://network.nature.com/) 2007-2010, Wordpress on\nthe [PLOS Blogs Network](http://blogs.plos.org) 2010-2013, and the\nstatic blogging engine [Jekyll](https://jekyllrb.com/) hosted on Github\nPages since 2013. It might be time for yet another blogging platform\nchange.\n\nThe main reason to switch from Wordpress to Jekyll was the concept of a\nstatic site generator: write posts in [markdown\nformat](http://commonmark.org/), store them in a Github repository, and\nthen have Jekyll automatically generate the HTML pages hosted on [Github\nPages](https://pages.github.com/). The main attraction was the blog\nposts in markdown format stored in git version control without the need\nof a database. Jekyll is the glue to make all this work, and I was able\nto customize Jekyll to my needs, e.g. by using\n[Pandoc](https://pandoc.org/) for the markdown to html conversion.\n\nWhile this workflow still makes sense for this blog, there are a number\nof shortcomings:\n\n- Jekyll needs to rebuild the entire site every time I publish a new\n  post. While this isn't much of a problem for the size of this blog, it\n  doesn't scale well for larger sites. And the process is more complex\n  if you use custom jekyll plugins like this blog, as you can't use the\n  automatic Jekyll pipeline provided by Github (hint: use a Travis\n  continuous integration server [to build the\n  site](https://blog.front-matter.io/posts/continuous-publishing/))\n- the web is moving to increasingly sophisticated javascript frontends,\n  using frameworks such as [Angular.js](https://angularjs.org/),\n  [Ember.js](http://emberjs.com/), or frontend libraries for scholarly\n  documents such as [Lens](http://elifesciences.org/elife-news/lens).\n  While they can be used together with Jekyll, that is not a typical use\n  case.\n- the tight integration between the code to generate the website and the\n  content (Wordpress and other blogging engines have the same approach)\n  is not always the best solution, e.g. when you want to want to\n  generate the pages for something that is not a blog (e.g. a\n  [book](http://book.openingscience.org/)).\n\nWhat could we do instead?\n\n> Build a Javascript frontend where the content is served via an API\n> built around markdown documents, stored in git version control.\n\n### API\n\nThe blog posts are still written in markdown, stored (and\nversion-controlled in a Github repository), but we would now access the\ncontent via API. The easiest solution is to use the [Github Contents\nAPI](https://developer.github.com/v3/repos/contents/) and either do the\nmarkdown to html conversion in javascript yourself, or let the Github\nAPI do the conversion to HTML for you. Alternatively we could build our\nown API, e.g. because we want to control the markdown to html\nconversion, or need additional functionality such as fulltext search.\nAnd of course the two approaches can be combined, e.g. via a Github\nwebhook that triggers the markdown to html conversion every time a\ndocument is added or updated, and stores the converted documents in the\nsame repo.\n\n### Frontend\n\nThe frontend should be written as a one-page javascript application, not\nrequiring a server backend. In contrast to the Jekyll workflow the\nfrontend code doesn't need to be updated every time we post a blog post.\nSince this is a very common scenario, there are probably several\nsolutions out there already. Please mention them in the comments if you\nhave suggestions. One candidate is\n[Lens](https://github.com/elifesciences/lens/) mentioned above - a\nbeautiful frontend for scholarly documents. Lens displays documents in\nthe\n[JATS](http://jats.nlm.nih.gov/publishing/tag-library/1.0/index.html)\nXML format, so your API would have to provide that format.\n\n### Conclusions\n\nThe separation into API and frontend is of course old news. But for\nblogs this seems to still be a fairly new concept, in particular when\ncombined with a backend using documents stored in git version control\nrather than in a database. Wordpress added a [REST API\nPlugin](https://wordpress.org/plugins/json-rest-api/) in 2014, and the\nGhost blogging framework (which uses a database backend) also seems to\n[go into that general\ndirection](https://trello.com/b/EceUgtCL/ghost-roadmap). Please ping me\nif you like the idea and want to contribute, or have implemented\nsomething like this already.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cvzv","guid":"62d42bbd41e317003df48d56","id":"3f9a42ea-2c58-429d-8dfe-54f9f4c912f3","image":"https://blog.front-matter.io/content/images/2022/08/logo-2x.png","indexed_at":1,"language":"en","published_at":1427111400,"reference":[],"relationships":[],"summary":"This blog has been on four different platforms since starting in 2007: a custom blogging engine and then Movable Type on Nature Network 2007-2010, Wordpress on the PLOS Blogs Network 2010-2013, and the static blogging engine Jekyll hosted on Github Pages since 2013. It might be time for yet another blogging platform change.\n","tags":["Feature"],"title":"Blogging Beyond Jekyll","updated_at":1660837303,"url":"https://blog.front-matter.io/posts/blogging-beyond-jekyll"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/introducing-the-scholarly-markdown-bundle","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"Using Markdown to author scholarly documents is an attractive\nalternative to the standard authoring tools Microsoft Word and LaTeX.\nThe feeling shared by many is that [Scholarly\nMarkdown](https://blog.front-matter.io/posts/what-is-scholarly-markdown/)\nis 80% there, and that more effort is needed for the remaining 20% -\nmoving markdown from a niche into the mainstream. What is mainly needed\nis building tools that connect the existing tools and ideas, resulting\nin one or more services attractive to a critical number of users. But\nmaybe we also need to rethink the essential parts of Scholarly Markdown.\nIn this post I propose that we expand the concept and define the\n*Scholarly Markdown Bundle*.\n\nIt is becoming increasingly clear that scholarly work can't be\nadequately described in a single text document, most commonly the\njournal article. Not only are there associated metadata, assets such as\nfigures and supplementary information, but also the research data and\nsoftware needed to produce the work described in the publication. The\nobvious next step is to think of scholarly work as a collection of\nobjects, most clearly described by Carol Goble and others as [Research\nObject Bundle](https://researchobject.github.io/specifications/bundle/).\n\nThere will probably never be a single authoring tool and format that\npleases everyone. Markdown has particular inherent strengths and\nweaknesses, complex math or tables will probably always be easier with\nother formats. The strength of markdown is the simplicity of the format.\nSome things are hard or impossible to do, but many other things are much\nsimpler. Creating a useful markdown editor is much easier than a word\nprocessor reading/writing `docx` format. Markdown is also a perfect\nformat to [work\nwith](https://blog.front-matter.io/posts/using-microsoft-word-with-git/)\nversion control systems such as git.\n\nThis low barrier of entry makes markdown perfect to be integrated into\nmany workflows. And we can go one step further than ePub and Research\nObject Bundle, which use the related Universal Container Format\n([UCF](https://wikidocs.adobe.com/wiki/display/PDFNAV/Universal+Container+Format))\nand ePub Open Container Format\n([OCF](http://www.idpf.org/epub/301/spec/epub-ocf.html)), respectively.\nInstead of using zip to compress a folder into a single file we can use\ngit version control instead: git provides the commands `git bundle` and\n`git archive` to compress a project under version control with or\nwithout version history. I feel this format is both more powerful So I\npropose the *Scholarly Markdown Bundle*:\n\n- a git repository with one or more markdown files, either as a folder,\n  or compressed into a single file using `git bundle`\n- a particular flavor or markdown called Scholarly Markdown, and\n  discussed here and elsewhere before\n- a `citeproc.json` file in the root of the project that contains all\n  metadata relevant to the container, including references\n\nThe `citeproc.json` file is similar to the minimal metadata schema\n[codemeta](https://github.com/mbjones/codemeta) proposed by Matt Jones\nand others, but is in the format used by Pandoc today. This is\n[important](https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/)\nbecause it adds citation parsing support out of the box. The last two\npoints rely on the [Pandoc](http://pandoc.org/) document conversion\ntool, so Scholarly Markdown bundles are really ****markdown**** +\n****Pandoc**** + ****Citeproc/CSL**** + ****git****. The format is\nflexible enough to not only describe scholarly articles, but also other\nkinds of scholarly works, including scientific software managed with git\nversion control. And it integrates nicely with a number of existing\nworkflows, e.g. an R project using RStudio for both code and text (in\nRmarkdown). This format should also work for blogs like this one, but I\nwould have to separate the blog posts from the Jekyll site generator\ncode, a direction I suggested in the\n[last](https://blog.front-matter.io/posts/blogging-beyond-jekyll/) post.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cvzt","guid":"62d42bbd41e317003df48d55","id":"ab30b0b0-887f-4b77-b00d-943c072746d3","image":null,"indexed_at":1,"language":"en","published_at":1429789680,"reference":[],"relationships":[],"summary":"Using Markdown to author scholarly documents is an attractive alternative to the standard authoring tools Microsoft Word and LaTeX. The feeling shared by many is that Scholarly Markdown is 80% there, and that more effort is needed for the remaining 20% - moving markdown from a niche into the mainstream.\n","tags":["Feature"],"title":"Introducing the Scholarly Markdown Bundle","updated_at":1660836284,"url":"https://blog.front-matter.io/posts/introducing-the-scholarly-markdown-bundle"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/happy-third-birthday-nature-network","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"Nature Network turns [3 years old today](https://web.archive.org/web/20120611031820/http://blogs.nature.com/nautilus/2008/02/happy_birthday_nature_network.html), and it has been a very interesting ride. I wasn\\'t around when Nature Network started, but posted by first Gobbledygook blog post (the blog had a different name back then) in August 2007. We passed the [50.000 comments milestone](https://web.archive.org/web/20120611031820/http://network.nature.com/people/U6E5B2CE1/blog/2010/01/26/nature-network-blogs-receives-50-000th-comment) just a few weeks ago. And we were told that big changes to the blogging platform underneath are imminent.\n\nI have had many, many positive experiences in these 2 1/2 years. I learned a lot about science publishing and met a large number of very nice and very clever people both online and offline. I wrote about 160 blog posts and an uncounted number of comments during that time, and writing blog posts is still a lot of fun and something I like doing on a regular basis (I decided a while ago to aim for one blog post per week). I am also excited about the upcoming [Science Online London 2010](https://web.archive.org/web/20120611031820/http://www.scienceonlinelondon.org/) meeting, although the exact date and location have not yet been set.\n\nHappy birthday.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw4m","guid":"62d42bbd41e317003df48def","id":"0e7e2bc0-c5bf-4f2f-bbb7-1da61e6974c9","image":"https://blog.front-matter.io/content/images/2022/08/3276406889_c13486bbfb_o.jpeg","indexed_at":1,"language":"en","published_at":1266105600,"reference":[],"relationships":[],"summary":"Nature Network turns 3 years old today, and it has been a very interesting ride. I wasn't around when Nature Network started, but posted by first Gobbledygook blog post (the blog had a different name back then) in August 2007. We passed the 50.000 comments milestone just a few weeks ago. And we were told that big changes to the blogging platform underneath are imminent. I have had many, many positive experiences in these 2 1/2 years.\n","tags":["News"],"title":"Happy third birthday Nature Network!","updated_at":1660811535,"url":"https://blog.front-matter.io/posts/happy-third-birthday-nature-network"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/there-is-still-so-much-to-learn-in-reference-management","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"Last week [Lambert Heller](https://web.archive.org/web/20120611033209/http://wikify.org/) and myself did a two-day workshop **Reference Management in Times of Web 2.0** for a group of German librarians. We introduced and tested the following five programs:\n\n-   [RefWorks](https://web.archive.org/web/20120611033209/http://www.refworks.com/)\n-   [Zotero](https://web.archive.org/web/20120611033209/http://www.zotero.org/)\n-   [CiteULike](https://web.archive.org/web/20120611033209/http://www.citeulike.org/)\n-   [Mendeley](https://web.archive.org/web/20120611033209/http://www.mendeley.com/)\n-   [Endnote](https://web.archive.org/web/20120611033209/http://www.endnote.com/)\n\nThe goal of the workshop was to introduce the participants to the Web 2.0 aspects of these reference managers. We briefly talked about [Papers](https://web.archive.org/web/20120611033209/http://www.mekentosj.com/papers) and [Citavi](https://web.archive.org/web/20120611033209/http://www.citavi.com/), but neither of them offers any Web 2.0 functionality. The goal of the workshop was **not** to pick the best reference manager. With the exception of **CiteULike** (which is more of a social bookmarking service and can\\'t be used to directly put references into manuscripts), all of them are probably good choices for most users. For some of the minor differences, please check my reference manager chart that I have updated for the workshop (PDF [here](https://web.archive.org/web/20120611033209/http://www.slideshare.net/mfenner/reference-manager-overview-2-1-3250074)):\n\n<figure class=\"kg-card kg-image-card\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/Reference-Manager-Overview-1.jpg\" class=\"kg-image\" loading=\"lazy\" width=\"472\" height=\"643\" />\n</figure>\n\nWe had used FriendFeed for the slides, links and comments in a [similar workshop last July](https://web.archive.org/web/20120611033209/http://friendfeed.com/bibman2). This time we picked [ScienceFeed](https://web.archive.org/web/20120611033209/http://www.sciencefeed.com/), both because ScienceFeed can be used for reference management, and to test the service that launched just three days earlier. The ScienceFeed group can be found [here](https://web.archive.org/web/20120611033209/http://www.sciencefeed.com/zblit2), but is in German. FriendFeed and ScienceFeed are not only great for conference microblogging, but are also excellent teaching tools, especially in a workshop where every participant has an internet-connected computer. We also had a few people listening in and putting up comments.\n\nThe workshop did help me understand what could become one of the most important features of reference managers. (I would exclude **Endnote** because it doesn\\'t allow public groups or sharing of full-text files). Libraries used to be places where you could find, store and read literature. A library would hold a subset of all the available literature, but still, far more texts than an individual could keep at his home. A library serves as an intermediary that helps the user get access to the literature he is interested in.\n\nA reference manager that stores all references and the associated full-text PDF files in an accessible (public or password-protected) place can fullfill exactly the same role. It is not necessary that an individual user stores every reference and fulltext paper on his own computer. And he doesn\\'t have to find all references for himself. Librarians could help with this, e.g. by not only handling a users search request but also filing the associated PDF files in a group folder. Other group folders would have the table of contents of your favorite journals (e.g. [CiteULike Journals](https://web.archive.org/web/20120611033209/http://www.citeulike.org/journals)). We used to go to the library for exactly these things. And now we do this all on our own, often not asking for help from our local library.\n\nIn the last session I talked about non-traditional ways to find scientific literature. Traditional would mean one of the following search strategies, summarized by Duncan Hull et al.^[1](https://web.archive.org/web/20120611033209/http://blogs.plos.org/mfenner/2010/02/22/there_is_still_so_much_to_learn_in_reference_management/#fn1)^:\n\n-   **Search** -- Search bibliographic databases\n-   **Browse** -- Scan tables of contents\n-   Recommend -- Recommendations by colleagues\n\n**Twitter** is just a modern tool for strategies **#2** (check the Twitter list [\\@mfenner/science-journals](https://web.archive.org/web/20120611033209/http://twitter.com/mfenner/science-journals) for some science journals using Twitter to announce interesting articles) and **#3** (papers recommended by friends you talk to via Twitter).\n\nThe non-traditional approach basically lets other people do the work for you. Some examples include:\n\n-   Experts pick noteworthy papers in your field -- [Faculty of 1000](https://web.archive.org/web/20120611033209/http://www.f1000.com/) and [Research Blogging](https://web.archive.org/web/20120611033209/http://www.researchblogging.org/).\n-   You follow what people with similar interests are reading -- **CiteULike** and **Mendeley**\n-   Recommendations based on what is in your library -- [CiteULike recommendations](https://web.archive.org/web/20120611033209/http://blog.citeulike.org/?p=136)\n-   Most popular articles in your research field of interest -- **CiteULike** and **Mendeley**. The **PLoS** [article-level metrics](https://web.archive.org/web/20120611033209/http://www.plos.org/cms/node/485) have the potential to do the same.\n\n### References\n\n**Hull D, Pettifer SR, Kell DB.** Defrosting the digital library: bibliographic tools for the next generation web. **PLoS Computational Biology**. 2008 https://doi.org/[10.1371/journal.pcbi.1000204](https://web.archive.org/web/20120611033209/http://dx.doi.org/10.1371/journal.pcbi.1000204)\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw4j","guid":"62d42bbd41e317003df48ded","id":"d30e7a2f-31ed-4145-8c50-530e2a318459","image":"https://blog.front-matter.io/content/images/2022/08/2587796561_36fea74569-1.jpg","indexed_at":1,"language":"en","published_at":1266796800,"reference":[{"key":"ref1","url":"https://web.archive.org/web/20120611033209/http:/dx.doi.org/10.1371/journal.pcbi.1000204"}],"relationships":[],"summary":"Last week Lambert Heller and myself did a two-day workshop\n<em>\n <em>\n  Reference Management in Times of Web 2.0\n </em>\n</em>\nfor a group of German librarians. We introduced and tested the following five programs:RefWorksZoteroCiteULikeMendeleyEndnote The goal of the workshop was to introduce the participants to the Web 2.0 aspects of these reference managers.\n","tags":["Meeting Report"],"title":"There is still so much to learn in reference management","updated_at":1660811425,"url":"https://blog.front-matter.io/posts/there-is-still-so-much-to-learn-in-reference-management"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/german-research-foundation-says-that-numbers-arent-everything","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"Last Tuesday the **German Research Foundation** (DFG) [announced](https://web.archive.org/web/20120611102053/http://www.dfg.de/en/service/press/press_releases/2010/pressemitteilung_nr_07/index.html) changes to the grant application process, going in effect in July. Researchers are no longer allowed to list all their publications in their grant proposals. The number of publications is limited to five per researcher and to two per year of planned funding (e.g. 6 papers for a 3-year grant). Publications submitted but not yet accepted for publication will no longer be allowed.\n\nSome of the reasoning behind this change was explained in the press conference where the policy change was announced. The DFG wants to put more emphasis on quality instead of quantity, in other words counteract the trend to publish several small pieces of incremental research findings (the [least publishable unit](https://web.archive.org/web/20120611102053/http://scienceblogs.com/drugmonkey/2009/01/repost_thoughts_on_the_least_p.php) or **LPU**). The DFG didn\\'t say so, but this might also reduce the practice of \"honorary coauthorship\" with some researchers being coauthors of 20 or even 50 papers per year. And the DFG is not happy with the increasing use of the Journal Impact Factor and other metrics as a token measure for the quality of research output. And as a reaction to problems with publication lists in [G&Atilde;\u00b6ttingen](https://web.archive.org/web/20120611102053/http://www.spiegel.de/unispiegel/studium/0,1518,622474,00.html) they want to stop the practice of including unpublished work in reference lists for grant applications.\n\nThese changes will decrease the administrative workload of the applicant, reviewer and the DFG. With much shorter reference lists in grant applications, reviewers will have it much easier to take a closer look at the research output of the applicant, instead of relying on an unfortunate proxy such as the **Journal Impact Factor**. Researchers seeking funding from the DFG will now probably be more likely to write fewer but more substantial papers. And research that doesn\\'t have the potential for a substantial paper, but is nevertheless worth publishing, can be quickly published in a reasonable journal instead of going through several rounds of submissions to a number of journals.\n\nBut how do you select your five best publications (assuming you have written more than five)? Choices include:\n\n-   publication date, e.g. a list of the five most recent publications\n-   Journal Impact Factor\n-   citation counts, page views, downloads or other article-level metrics\n-   personal preference\n\nUsing my personal preference (and not too much thought), I picked four papers and one correspondence:\n\n-   **Shioda T, Fenner MH, Isselbacher KJ** Msg1, a novel melanocyte-specific gene, encodes a nuclear protein and is associated with pigmentation. **PNAS** 1996 [PubMed Central](https://web.archive.org/web/20120611102053/http://www.ncbi.nlm.nih.gov/pmc/articles/PMC37985/?tool=pubmed)\\\n    The first paper from my postdoctoral research project. We identified and cloned a new gene thought to be involved in cancer metastasis, using a technology called differential display to compare the gene expression profile of two melanoma cell lines. This was before the mouse and human genomes were sequenced, and before microarrays became available. What took us two years of work 15 years ago can now probably be done in a few weeks.\n-   **Sado T, Fenner MH, Tan SS Tam P, Shioda T, Li E** X Inactivation in the Mouse Embryo Deficient for Dnmt1: Distinct Effect of Hypomethylation on Imprinted and Random X Inactivation. **Dev Biol** 2000 [doi:10.1006/dbio.2000.9823](https://web.archive.org/web/20120611102053/http://dx.doi.org/10.1006/dbio.2000.9823)\\\n    I spent most of my time as a post-doc generating a knockout mouse for the gene identified in the previous paper. As the knockout mouse had no obvious phenotype, it took another post-doc (the first author) to finish the project.\n-   **Krege S et al.** European consensus conference on diagnosis and treatment of germ cell cancer: a report of the second meeting of the European Germ Cell Cancer Consensus group (EGCCCG): part I. **Eur Urol** 2008 [doi:10.1016/j.eururo.2007.12.024](https://web.archive.org/web/20120611102053/http://dx.doi.org/10.1016/j.eururo.2007.12.024)\\\n    This paper summarizes the conclusions of a consensus conference on the diagnosis and treatment of testicular cancer, and is the best review on the subject. I am one of over 80 coauthors, something I haven\\'t done before or since. The journal published this as two papers because of length. This would have been a perfect paper for an Open Access journal, I hope I can convince the coauthors to do so when we update this in 2011.\n-   **Fenner MH, Beutel G, Gruenwald V.** Targeted therapies for patients with germ cell tumors. **Expert Opin Investig Drugs** 2008 [doi:10.1517/13543784.17.4.511](https://web.archive.org/web/20120611102053/http://dx.doi.org/10.1517/13543784.17.4.511)\\\n    Testicular cancer is one of the few chemotherapy success stories, as most patients with advanced metastatic disease can be cured. Targeted therapies have become important treatment options in many cancers. This is the first review to look at the evidence for the use of targeted therapies in testicular cancer.\n-   **Fenner MH.** Duplication: stop favouring applicant with longest list. **Nature** 2008 [doi:10.1038/452029a](https://web.archive.org/web/20120611102053/http://dx.doi.org/10.1038/452029a)\\\n    This is a **Nature** correspondence, included here only to show that comments made in a Nature Network forum can end up in **Nature**. And because it is relevant to this blog post, as I suggested to **ask applicants to select their best three, five or ten papers** instead of giving grants or jobs to those with the longest publication list.\n\nThe Wellcome Trust last year [announced](https://web.archive.org/web/20120611102053/http://www.wellcome.ac.uk/Funding/investigator-awards/Implementation/index.htm) a different change to they grant application process. Starting later this year, they will stop accepting proposals for project grants, and rather evaluate the reaseach output of the scientist asking for funding (**Investigator Awards**). They argue that researchers that alrady have shown excellence in the past shoudn\\'t be burdened with the administrative overhead and restrictions of writing a detailed project proposal every three years.\n\nIt will be interesting to see how institutions and other research funders in Germany (e.g. [Helmholtz](https://web.archive.org/web/20120611102053/http://www.helmholtz.de/en/) or [Leibniz](https://web.archive.org/web/20120611102053/http://www.wgl.de/)) or elsewhere react to this DFG policy change. I would be happy if this is a step towards more reasonable publication policies. And I hope that the upcoming unique author identifier [ORCID](https://web.archive.org/web/20120611102053/http://www.orcid.org/) will not be used for even more complicated bibliometric calculations, but rather as a tool for researchers to showcase their most interesting work.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw4v","guid":"62d42bbd41e317003df48df6","id":"459e57cd-6b12-47ee-96bd-65e633f8bff6","image":"https://blog.front-matter.io/content/images/2022/08/76463757_24a1858d2e_m.jpeg","indexed_at":1,"language":"en","published_at":1267401600,"reference":[],"relationships":[],"summary":"Last Tuesday the\n<em>\n <em>\n  German Research Foundation\n </em>\n</em>\n(DFG) announced changes to the grant application process, going in effect in July. Researchers are no longer allowed to list all their publications in their grant proposals.\n","tags":["News"],"title":"German Research Foundation says that numbers aren\u2019t everything","updated_at":1660811263,"url":"https://blog.front-matter.io/posts/german-research-foundation-says-that-numbers-arent-everything"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/how-do-researchers-use-online-journals","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"<figure class=\"kg-card kg-image-card\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/rb2_large_gray-3.png\" class=\"kg-image\" loading=\"lazy\" width=\"70\" height=\"85\" alt=\"ResearchBlogging.org\" />\n</figure>\n\nLast Monday I was listening to a very interesting presentation by [Ian Rowlands](https://web.archive.org/web/20120611102310/http://www.ucl.ac.uk/infostudies/ian-rowlands/), reader in scholarly communication in the [Department of Information Studies](https://web.archive.org/web/20120611102310/http://www.infostudies.ucl.ac.uk/) at University College London. He and his colleagues are interested in how researchers find and use information, and how this has changed with the internet, especially for the [Google Generation](https://web.archive.org/web/20120611102310/http://www.jisc.ac.uk/whatwedo/programmes/resourcediscovery/googlegen.aspx) (people born after 1993). If you want to be part in this research (and have some fun), you can take part in the [BBC Web Behaviour Test](https://www.bbc.co.uk/labuk/experiments/webbehaviour). The test will help you discover which species of web animal you are (I\\'m a ****fox****).\n\nIn another project, funded by the Research Information Network ([RIN](https://web.archive.org/web/20120611102310/http://www.rin.ac.uk/)), Ian and his colleagues are studying how researchers are using electronic journals. The findings of the first part of the project were presented and discussed in a [workshop last July](https://web.archive.org/web/20120611102310/http://www.rin.ac.uk/news/events/e-journals-revolution-how-use-scholarly-journals-shaping-research). The presentations are available as PDF download, and as [podcast](https://web.archive.org/web/20120611102310/http://www.rin.ac.uk/resources/rin-publications/podcasts/e-journals-revolution-podcast) with interviews of the speakers. The findings were summarized in a paper also published last July: ****Online use and information seeking behaviour: institutional and subject comparisons of UK researchers****.\n\nIn the paper, the use of [Oxford Journals](https://web.archive.org/web/20120611102310/http://www.oxfordjournals.org/) by 10 major UK research institutions was analyzed in the fields of life sciences, economics and history, using the server logs for the full year 2007. Some of the key findings of the study include:\n\n### One third of users access Oxford Journals outside business hours\n\n9.7% of uses happened on a Saturday/Sunday and 30.1% between 6 PM and 9 AM. This means that about one third of users accessed Oxford Journals outside typical business hours, either working late or from home (the study didn\\'t distinguish between these two). These numbers indicate that remote access (from home, but probably also when traveling) is important for many users. This is obviously not an issue for Open Access journals, but institutions need to provide practical solutions ([VPN](https://web.archive.org/web/20120611102310/http://en.wikipedia.org/wiki/Virtual_private_network), etc.) for subscription journals. From personal experience this remote access is still overly complicated. And these numbers also mean that librarians will not be available for support questions one third of the time.\n\n### Around 40% of sessions originated from a Google Search\n\nIn 2004 Oxford Journals opened up to Google for indexing. I didn\\'t expect this important role that Google seems to play in finding scholarly papers, and I would be very interested in feedback from blog readers. Only 4% of sessions originated from Google Scholar (22% in economics). These results probably explain why Google Scholar hasn\\'t seen that much development since it was launched. The search function at Oxford Journals was rarely used.\n\n43% of users of history journals, but only 16% of users of life sciences journals used navigational tools (table of contents, etc.) provided by the journal. This statistic obviously doesn\\'t look at users getting the table of contents via email or RSS, but it again shows that access via search now probably is more common than via browsing.^[1](https://web.archive.org/web/20120611102310/http://blogs.plos.org/mfenner/2010/03/08/evaluating_usage_patterns_of_online_journals/#fn1)^\n\n### Most users spend little time on journal webpages, but return often\n\nThe average number of articles viewed per session was 1.1, and the average session time was just over 4 minutes. Users rather return often, usually via a search. These numbers indicate that journal webpages are not a place where users spend a lot of time. Unless journals change this (e.g. by more active involvement of users via comments and other social networking features, etc.), they probably can\\'t expect to generate significant revenue from online advertising. The internet has not only dramatically changed the role of [libraries](https://web.archive.org/web/20120611102310/http://blogs.nature.com/mfenner/2010/01/24/scientists-and-librarians-friend-or-foe), but also for journals, as users are mostly interested in single articles, rather than the journal as a whole.\n\n### The median age of articles was 48 months (life sciences), 73 months (economics), and 90 months (history) {#the-median-age-of-articles-was-48-months-life-sciences-73-months-economics-and-90-months-history-}\n\nIn the life sciences only 25% of the articles were no more than 16 months old, but another 25% were over 104 months old. I would have expected that the median age of articles would be much lower in the life sciences (it was two years in a similar study with ScienceDirect[2](https://web.archive.org/web/20120611102310/http://blogs.plos.org/mfenner/2010/03/08/evaluating_usage_patterns_of_online_journals/#fn2)). It seems as if most papers are not accessed when they are published (in the first few months after publication), but rather as the result of a search strategy, e.g. when writing a paper.\n\n### Life sciences users rarely read abstracts on publisher platforms\n\nThis should not come as a surprise, as life sciences users typically read abstracts in specialized databases, particularly ****PubMed****. But maybe Journal publishers should stop displaying papers in an abstract view, saving users and themselves some effort. **PLoS** journals don\\'t have an abstract view, but the **Biomed Central** journals (which are also Open Access) do. Subscription journals (including **Nature**) typically display the abstract instead of full-text to users without subscription access, so there is also no need for a separate abstract view for them.\n\nThe number of PDF views was higher than the number of full-text HTML views (178,152 vs. 106,582). This difference was much more pronounced in economics and history journals, probably indicating that here most papers were printed out and [not read on the computer](https://web.archive.org/web/20120611102310/http://blogs.nature.com/mfenner/2010/01/10/how-do-you-read-papers-2010-will-be-different).\n\n## References\n\nNicholas, D., Clark, D., Rowlands, I., & Jamali, H. (2009). Online use and information seeking behaviour: institutional and subject comparisons of UK researchers *Journal of Information Science, 35* (6), 660-676 https://doi.org/[10.1177/0165551509338341](https://web.archive.org/web/20120611102310/http://dx.doi.org/10.1177/0165551509338341)\n\n^1^ My July 2008 blog post [Do online journals narrow science and scholarship?](https://front-matter.io/mfenner/do-online-journals-narrow-science-and-scholarship) discussed potential consequences.\n\n^2^ CIBER, Evaluating the usage and impact of e-journals in the UK. Working paper 5. Available at [http://www.ucl.ac.uk/infostudies/research/ciber/](https://web.archive.org/web/20120611102310/http://www.ucl.ac.uk/infostudies/research/ciber/)\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw4t","guid":"62d42bbd41e317003df48df5","id":"f6615c01-e956-4b94-ba97-2bf616a1dad7","image":"https://blog.front-matter.io/content/images/2022/08/17071467_11820b826c.jpeg","indexed_at":1,"language":"en","published_at":1268006400,"reference":[{"key":"ref1","url":"https://web.archive.org/web/20120611102310/http:/dx.doi.org/10.1177/0165551509338341"},{"key":"ref2","url":"https://front-matter.io/mfenner/do-online-journals-narrow-science-and-scholarship"},{"key":"ref3","url":"https://web.archive.org/web/20120611102310/http:/www.ucl.ac.uk/infostudies/research/ciber"}],"relationships":[],"summary":"Last Monday I was listening to a very interesting presentation by Ian Rowlands, reader in scholarly communication in the Department of Information Studies at University College London.\n","tags":["Feature"],"title":"How do researchers use online journals?","updated_at":1660811136,"url":"https://blog.front-matter.io/posts/how-do-researchers-use-online-journals"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/standards-for-the-conduct-of-science-in-the-information-age","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"Assuming our airports are again open next weekend, I will be attending a meeting organized by the [NSF](https://web.archive.org/web/20120611093752/http://www.nsf.gov/) (National Science Foundation) and [EuroHORCS](https://web.archive.org/web/20120611093752/http://www.eurohorcs.org/E/Pages/home.aspx) (European Heads of Research Councils) on **Changing the Conduct of Science in the Information Age** in Washington on April 26. We have been asked to submit a one page white paper in advance of the meeting.^[1](https://web.archive.org/web/20120611093752/http://blogs.plos.org/mfenner/2010/04/17/improving_the_conduct_of_science/#fn1)^ I decided to focus on the importance of standards, obviously leaving out many other important technological and social aspects. But defining and adhering to standards will enable or enhance a number of very interesting ways to conduct and report science in the information age.\n\nImproving the conduct of science through digital technology requires standards for linking to and formatting scholarly resources. These standards should be coordinated by independent organizations that are not restricted to geographic areas or particular research domains.\n\n### Data access\n\nDigital Object Identifiers ([DOIs](https://web.archive.org/web/20120611093752/http://www.doi.org/)) are the primary system to link to digital content. The International [DataCite](https://web.archive.org/web/20120611093752/http://www.datacite.org/) initiative is the DOI registration agency for scientific primary data. Although there are many uses of DOIs for primary research data (e.g. [PANGAEA](https://web.archive.org/web/20120611093752/http://www.pangaea.de/), earth system research), many systems still use different identifiers.\\\nResearch funders and journals working in specific domains should collaborate on standards and best practices for primary research datasets, and journal publishers should encourage or even require linking to research datasets from publications. Successful examples include [GenBank](https://web.archive.org/web/20120611093752/http://www.ncbi.nlm.nih.gov/genbank/) (genetic sequences) and [MIAME](https://web.archive.org/web/20120611093752/http://www.mged.org/Workgroups/MIAME/miame.html) (microarray gene expression).\n\n### Knowledge access\n\nDOIs have become the standard identifier for electronic scholarly publications and are managed by the [CrossRef](https://web.archive.org/web/20120611093752/http://www.crossref.org/) registration agency. Journal articles, databases and websites linking to scholarly publications should use DOIs whenever possible instead of internal identifiers such as the PubMed ID or direct links to publisher webpages. Publishers should implement citation styles that use the DOI instead of volume, issue and page numbers.\\\nThe [NLM DTD](https://web.archive.org/web/20120611093752/http://dtd.nlm.nih.gov/) is the standard format used by PubMed Central and many scholarly publishers to produce content for reading in the HTML, PDF or ePub formats. The [Article Authoring Add-in for Microsoft Office Word](https://web.archive.org/web/20120611093752/http://www.microsoft.com/mscorp/tc/scholarly_communication.mspx) and [Lemon8-XML](https://web.archive.org/web/20120611093752/http://pkp.sfu.ca/lemon8) allow researchers to produce content in the NLM DTD format. The workflow of writing, reviewing and publishing scientific papers should be based completely on the NLM DTD and tools for collaborative writing, journal submission and peer review should be build around that format.\n\n### Attribution\n\nThe recently announced[2](https://web.archive.org/web/20120611093752/http://blogs.plos.org/mfenner/2010/04/17/improving_the_conduct_of_science/#fn2) Open Researcher and Contributor ID ([ORCID](https://web.archive.org/web/20120611093752/http://www.orcid.org/)) is one of many initiatives for a unique researcher identifier, but has probably the broadest support among institutions, publishers and research organizations. ORCID will be managed by an independent non-profit organization, and will allow the exchange of profiles with other researcher identifier systems such as those used by [Scopus](https://web.archive.org/web/20120611093752/http://www.scopus.com/), [RePEc](https://web.archive.org/web/20120611093752/http://repec.org/), or [Inspire](https://web.archive.org/web/20120611093752/https://twiki.cern.ch/twiki/bin/view/Inspire/WebHome).\\\nThe information in the author profile may be initially provided by an institution, society or publisher, but should eventually be claimed by the individual researcher because of privacy concerns and because automated author disambiguation is never 100% accurate. Attribution should include all aspects of scholarly activity, including curation of primary research datasets and peer review.\\\nThe Public Library of Science (PLoS) [article-level metrics](https://web.archive.org/web/20120611093752/http://article-level-metrics.plos.org/) make available comprehensive information (citations, downloads, social bookmarks, comments, etc.) with every published article. This system should be linked to author identifiers and developed into a standard for scholarly resources. Other scholarly publishers and databases for primary research data should then adopt these metrics.\n\nfn1. Cameron Neylon\\'s draft white paper is [here](https://web.archive.org/web/20120611093752/http://cameronneylon.net/blog/draft-white-paper-researcher-identifiers/).\n\nfn2. Interestingly both DataCite and ORCID were first announced December 1, 2009 at two independent events in London (press releases [here](https://web.archive.org/web/20120611093752/http://www.tib-hannover.de/en/the-tib/news/news/id/133/) and [here](https://web.archive.org/web/20120611093752/http://orcid.org/media/pdf/ORCID_Announcement.pdf)).\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw4x","guid":"62d42bbd41e317003df48df8","id":"acafe9ef-0995-4fb5-b715-81bfe2330503","image":"https://blog.front-matter.io/content/images/2022/08/3429599200_2f54dbd5cd.jpeg","indexed_at":1,"language":"en","published_at":1271462400,"reference":[],"relationships":[],"summary":"Assuming our airports are again open next weekend, I will be attending a meeting organized by the NSF (National Science Foundation) and EuroHORCS (European Heads of Research Councils) on\n<em>\n <em>\n  Changing the Conduct of Science in the Information Age\n </em>\n</em>\nin Washington on April 26. We have been asked to submit a one page white paper in advance of the meeting.\n<sup>\n 1\n</sup>\nI decided to focus on the importance of standards, obviously leaving\n","tags":["Meeting Report"],"title":"Standards for the Conduct of Science in the Information Age","updated_at":1660810246,"url":"https://blog.front-matter.io/posts/standards-for-the-conduct-of-science-in-the-information-age"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/bibapp-mashups-for-universities","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"Friday afternoon discussions can be dangerous. Last Friday I talked with [Heinz Pampel](https://web.archive.org/web/20120611032822/http://network.nature.com/people/UC0402CE6/profile) from the [Helmholtz Open Access Initiative](https://web.archive.org/web/20120611032822/http://oa.helmholtz.de/index.php?id=137) via email about the upcoming [BibCamp Hannover](https://web.archive.org/web/20120611032822/http://bibcamp.wordpress.com/) (a barcamp for librarians and others interested in online science that will take place this weekend). I said that I was looking for a solution to make the list of publications from our institution more accessible -- we currently store them in a regularly updated [RefWorks database](https://web.archive.org/web/20120611032822/http://www.refworks.com/refshare/?site=047931198224000000%2F). Heinz not only told me that there is actually a name for this kind of tool (Current Research Information System or [CIRS](https://web.archive.org/web/20120611032822/http://www.cris2010.org/)), but also gave me some good links. [This talk](https://web.archive.org/web/20120611032822/http://espace.library.uq.edu.au/eserv/UQ:152805/Simon_Porter.pdf) by Simon Porter from the University of Melbourne is for example a very good introduction to the topic.\n\nHeinz also suggested [BibApp](https://web.archive.org/web/20120611032822/http://bibapp.org/), a nice web-based tool for exactly this purpose written in the **Ruby on Rails** programming language. Because I am a [very familiar with Ruby on Rails](https://web.archive.org/web/20120611032822/http://www.mh-hannover.de/studien/en/), I took a closer look.\n\n[Bibapp -- Find Campus Experts](https://web.archive.org/web/20120611032822/http://vimeo.com/2104723) from [Eric Larson](https://web.archive.org/web/20120611032822/http://vimeo.com/user885968) on [Vimeo](https://web.archive.org/web/20120611032822/http://vimeo.com/).\n\nIn the end I spent a good deal of this weekend setting up **BibApp**, importing all publications from our institution since 2008 via **Refworks**, starting to add researchers and research groups and adjusting **BibApp** to our needs (mainly changing the layout to our institution style and starting to translate the templates into German). **BibApp** is already a fully working system and is telling me some interesting things. This includes many interesting papers from our institution that I didn\\'t know about, but also that two researchers each have published more than 150 papers in two years, and that my colleagues have published 6 papers in [Medical Hypotheses](https://web.archive.org/web/20120611032822/http://www.timeshighereducation.co.uk/story.asp?storycode=411168) since 2008. The technical aspects of setting up **BibApp** are almost solved (it helps that I run two other **Ruby on Rails** applications at my institution), so now I have to convince our library and administration that it\\'s worth having (and maintaining) such a CRIS tool.\n\n[Two weeks ago I wrote about the upper part of the figure](https://web.archive.org/web/20120611032822/http://blogs.nature.com/mfenner/2010/04/17/improving-the-conduct-of-science) (for a **NSF** workshop that got postponed to September because of the Volcano ash). As far as I can see, there is no standard between funding agencies for grant reporting, and both DataCite and ORCID are fairly new initiatives.\n\nThe CRIS can be used to facilitate access to institutional repositories or primary research datasets. **BibApp** supports the [SWORD](https://web.archive.org/web/20120611032822/http://www.ariadne.ac.uk/issue54/allinson-et-al/) protocol for article deposition, and it automatically checks all papers against the [ROMEO](https://web.archive.org/web/20120611032822/http://www.sherpa.ac.uk/romeo/) database of publisher copyright policies. A CRIS is a great discovery tool and it can be further enhanced by integration with social networking tools (e.g. with the [new Nature Network](https://web.archive.org/web/20120611032822/http://blogs.nature.com/u6e5b2ce1/2010/04/28/coming-soon-all-new-nature-network) or the [Mendeley API](https://web.archive.org/web/20120611032822/http://www.mendeley.com/blog/press-release/announcing-mendeley-open-api/) both announced a few days ago).\n\nThe main interest of administrations if of course evaluation of research output. A CRIS can be used to do exactly that, and it has two advantages: a) it can automate some of the processes that are currently done manually by researchers (regularly collecting and reporting information about grants and publications), and b) it is a great platform to develop new tools for the evaluation of scientific output. My institution currently evaluates using the **Impact Factor** of the published papers, and takes first and last authorship (and female authors) into consideration. A CRIS would allow an institution to use similar tools as the [PLoS Article-Level Metrics](https://web.archive.org/web/20120611032822/http://www.plosone.org/static/almInfo.action) (usage data, citation data, usage by social networking tools) instead of the **Impact Factor**, and several projects are already trying some of that, e.g. the German [Open Access Statistics](https://web.archive.org/web/20120611032822/http://www.dini.de/projekte/oa-statistik/english/) project.\n\nBut the best thing about CRIS tools in general, and **BibApp** in particular, is that they add a lot of value for relatively little effort. Universities don\\'t want to (and can\\'t) compete with large institutions or companies such as scientific publishers. Because they basically just integrate the data that are already available in an intelligent way (Mashup in Web 2.0 language), they require a reasonable effort to maintain. This will be particularly true once the [ORCID](https://web.archive.org/web/20120611032822/http://www.orcid.org/) system of unique author identifiers is in place, because author disambiguation is currently one of the most time-consuming aspects (even though **BibApp** is pretty smart about this). I\\'m looking forward to adapt **BibApp** to the **ORCID** prototype system that is planned for this summer.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw50","guid":"62d42bbd41e317003df48dfb","id":"dcfd383e-028d-4c5e-9c71-b61f0a986020","image":"https://blog.front-matter.io/content/images/2022/08/4572784486_52fff91a71.jpeg","indexed_at":1,"language":"en","published_at":1272844800,"reference":[],"relationships":[],"summary":"Friday afternoon discussions can be dangerous.\n","tags":["Feature"],"title":"BibApp: Mashups for Universities","updated_at":1660810130,"url":"https://blog.front-matter.io/posts/bibapp-mashups-for-universities"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/on-privacy","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"Social media and privacy have a complicated relationship, as using social media implies giving up at least some privacy. And the value of a social networking site is directly related not only to the number of users, but also the extend of personal data that the site has collected. All this is of course not unique to social networking tools for scientists, but conducting science using online tools is different from connecting to friends or people with similar personal interests with these tools. One area where privacy issues are particularly prominent is the creation of unique identifiers for scientists, and here I\\'m involved in the [ORCID](https://web.archive.org/web/20120611031846/http://www.orcid.org/) initiative. We need a discussion about required privacy standards, and about the limitations of privacy that we accept in order to increase our scientific productivity.\n\nI\\'ve collected a couple of thoughts below. They are of course only starting points for a discussion, and I welcome any comments and suggestions.\n\n### 1. The service allows anonymous access {#1-the-service-allows-anonymous-access}\n\nSocial networking sites for scientists can be quite useful for anonymous users, e.g. for reading of blog or forum posts. Users should not be required to sign up for a service just for reading a public message or looking at the public part of a user profile. Many social networking sites unfortunately require a user account these activities, and they often nag users to \"complete their personal profiles\", i.e. to provide as much personal information as possible.\n\n### 2. The service has a privacy policy {#2-the-service-has-a-privacy-policy}\n\nI\\'ve randomly checked five social networking sites for scientists, and they all provide a privacy policy:\n\n-   [Academia.edu](https://web.archive.org/web/20120611031846/http://www.academia.edu/privacy)\n-   [CiteULike](https://web.archive.org/web/20120611031846/http://www.citeulike.org/privacy)\n-   [Mendeley](https://web.archive.org/web/20120611031846/http://www.mendeley.com/privacy/)\n-   [Nature Network](https://web.archive.org/web/20120611031846/http://network.nature.com/site/privacy)\n-   [ResearchGate](https://web.archive.org/web/20120611031846/http://www.researchgate.net/application.PrivacyPolicy.html)\n\nThe privacy policy should make clear what user data the service is collecting, whether the service is providing these user data to third parties, and should provide an email address for further privacy questions.\n\n### 3. Personal data are owned by the user {#3-personal-data-are-owned-by-the-user}\n\nAll personal data that a user uploads should be owned by the user, and the privacy policy should make this clear. This implies that a user should be allowed to cancel an account and delete all personal information (surprisingly difficult with most social networking sites), and that the user decides which part of the personal data is shared with others, and with whom.\n\nTo give users control over their privacy settings, these settings should default to not being public for everything beyond the most basic information, and they should not change over time ([The Evolution of privacy on Facebook](https://web.archive.org/web/20120611031846/http://mattmckeon.com/facebook-privacy/)).\n\nObviously, there is a large grey area. If I comment on a blog post by someone else, who owns this comment, and who should be allowed to delete this comment -- me, the author of the blog post, and/or the provider of the social networking site? And who owns my usage data of a service, how often I logged in, my activity in the service, etc.?\n\n### 4. The service protects the user data {#4-the-service-protects-the-user-data}\n\nThe social networking site should make all efforts necessary to protect the personal data of a user. There are examples where this has gone wrong, and this includes examples involving scientists ([Fake Facebook pages spin web of deceit](https://web.archive.org/web/20120611031846/http://www.nature.com/news/2009/090423/full/news.2009.398.html)).\n\n**Update 5/25/10: I didn\\'t see it when I wrote the post, but last week the Electronic Frontier Foundation published a [Bill of Privacy Rights for Social Network Users](https://web.archive.org/web/20120611031846/http://www.eff.org/deeplinks/2010/05/bill-privacy-rights-social-network-users) (thanks to Renny Guida for the link).**\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw53","guid":"62d42bbd41e317003df48dfe","id":"46bf9220-78f4-4e98-ba0b-85ade1e48eea","image":"https://blog.front-matter.io/content/images/2022/08/2404940312_e759c4030d.jpeg","indexed_at":1,"language":"en","published_at":1274659200,"reference":[],"relationships":[],"summary":"Social media and privacy have a complicated relationship, as using social media implies giving up at least some privacy. And the value of a social networking site is directly related not only to the number of users, but also the extend of personal data that the site has collected.\n","tags":["Feature"],"title":"On Privacy","updated_at":1660809897,"url":"https://blog.front-matter.io/posts/on-privacy"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/yet-another-look-at-blogging-networks","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"The last few days we have seen a number of blog posts reflecting on the pros and cons of science blogging networks. Bora Zivkovic last week announced his departure from scienceblogs.com, and in his must-read post reflected on the history of science blogging ([A Farewell to Scienceblogs: the Changing Science Blogging Ecosystem](https://web.archive.org/web/20120611102940/http://scienceblogs.com/clock/2010/07/scienceblogs_and_me_and_the_ch.php)). Richard Grant on Saturday wrote down his thoughts [On Nature Network](https://web.archive.org/web/20120611102940/http://blogs.nature.com/rpg/2010/07/24/on-nature-network). Cameron Neylon draws an interesting parallel between science networks and scientific journals ([The Nature of Science Blog Networks](https://web.archive.org/web/20120611102940/http://cameronneylon.net/blog/the-nature-of-science-blog-networks/)). And Katherine Haxton compared her experience blogging on Nature Network vs. blogging on her own blog ([Science Blogging Networks](https://web.archive.org/web/20120611102940/http://www.possibilitiesendless.com/?p=270)).\n\nMy thoughts on this: it\\'s complicated. I don\\'t see how blogging networks (or any particular network) can be inherently better or worse than setting up your own blog. It\\'s an individual decision. Right now I like to write as part of a blogging network. But I may change my mind and write for a different network, or on an individually hosted blog. I would like to add three considerations to the discussion.\n\n### Consider institutional blogs\n\nWe shouldn\\'t forget that there is also a third alternative to blogging networks and individually hosted blogs: a blog hosted by your institution. An institutional blog has a different set of advantages and disadvantages and is therefore not the right choice for everybody. But I will soon start an official blog for the cancer center of my medical school (I\\'ve gotten the green light from administration and the PR department, the WordPress 3.0 test system is set up, but it probably will be a few weeks before the first post). I have no intentions stopping the Gobbledygook blog -- the new blog will have a different focus, and it will be in German. [Richard](https://web.archive.org/web/20120611102940/http://network.nature.com/profile/rpg) have written institutional blogs for years, but this will be new for me -- and will also be the first official blog at our university.\n\n### We need a better aggregator for science blogs\n\nMost of us probably have subscribed to a good number of science blogs with an RSS reader. The best way to find interesting new posts is probably through links in blogs we read regularly. In addition, we stumble upon interesting posts via links in blog networks, blog rolls, **Twitter**, **FriendFeed**, or shared items in **Google Reader**.\n\nIn addition, we also need a good aggregator of science blogs. I have to admit that I have stopped using **Technorati** a while ago. [Nature.com Blogs](https://web.archive.org/web/20120611102940/http://blogs.nature.com/) was a good start, and [ResearchBlogging](https://web.archive.org/web/20120611102940/http://www.researchblogging.org/) does a good job of covering blog posts about peer-reviewed literature. But we probably can do much better. Whether the best strategy would be to put more resources into one of the existing services (see also Lou\\'s [comment](https://web.archive.org/web/20120611102940/http://blogs.nature.com/rpg/2010/07/24/on-nature-network#comment-61864) from earlier today), or whether to start building something new, I don\\'t know. But there is a lot of potential for building a better discovery service that at the same time will become an interesting archive of what the science blogosphere is talking about. [Streamosphere](https://web.archive.org/web/20120611102940/http://blogs.nature.com/mfenner/2009/08/20/streamosphere-interview-with-euan-adie) is already a good step in the right direction.\n\n### Personal interactions are important\n\nIt is usually much more rewarding to interact with someone online whom you have also met in person. This is true not only for scientific collaborations, but of course also for social media. This is obviously much easier if you live in places like London, but even Hannover (where I live) has a really nice [Science 2.0 community](https://web.archive.org/web/20120611102940/http://blogs.nature.com/mfenner/2010/05/11/action-points). And this is why science blogging conferences such as [ScienceOnline2010](https://web.archive.org/web/20120611102940/http://www.scienceonline2010.com/index.php/wiki/) or [Science Online London 2010](https://web.archive.org/web/20120611102940/http://www.scienceonlinelondon.org/) are so important. Science Online London is only six weeks away (September 3-4 at the British Library), and I\\'m really excited not only about the program, but also because of all the people I will for the first time or again meet in person.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw56","guid":"62d42bbd41e317003df48e01","id":"38c2f0f3-c412-4800-9854-a86e8b4389c4","image":"https://blog.front-matter.io/content/images/2022/08/3849275338_d77a382643.jpeg","indexed_at":1,"language":"en","published_at":1280102400,"reference":[],"relationships":[],"summary":"The last few days we have seen a number of blog posts reflecting on the pros and cons of science blogging networks. Bora Zivkovic last week announced his departure from scienceblogs.com, and in his must-read post reflected on the history of science blogging (A Farewell to Scienceblogs: the Changing Science Blogging Ecosystem). Richard Grant on Saturday wrote down his thoughts On Nature Network.\n","tags":["Feature"],"title":"Yet another look at blogging networks","updated_at":1660809792,"url":"https://blog.front-matter.io/posts/yet-another-look-at-blogging-networks"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/flipboard-changes-the-way-we-use-twitter","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"[Flipboard](https://web.archive.org/web/20120628140034/http://www.flipboard.com/) is a **personalized social magazine** for the iPad. The free application was released on July 22, and instantly created a lot of buzz. Because of the overwhelming interest, they had to create a waitlist for the personal features and I could only sign up for and start using them a few days ago. Flipboard is a true iPad application, it would not work the same on a laptop computer or mobile phone.\n\nFlipboard allows you to set up nine sections for different content. You can select them from a predefined list, but the really interesting part is to create your own sections from Twitter users or Twitter lists.\n\nYou can also create a section with all the Twitter accounts you follow. Flipboard will display Tweets in a visually pleasing way. Flipboard doesn\\'t display all Tweets in your Twitter timeline but filters the most popular and interesting tweets.\n\nBut Flipboard does something else. Rather than just displaying tweets, it follows the links provided in your Twitter stream and displays that information (photos, YouTube videos, blog posts, etc.). It can\\'t handle all the links and for example has problems with links to FriendFeed (very common in my Twitter feed).\n\nTo filter the information, you can also create sections from Twitter lists (or individual users). I had created lists with Science Journals ([\\@mfenner/science-journals](https://web.archive.org/web/20120628140034/https://twitter.com/mfenner/science-journals)) and Nature Network ([\\@mfenner/nature-network](https://web.archive.org/web/20120628140034/https://twitter.com/mfenner/nature-network)) bloggers in the past.\n\nTwitter lists are great for following meetings (e.g. [\\@BoraZ/scienceonline2010](https://web.archive.org/web/20120628140034/https://twitter.com/BoraZ/scienceonline2010)), but unfortunately Flipboard doesn\\'t yet allow to create sections from Twitter hashtags (e.g. [#scifoo](https://web.archive.org/web/20120628140034/https://twitter.com/#search?q=%23scifoo)).\n\nWhen you click on an individual entry, you will see a longer text, and also Tweets referring to that time as well as a link to the full-text article.\n\n<figure class=\"kg-card kg-image-card\">\n<img src=\"https://web.archive.org/web/20120628140034im_/http://blogs.plos.org/mfenner/files/2010/11/flipboard7.jpg\" class=\"kg-image\" loading=\"lazy\" />\n</figure>\n\nFlipboard does something similar with your Facebook News Feed. It is important to understand that Flipboard is not an RSS reader, but rather a visually pleasing aggregator from News in your Twitter and Facebook networks. Flipboard doesn\\'t present all the information in these networks, but rather filters the most popular and \"interesting\" stuff.\n\nHow is Flipboard relevant to reading scholarly papers? It can be used out of the box for journals that tweet their table of contents or at least the most interesting papers. And everybody can create a Twitter account that retweets interesting papers in a particular subject area or from a particular institution (ideally this should be integrated with a bookmarking tool such as CiteULike). Scientific publishers could also work with Flipboard to integrate their content (you see in the example above that the scraping used by flipboard sometimes isn\\'t perfect). Almost all scientific papers have an abstract. The abstract would display well in Flipboard, and could then link to the full text at the journal site.\n\n**To get started reading science blogs on Flipboard, add a ResearchBlogging.org section by subscribing to the \\@ResearchBlogs Twitter account.**\n\nFlipboard is of course also a great tool to follow science blogs. It probably works best if a new Twitter account is set up just for that purpose. This account could announce all new posts from a particular blog, or about a particular topic. Twitter lists could then be used for blogging networks such as **Nature Network** or **Scienceblogs.com**. Flipboard would also work very well to cover the blogging and tweeting of scientific conferences. With all these activities we will very soon need more than the nine sections that Flipboard supports.\n\n**Update 08/01/10: Added ResearchBlogging.org screenshot.**\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw5d","guid":"62d42bbd41e317003df48e08","id":"91aea273-df85-4710-80ab-a9273aca22d1","image":"https://blog.front-matter.io/content/images/2022/08/flipboard7.jpeg","indexed_at":1,"language":"en","published_at":1280620800,"reference":[],"relationships":[],"summary":"Flipboard is a\n<em>\n <em>\n  personalized social magazine\n </em>\n</em>\nfor the iPad. The free application was released on July 22, and instantly created a lot of buzz. Because of the overwhelming interest, they had to create a waitlist for the personal features and I could only sign up for and start using them a few days ago. Flipboard is a true iPad application, it would not work the same on a laptop computer or mobile phone.\n","tags":["Feature"],"title":"Flipboard changes the way we use Twitter","updated_at":1660809686,"url":"https://blog.front-matter.io/posts/flipboard-changes-the-way-we-use-twitter"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/book-review-cognitive-surplus-by-clay-shirky","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"In his new book **Cognitive Surplus** Clay Shirky argues that in the last 50 years many of those living in industrialized countries have seen a dramatic increase in free time, paired with better education and a higher standard of living. But a very large part of that free time or cognitive surplus is now routinely used to watch television, a passive activity that makes us a consumer rather than a participant. In a trend that is also true for other media (eg. music), we have seen a shift away from participation (usually on an amateur level) towards consuming professionally produced media content.\n\nIn the last few years we have seen a dramatic change in Internet technologies that now make it extremely easy for everybody to produce content and distribute it on the Internet (e.g. Wikipedia, blogs, photos on Flickr, or YouTube videos) something we usually call Web 2.0 or social media. Clay Shirky contrasts the time that users spend editing **Wikipedia** (or other social media activities) with the hours we typically watch television to kill the argument that most of us would have no time for social media.\n\nThe combination of increased free time and social media is creating a lot of interesting collaborative projects, and the book is full of interesting examples. Clay Shirky stresses that social media only enable new uses of the cognitive surplus, it is how they are used that decides whether we create personal, communal, public or civic values. He uses [ICanHazCheeseburger](https://web.archive.org/web/20120524201437/http://www.icanhazcheeseburger.com/) (a popular website that shows cute pictures of cats with cute captions) as an example for communal value, the [Apache Webserver](https://web.archive.org/web/20120524201437/http://www.apache.org/) Open Source software project as an example of public value, and [Ushahidi.com](https://web.archive.org/web/20120524201437/http://www.ushahidi.com/) (a site started to allow citizens to track outbreaks of ethnic violence in Kenya) as an example of civic value.\n\nSocial media in the context of science and medicine are discussed briefly in the book. Clay Shirky describes the **Invisible College**, a group formed around 1645 in London by Robert Boyle, Robert Hooke and others that established many of the principles of conducting science that are still valid today (test every hypothesis with experiments, describe experiments detailed enough so that they could be reproduced, etc.). The group formed the core of what a little later became the **Royal Society**. Clay Shirky argues that the collaborative nature of how science was conducted by the Invisible College lead to a dramatic increase in our scientific knowledge and contrasts this with how alchemy was performed at the time (reclusive and secretive).\n\nClay Shirky also talks about [PatientsLikeMe.com](https://web.archive.org/web/20120524201437/http://www.patientslikeme.com/), a site that allows patients with chronic diseases to share their health information, both for personal advice, but also as participants in clinical trials. Patients Like Me only works because patients are willing to share their personal healthcare information, and that is a cultural shift from the strict privacy that usually surrounds information about your personal health. Patients participating in Patients Like Me obviously think that the benefits from sharing their personal healthcare information outweigh the risks.\n\nCognitive Surplus is very entertaining reading, and on almost every page Clay Shirky gives us food for thought that will keep us busy for days or weeks. The book is required reading for everybody who is interested in how social media are changing the way we consume, communicate, and conduct science. After finishing the book, you will no longer think that the scientific article of the future is primarily about integration of video or other multimedia, intelligent navigation, or display on mobile devices. The successful journals of the future will be those that work hardest in facilitating collaboration among scientists, and this requires cultural changes as much as it requires technological changes.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw5a","guid":"62d42bbd41e317003df48e05","id":"5de444a2-d01f-4036-8672-51548b96f1d9","image":"https://blog.front-matter.io/content/images/2022/08/1594202532.jpeg","indexed_at":1,"language":"en","published_at":1281744000,"reference":[],"relationships":[],"summary":"In his new book\n<em>\n <em>\n  Cognitive Surplus\n </em>\n</em>\nClay Shirky argues that in the last 50 years many of those living in industrialized countries have seen a dramatic increase in free time, paired with better education and a higher standard of living. But a very large part of that free time or cognitive surplus is now routinely used to watch television, a passive activity that makes us a consumer rather than a participant.\n","tags":["Book Review"],"title":"Book Review: Cognitive Surplus by Clay Shirky","updated_at":1660809272,"url":"https://blog.front-matter.io/posts/book-review-cognitive-surplus-by-clay-shirky"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/welcome-to-gobbledygook","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"In his [introductory post](https://web.archive.org/web/20120506093643/http://blogs.plos.org/blog/2010/08/31/the-niche-blog-network-lessons-from-the-past-visions-for-the-future/), PLoS community manager Brian Mossop talks about how PLoS Blogs came to life, and the lessons learned from other blogging networks. For me personally it all started a few weeks ago with a phone call one Friday evening from [Pete Binfield](https://web.archive.org/web/20120506093643/http://www.plos.org/about/people/one.php#pbinfield), Publisher of PLoS ONE and the PLoS Community Journals.\n\nSince August 2007 and until today I was blogging over at [Nature Network](https://web.archive.org/web/20120506093643/http://blogs.nature.com/mfenner). The focus of that blog was how the internet is changing scientific publishing. This is obviously a very broad topic. A lot of my blog posts looked at rather technical aspects, including new products and services (the [last post](https://web.archive.org/web/20120506093643/http://blogs.nature.com/mfenner/2010/08/29/elsevier-launches-sciverse-integrates-sciencedirect-scopus-more) was about Elsevier's SciVerse that launched last weekend).\n\nI will continue to write about the same topics. I particularly like to continue [interviews](https://web.archive.org/web/20120506093643/http://blogs.nature.com/mfenner/2010/08/31/bye-bye-nature-network), and I want to write more recipes ([Recipe: Distributing papers for a journal club](https://web.archive.org/web/20120506093643/http://blogs.nature.com/mfenner/2009/08/08/recipe-distributing-papers-for-a-journal-club)). Of course I also want to try different things, e.g. shorter blog posts of interesting stuff I find (something I currently post on Twitter). Please contact me if you have something related to scientific publishing that you want me to write about.\n\nPLoS Blogs is not the only new science blogging network. [Guardian Science Blogs](https://web.archive.org/web/20120506093643/http://www.guardian.co.uk/science/blog/2010/aug/31/blogging-digital-media) launched just yesterday, and [Scientopia](https://web.archive.org/web/20120506093643/http://scientopia.org/blogs/) and [Science 3.0](https://web.archive.org/web/20120506093643/http://www.science3point0.com/blogs/) in the last few weeks. And [Scienceblogging.org](https://web.archive.org/web/20120506093643/http://scienceblogging.org/2010/08/19/some-thoughts-about-science-blog-aggregation/), an aggregator of science blogs (to keep track of all those great blog posts), was launched by Anton Zuiker, Bora Zivkovic and Dave Munger two weeks ago.\n\nThis is a good week for science blogging for another reason. The [Science Online London Conference](https://web.archive.org/web/20120506093643/http://www.scienceonlinelondon.org/) takes place this Friday and Saturday. Most relevant to the launch of PLoS Blogs is the panel discussion Friday afternoon [The state of science blogging?](https://web.archive.org/web/20120506093643/http://www.scienceonlinelondon.org/programme.php?tab=abstracts#panel2)\n\n<figure class=\"kg-card kg-image-card\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/logo.png\" class=\"kg-image\" loading=\"lazy\" width=\"271\" height=\"208\" alt=\"Science Online London\" />\n</figure>\n\nThere will of course be other exciting sessions. The panel [\"Rebooting\" (aka the future of) science journalism](https://web.archive.org/web/20120506093643/http://www.scienceonlinelondon.org/programme.php?tab=abstracts#panel1) with David Dobbs, Ed Yong, Martin Robbins, and Alice Bell should be a lot of fun. The closing panel discussion on Saturday [If you build it, will they come?](https://web.archive.org/web/20120506093643/http://www.scienceonlinelondon.org/programme.php?tab=abstracts#panel3) will look at the adoption (or lack thereof) of \u00a0Web 2.0 tools for scholarly communication, based on a [recent report](https://web.archive.org/web/20120506093643/http://www.rin.ac.uk/our-work/communicating-and-disseminating-research/use-and-relevance-web-20-researchers) by the Research Information Network. And a number of sessions focus on open data, a trending topic I'm personally very interested in. Together with Geoff Bilder and Gudmundur Thorisson I will moderate a session [ORCID as unique author identifier: what is it good for and should we worry or be happy?](https://web.archive.org/web/20120506093643/http://www.scienceonlinelondon.org/programme.php?tab=abstracts#breakout11)\n\nMost importantly, Science Online London is a great opportunity to meet many of my fellow science bloggers in person, including Brian Mossop, the PLoS Blogs community manager. Expect more reports from Science Online London in the next few days, for more up-to-date information please follow me on Twitter ([\\@mfenner](https://web.archive.org/web/20120506093643/http://twitter.com/mfenner), conference hashtag [#solo10](https://web.archive.org/web/20120506093643/http://twitter.com/#search?q=%23solo10)) or try the [video stream](https://web.archive.org/web/20120506093643/http://www.science3point0.com/solo10-2/) put together by Graham Steel.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw5n","guid":"62d42bbd41e317003df48e10","id":"f48210af-29b7-43a2-ac7e-47a3bf176b6f","image":"https://blog.front-matter.io/content/images/2022/08/2187485704_a598c84739.jpeg","indexed_at":1,"language":"en","published_at":1283299200,"reference":[],"relationships":[],"summary":"In his introductory post, PLoS community manager Brian Mossop talks about how PLoS Blogs came to life, and the lessons learned from other blogging networks. For me personally it all started a few weeks ago with a phone call one Friday evening from Pete Binfield, Publisher of PLoS ONE and the PLoS Community Journals. Since August 2007 and until today I was blogging over at Nature Network.\n","tags":["Meeting Report"],"title":"Welcome to Gobbledygook","updated_at":1660809196,"url":"https://blog.front-matter.io/posts/welcome-to-gobbledygook"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/bye-bye-nature-network","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"This is my last post for this Nature Network blog. Later today, I will start a new blog somewhere else -- also called Gobbledygook and covering the same topics.\n\nWriting this blog here on Nature Network since August 2007 has been an incredible experience, something that can\\'t be covered in a single blog post. I simply want to say thank you to all the people I interacted with over the years -- both online and in person. And a particular thanks for Matt, Corie, Anna and Lou from Nature Network who made all this possible.\n\nThere are several of my posts I particularly like -- and some I like a little less. Something I really enjoyed doing -- and something that I think works very well in the blog format -- is interviews. I did around 20 interviews in the last two years (the last two on the [Lindau Laureate Meeting](https://web.archive.org/web/20120525055619/http://lindau.nature.com/) blog), and I\\'ve listed them all below.\n\n-   [Victor Henning about Mendeley](https://web.archive.org/web/20120525055619/http://blogs.nature.com/mfenner/2008/09/05/interview-with-victor-henning-from-mendeley)\n-   [Alex Griekspoor about Papers](https://web.archive.org/web/20120525055619/http://blogs.nature.com/mfenner/2008/10/03/interview-with-alexander-griekspoor)\n-   [Pablo Fernicola about the Microsoft Word Article Authoring Add-In](https://web.archive.org/web/20120525055619/http://blogs.nature.com/mfenner/2008/11/07/interview-with-pablo-fernicola)\n-   [Moshe Pritsker about JOVE](https://web.archive.org/web/20120525055619/http://blogs.nature.com/mfenner/2009/01/24/interview-with-moshe-pritsker)\n-   [Kevin Emamy about CiteULike](https://web.archive.org/web/20120525055619/http://blogs.nature.com/mfenner/2009/01/30/interview-with-kevin-emamy)\n-   [Geoff Bilder about CrossRef and author identifiers](https://web.archive.org/web/20120525055619/http://blogs.nature.com/mfenner/2009/02/17/interview-with-geoffrey-bilder)\n-   [MJ Suhonos about Lemon8-XML](https://web.archive.org/web/20120525055619/http://blogs.nature.com/mfenner/2009/02/27/lemon8-xml-interview-with-mj-suhonos)\n-   [Trevor Owens about Zotero](https://web.archive.org/web/20120525055619/http://blogs.nature.com/mfenner/2009/03/04/zotero-interview-with-trevor-owens)\n-   [Richard Wynne about Editorial Manager](https://web.archive.org/web/20120525055619/http://blogs.nature.com/mfenner/2009/03/25/editorial-manager-interview-with-richard-wynne)\n-   [Richard Grant about Faculty of 1000](https://web.archive.org/web/20120525055619/http://blogs.nature.com/mfenner/2009/04/28/faculty-of-1000-interview-with-richard-grant)\n-   [Elizabeth Blake and Bruce Rosenblum about eXtyles](https://web.archive.org/web/20120525055619/http://blogs.nature.com/mfenner/2009/05/01/extyles-interview-with-elizabeth-blake-and-bruce-rosenblum)\n-   [Tony Hammond about OAI-PMH](https://web.archive.org/web/20120525055619/http://blogs.nature.com/mfenner/2009/05/25/oai-pmh-interview-with-tony-hammond)\n-   [Peter Binfield about PLoS ONE and article level metrics](https://web.archive.org/web/20120525055619/http://blogs.nature.com/mfenner/2009/08/15/plos-one-interview-with-peter-binfield)\n-   [Euan Adie about Streamosphere](https://web.archive.org/web/20120525055619/http://blogs.nature.com/mfenner/2009/08/20/streamosphere-interview-with-euan-adie)\n-   [Alex Knoll about Conference Blogging](https://web.archive.org/web/20120525055619/http://blogs.nature.com/mfenner/2009/10/01/conference-blogging-interview-with-alex-knoll)\n-   [Phil Vaughan about UK PubMed Central](https://web.archive.org/web/20120525055619/http://blogs.nature.com/mfenner/2009/11/04/uk-pubmed-central-interview-with-phil-vaughan)\n-   [Lesley Anson about Nature Communications](https://web.archive.org/web/20120525055619/http://blogs.nature.com/mfenner/2009/11/26/nature-communications-interview-with-lesley-anson)\n-   [Ijad Madisch about ScienceFeed](https://web.archive.org/web/20120525055619/http://blogs.nature.com/mfenner/2010/02/15/sciencefeed-interview-with-ijad-madisch)\n-   [Renny Guida about Researcher ID](https://web.archive.org/web/20120525055619/http://blogs.nature.com/mfenner/2010/04/26/researcherid-interview-with-renny-guida)\n-   [Jason Rollins about Endnote](https://web.archive.org/web/20120525055619/http://blogs.nature.com/mfenner/2010/08/03/endnote-interview-with-jason-rollins)\n-   [Nobel Laureate Edmond Fischer](https://web.archive.org/web/20120525055619/http://www.scilogs.eu/en/blog/lindaunobel/2010-07-13/interview-with-edmond-fischer)\n-   [Nobel Laureate Francoise Barr\u00e9-Sinoussi -- together with Lou Woodley](https://web.archive.org/web/20120525055619/http://www.scilogs.eu/en/blog/lindaunobel/2010-07-14/an-interview-francoise-barre-sinoussi)\n\nPlease stay in touch. And if possible, come around to the [Science Online London Conference](https://web.archive.org/web/20120525055619/http://www.scienceonlinelondon.org/) this weekend.\n\nUpdate: Gobbledygook has moved to [PLoS Blogs](https://web.archive.org/web/20120525055619/http://blogs.plos.org/mfenner).\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw5e","guid":"62d42bbd41e317003df48e09","id":"a73c8a56-2baf-4cf6-950d-e98e55875a04","image":"https://blog.front-matter.io/content/images/2022/08/3378007233_f8d5e5a539.jpeg","indexed_at":1,"language":"en","published_at":1283299200,"reference":[],"relationships":[],"summary":"This is my last post for this Nature Network blog. Later today, I will start a new blog somewhere else \u2013 also called Gobbledygook and covering the same topics. Writing this blog here on Nature Network since August 2007 has been an incredible experience, something that can't be covered in a single blog post. I simply want to say thank you to all the people I interacted with over the years \u2013 both online and in person.\n","tags":["News"],"title":"Bye-Bye Nature Network","updated_at":1660809034,"url":"https://blog.front-matter.io/posts/bye-bye-nature-network"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/how-readers-can-support","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"The Front Matter blog [launched last\nweek](https://blog.front-matter.io/posts/front-matter-officially-launches-today)\nand while the content is currently only written by me, I hope this will\nchange in the coming months to include one-time guest posts and regular\nwriters. One challenge is to figure out how to finance the blog in the\nlong run. Running blog infrastructure is not overtly expensive, and in\nthe case of the Front Matter blog amounts to about 120\u20ac/\\$140 a month:\n\n- hosting Ghost blog editor 15\u20ac/month ([Digital\n  Ocean](https://www.digitalocean.com/))\n- hosting Next.js frontend 20\u20ac/month ([Vercel](https://vercel.com/))\n- hosting full-text search index 35\u20ac/month\n  ([Typesense](https://typesense.org/))\n- hosting Discourse commenting platform 15\u20ac/month ([Digital\n  Ocean](https://www.digitalocean.com/))\n- web analytics \u20ac5/month ([Plausible](https://plausible.io/))\n- registration domain name 35\u20ac/year ([DNSimple](https://dnsimple.com/))\n- DOI registration \u20ac300/year (estimate,\n  [Crossref](https://www.crossref.org/))\n\nThe cost not reflected above, is of course staff time for writing blog\nposts, but also editing, deciding on topics, reaching out to potential\nwriters, etc. A reasonable goal would be to pay for an editor one day a\nweek, which would add about 1280\u20ac/1500\\$ to the monthly cost running the\nblog. How can this be supported financially?\n\nWhile there is always the hope of finding an organization (funder,\npublisher, institution, infrastructure provider, etc.) that cares enough\nabout Open Science to pay for running this blog, a more realistic\nalternative is to depend on reader contributions, combined with\nvolunteer donations.\n\n<figure class=\"kg-card kg-image-card kg-card-hascaption\">\n<img\nsrc=\"https://blog.front-matter.io/content/images/2022/07/Bildschirmfoto-2021-08-09-um-20.21.20.png\"\nclass=\"kg-image\" loading=\"lazy\"\nsrcset=\"https://blog.front-matter.io/content/images/size/w600/2022/07/Bildschirmfoto-2021-08-09-um-20.21.20.png 600w, https://blog.front-matter.io/content/images/size/w1000/2022/07/Bildschirmfoto-2021-08-09-um-20.21.20.png 1000w, https://blog.front-matter.io/content/images/size/w1600/2022/07/Bildschirmfoto-2021-08-09-um-20.21.20.png 1600w, https://blog.front-matter.io/content/images/2022/07/Bildschirmfoto-2021-08-09-um-20.21.20.png 2000w\"\nsizes=\"(min-width: 720px) 720px\" width=\"2000\" height=\"1133\" />\n<figcaption><a href=\"https://www.buymeacoffee.com/frontmatter\">Buy Me a\nCoffee page</a> for Front Matter</figcaption>\n</figure>\n\nAdvertisements are a very painful way to recover even a fraction of the\ncosts for running a blog that caters to a relatively small audience\n(scholarly communication). In response, several platforms, including\n[Medium](https://medium.com/), [Ghost](https://ghost.org/) and\n[Substack](https://substack.com/), have evolved with a business model\nfocused on providing exclusive content to paying subscribers. This is\nobviously not an option for an Open Science blog, where the assumption\nis that content is free to read and reuse under a Creative Commons\nlicense.\n\nToday the Front Matter blog is starting a newsletter with a small\nmonthly subscription fee (3\u20ac/month or 30\u20ac/year). The newsletter does not\nprovide exclusive content, but rather is a convenience for users to\ndirectly receive content in their email inbox rather than via the [Front\nMatter RSS Feed](https://blog.front-matter.io/feed.xml). In addition,\nusers can give one-time donations to support the Front Matter blog.\nThese payment options are provided by [Buy Me a\nCoffee](https://www.buymeacoffee.com/), with a\n[link](https://blog.front-matter.io/support) to the membership/support\npage in the footer of every Front Matter page \u00a0(see screenshot below).\n\nI hope that by the end of the year, some revenue will accrue that can\nsupport the Front Matter blog. It would definitely be a strong\nmotivation to write regular Open Science blog posts with interesting\ncontent. A related aim is of course to nurture active and engaged\nreaders who write comments in response to the posts, suggest topics to\nwrite about, and generally tell me via comments or email how Front\nMatter can do better.\n","doi":"https://doi.org/10.53731/r8hb7h1-97aq74v-ag6ew","guid":"62d42bbd41e317003df48f11","id":"47bfec7f-b021-41fc-83ea-8dfb9035ad19","image":"https://blog.front-matter.io/content/images/2022/07/photo-1454165804606-c3d57bc86b40.jpeg","indexed_at":1,"language":"en","published_at":1628605197,"reference":[],"relationships":[],"summary":"The Front Matter blog launched last week and while the content is currently only written by me, I hope this will change in the coming months to include one-time guest posts and regular writers. One challenge is to figure out how to finance the blog in the long run.\n","tags":["Feature"],"title":"How readers can support the Front Matter blog","updated_at":1660746739,"url":"https://blog.front-matter.io/posts/how-readers-can-support"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/orcid-as-unique-author-identifier-what-is-it-good-for-and-should-we-worry-or-be-happy","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"This was the title of the session with ****Geoff Bilder****, ****Gudmundur Thorisson**** and myself at the [Science Online London Conference](https://web.archive.org/web/20120525074318/http://www.scienceonlinelondon.org/programme.php?tab=abstracts#breakout12) last Saturday. Geoff first introduced the ORCID initiative, including several \u00a0principles.\n\nWe then talked about two use cases for ORCID. I started with the manuscript submission scenario ([my Slideshare presentation](https://web.archive.org/web/20120525074318/http://www.slideshare.net/mfenner/orcid-as-unique-author-identifier-what-is-it-good-for-and-should-we-worry-or-be-happy)), and I suggested that a critical mass of journals using ORCID would have these benefits to researchers:\n\n1.  Reduced submission work\n2.  Automated CVs and publication lists\n3.  Find related works by author\n4.  Semantic meaning of authorship\n\nSemantic meaning of authorship (\"corresponding author\" or \"analyzed microarray data\") is not a goal for the first ORCID release, but an interesting future perspective.\n\nGudmundur followed with a similar presentation about the research dataset submission scenario ([his Slideshare presentation](https://web.archive.org/web/20120525074318/http://www.slideshare.net/gthorisson/thorisson-science-online-london-sep2010)).\n\nThe process is similar to journal submission but interacts with repositories instead of journals. Gudmundur showed how this workflow could integrate the submission of a manuscript and the corresponding research data. He also demonstrated how datasets in repositories associated with a particular author could be discovered with the help of ORCID.\n\nBut most of the session was dedicated to discussion. As open data was one of the main themes of the conference, the meaning of \"open\" in ORCID was one of the topics. We talked about how the identifier ORCID could be combined with authentication such as the OAuth system. Phil Lord wanted a modification of the journal submission use case, in that the ORCIDs of authors should be provided with the manuscript, and not entered in the journal submission system. And we talked about whether ORCID should also be used for blog posts, Wikipedia submissions, Slideshare presentations, etc. -- I argued that not everything needs to be attributed and measured (see my [previous blog post](https://blog.front-matter.io/posts/unmeasurable-science/)).\n\n<figure class=\"kg-card kg-image-card kg-card-hascaption\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/4953236107_349c7d7b02_m.jpeg\" class=\"kg-image\" loading=\"lazy\" width=\"180\" height=\"240\" alt=\"Konferensp\u00e5se\" />\n<figcaption>Flickr photo by malin_c.</figcaption>\n</figure>\n\nToday the ORCID initiative reached another important milestone. ORCID is [now an official non-profit organization](https://web.archive.org/web/20120525074318/http://orcid.org/node/166) with a first board of directors. I am looking forward to serving on this board of directors.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw5j","guid":"62d42bbd41e317003df48e0d","id":"b5b327d5-b6f2-4ed8-b24b-40a714459486","image":"https://blog.front-matter.io/content/images/2022/08/bilder.jpeg","indexed_at":1,"language":"en","published_at":1283817600,"reference":[],"relationships":[],"summary":"This was the title of the session with\n<strong>\n <strong>\n  Geoff Bilder\n </strong>\n</strong>\n,\n<strong>\n <strong>\n  Gudmundur Thorisson\n </strong>\n</strong>\nand myself at the Science Online London Conference last Saturday. Geoff first introduced the ORCID initiative, including several \u00a0principles. We then talked about two use cases for ORCID.\n","tags":["Meeting Report"],"title":"ORCID as unique author identifier: what is it good for and should we worry or be happy?","updated_at":1660744392,"url":"https://blog.front-matter.io/posts/orcid-as-unique-author-identifier-what-is-it-good-for-and-should-we-worry-or-be-happy"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/starting-a-reading-list-for-goobledygook","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"All science bloggers do a lot of reading for background information, or write blog posts based on a (newly published) paper, blog post or news item. So I thought that it would be a good idea to collect those references in a single place.\n\nReading lists are perfect for this, and they are easy to create and maintain with web-based reference managers. Reading lists are used in teaching, e.g. to provide a list of required reading material for a class. But I can also see a number of benefits for science blogs:\n\n-   they help the blogger to organize his background material for writing\n-   they help the reader find and keep referenced material\n-   they can provide additional reading not mentioned in the blog post\n\nThere are several good tools for reading lists. I decided to use [CiteULike](https://web.archive.org/web/20120604134625/http://www.citeulike.org/), because what I really want here is a social bookmarking tool that understands references. My Goobledygook reading list is [here](https://web.archive.org/web/20120604134625/http://www.citeulike.org/group/13987/library), the RSS feed is [here](https://web.archive.org/web/20120604134625/http://www.citeulike.org/rss/group/13987/library), and the most recent items in the reading list are also shown in a new sidebar to the right. I started with references to papers, but plan to also include blog posts and other web resources.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw5s","guid":"62d42bbd41e317003df48e14","id":"1535a468-5dae-4d22-81ce-9366d5aada6f","image":"https://blog.front-matter.io/content/images/2022/08/1252522330_78b53d7e16.jpeg","indexed_at":1,"language":"en","published_at":1284595200,"reference":[],"relationships":[],"summary":"All science bloggers do a lot of reading for background information, or write blog posts based on a (newly published) paper, blog post or news item. So I thought that it would be a good idea to collect those references in a single place. Reading lists are perfect for this, and they are easy to create and maintain with web-based reference managers.\n","tags":["Feature"],"title":"Starting a reading list for Gobbledygook","updated_at":1660744132,"url":"https://blog.front-matter.io/posts/starting-a-reading-list-for-goobledygook"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/why-cant-i-reuse-these-tables-and-figures","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"Tables and figures contain the data of a scientific paper in condensed (and often visually appealing) form. This is why they are among the first thing we look at, and why they are often reused when we discuss the paper in a presentation or blog post.\n\n<figure class=\"kg-card kg-image-card kg-card-hascaption\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/ppat.v06.i08.jpg\" title=\"PLoS Pathogens\" class=\"kg-image\" loading=\"lazy\" width=\"251\" height=\"251\" />\n<figcaption><em><em>From</em> https://doi.org/<em><a href=\"https://web.archive.org/web/20120525130956/http://dx.doi.org/10.1371/journal.ppat.1001042\">10.1371/journal.ppat.1001042</a>. Image credit: Thomas J. Hannan, Washington University.</em></em></figcaption>\n</figure>\n\nElectronic publication has dramatically simplified the reuse of tables and figures, and therefore reuse has become very common -- you probably find reused material in most presentations given in academic institutions or at conferences.\n\nMost authors will probably be happy that their results are disseminated, and reuse is likely to lead to more people reading the full paper and citing the work.\n\nBut this reuse has two problems. The first problem is copyright. Many journals own the copyright of the papers they publish and don't allow reuse without prior permission. Unfortunately, copyright is a complicated issue, and also differs between countries. Most researchers assume \"[Fair use](https://web.archive.org/web/20120525130956/http://www.copyright.gov/fls/fl102.html)\" when they reuse material, but this might not apply to all situations, e.g. presentations at conferences. And many researchers don't understand that they have often given away the copyright to their own works so that they can't show a figure from one of their papers without permission.\n\nMany publishers have automated the process of obtaining permissions for copyrighted work, e.g. using the [Rightslink](http://www.copyright.com/viewPage.do?pageCode=pu4-n) system of the Copyright Clearance Center. But it still requires a considerable investment in time (and often money) to obtain all permissions, especially since these are usually one-time permissions only. This combination of unawareness of the details of copyright law and the required extra work means that many researchers probably don't obtain permission prior to reuse.\n\nThe solution to the copyright problems is obviously to use material with a [Creative Commons](https://creativecommons.org/) license whenever possible, as I have done in this blog post. And most Open Access papers are published under this license, so there is plenty of material to choose from.\n\nBut there is also a second problem with reusing tables and figures. They were designed to be part of a paper and often look terrible in a presentation, particularly tables.\n\n<figure class=\"kg-card kg-image-card kg-card-hascaption\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/plosone-e1285879245843.png\" title=\"plosone\" class=\"kg-image\" loading=\"lazy\" width=\"500\" height=\"402\" />\n<figcaption><em><em>From</em> https://doi.org/</em><a href=\"https://web.archive.org/web/20120525130956/http://dx.doi.org/10.1371/journal.pone.0006022\"><em><em>10.1371/journal.pone.0006022</em></em></a>.</figcaption>\n</figure>\n\nThe solution to this problem is to provide the data behind the table or figure, so that the information can be displayed in a way that makes sense in a presentation. Here we usually have to reduce the amount of information, but it could also mean that we remix the content with other sources. The Creative Commons licenses discussed above are [not appropriate](http://pantonprinciples.org/) for data. Whenever possible, scientific data should be placed in the public domain.\n\nIt is important to distinguish the publication of table and figure data from the publication of the [whole research dataset](https://web.archive.org/web/20120525130956/http://blogs.openaccesscentral.com/blogs/bmcblog/entry/bmc_research_notes_wants_your). The open questions with the latter (e.g. standard data formats, appropriate repositories, archiving) don't apply to the former. This means that publishers could start providing these data immediately. I'm confident that they would see an increase in paper downloads and citations. But more importantly, I hope this would lead to better presentations in seminars and at conferences.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw60","guid":"62d42bbd41e317003df48e1b","id":"93f6ccd5-3f2e-4f4b-acc6-eb393fedfc7a","image":"https://blog.front-matter.io/content/images/2022/08/bmccancer-e1285879074865--1-.jpeg","indexed_at":1,"language":"en","published_at":1285804800,"reference":[],"relationships":[],"summary":"Tables and figures contain the data of a scientific paper in condensed (and often visually appealing) form. This is why they are among the first thing we look at, and why they are often reused when we discuss the paper in a presentation or blog post.\n<em>\n <em>\n  From\n </em>\n https://doi.org/\n <em>\n  10.1371/journal.ppat.1001042.\n </em>\n</em>\n","tags":["Chart"],"title":"Why can\u2019t I reuse these tables and figures?","updated_at":1660744018,"url":"https://blog.front-matter.io/posts/why-cant-i-reuse-these-tables-and-figures"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/registration-for-scienceonline2011-starts-today","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"Registration for the [ScienceOnline2011](https://web.archive.org/web/20101124185427/http://scienceonline2011.com/) conference starts today at 12 noon EST. This is the fifth annual conference on science and the web, and will be held January 13-15, 2011 in Research Triangle Park, North Carolina.\n\nThis is the second time I will go to the conference -- I had a wonderful time in 2009. The discussion around the 2009 session [Reputation, Authority and Incentives](https://web.archive.org/web/20101124185427/http://jdupuis.blogspot.com/2009/01/scienceonline-09-sunday-summary-and.html) (moderated by Bj\u00f6rn Brembs and Pete Binfield) was really the starting point for my interest in unique researcher identifiers. The conference was also the first time that I met PLoS Blogs partner [David Kroll](https://web.archive.org/web/20101124185427/http://blogs.plos.org/takeasdirected/) and many other great people.\n\nYou will find my name on the [preliminary program](https://web.archive.org/web/20101124185427/http://scio11.wikispaces.com/Program+Finalization) in a session ****Having Fun with Citations**** (together with Melody Dye)****:****\n\n> **Citations play a central role in science communication, but their role in the traditional scientific publication is often rather boring. We love to count citations for measures of scientific impact, but we spend little time thinking about the context and meaning of citations. In this session I would like to talk about topics ranging from semantic meaning of citations (using CiTO, the Citation Typing Ontology by David Shotton), citations of retracted papers, citations of datasets (using Datacite), the importance of an Open Bibliography, formatting of citations using CSL (Citation Style Language), citations in Twitter and other unusual places, citation mutations and the integration of unique researcher identifiers (using ORCID). There is some interesting work on how citation rates follow Zipfian-like distributions; it would be interested to discuss the background and implications.**\n\nThe exact session format and the other session moderators have not been finalized. There are also at least two related session proposals: **How is the Web changing the way we identify scientific impact?** (Jason Priem, Paul Groth) **** and ****The Digital Toolbox: What's Needed?**** (Kaitlin Thaney) -- we might combine some of our ideas. And of course, I am also looking forward to again meeting all these wonderful people that are interested in science and the web.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw7y","guid":"62d42bbd41e317003df48e59","id":"8f3e59ef-b6c0-4e75-bc83-0987a6a875a9","image":"https://blog.front-matter.io/content/images/2022/08/Scionline2011-100.png","indexed_at":1,"language":"en","published_at":1286668800,"reference":[],"relationships":[],"summary":"Registration for the ScienceOnline2011 conference starts today at 12 noon EST. This is the fifth annual conference on science and the web, and will be held January 13-15, 2011 in Research Triangle Park, North Carolina. This is the second time I will go to the conference \u2013 I had a wonderful time in 2009.\n","tags":["Meeting Report"],"title":"Registration for ScienceOnline2011 starts today","updated_at":1660743788,"url":"https://blog.front-matter.io/posts/registration-for-scienceonline2011-starts-today"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/survey-asks-for-feedback-about-orcid-unique-researcher-identifier","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"The [ORCID](https://web.archive.org/web/20101013051207/http://www.orcid.org/) initiative for unique researcher identifiers yesterday started a [survey](https://web.archive.org/web/20101013051207/http://survey.euro.confirmit.com/wix/p501806648.aspx) that everybody interested in ORCID should fill out.\n\nThe survey asks questions about the main services that users expect from ORCID, and how the ORCID service should be paid for (e.g. membership fees or fee-for service).\n\nIn quick response to the announcement of the survey on Twitter, an [interesting discussion](https://web.archive.org/web/20101013051207/http://friendfeed.com/researchremix/d5611278/rt-orcid_org-please-help-us-move-orcid-forward) started on ****FriendFeed****. Several commenters were worried that ORCID tries to be too much. Their thoughts were nicely summarized in [this tweet](https://web.archive.org/web/20101013051207/http://twitter.com/#!/CameronNeylon/status/27158241887) by ****Cameron Neylon****:\n\n<figure class=\"kg-card kg-embed-card\">\n<blockquote>\n<p>.<a href=\"https://twitter.com/mfenner?ref_src=twsrc%5Etfw\">@mfenner</a> Agree with <a href=\"https://twitter.com/ReaderMeter?ref_src=twsrc%5Etfw\">@ReaderMeter</a> + <a href=\"https://twitter.com/mrgunn?ref_src=twsrc%5Etfw\">@mrgunn</a>: <a href=\"https://twitter.com/ORCID_Org?ref_src=twsrc%5Etfw\">@ORCID_Org</a> will be a success when it does amazing things for me and I barely notice it's there</p>\n<p>\u2014 C\u24d0meronNeylon (@CameronNeylon) <a href=\"https://twitter.com/CameronNeylon/status/27158241887?ref_src=twsrc%5Etfw\">October 12, 2010</a></p>\n</blockquote>\n</figure>\n\nThe survey is open until October 28, the results will be reported in November.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw8c","guid":"62d42bbd41e317003df48e67","id":"af41b3d6-5451-4e89-9d80-fce93a24f09f","image":"https://blog.front-matter.io/content/images/2022/08/215910967_7ede5cc61a.jpeg","indexed_at":1,"language":"en","published_at":1286841600,"reference":[],"relationships":[],"summary":"The ORCID initiative for unique researcher identifiers yesterday started a survey that everybody interested in ORCID should fill out. The survey asks questions about the main services that users expect from ORCID, and how the ORCID service should be paid for (e.g. membership fees or fee-for service). In quick response to the announcement of the survey on Twitter, an interesting discussion started on\n<strong>\n <strong>\n  FriendFeed\n </strong>\n</strong>\n.\n","tags":["News"],"title":"Survey asks for feedback about ORCID unique researcher identifier","updated_at":1660743357,"url":"https://blog.front-matter.io/posts/survey-asks-for-feedback-about-orcid-unique-researcher-identifier"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/today-i-started-a-new-blogging-network","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"In the last few weeks I haven't seen any announcement for a new science blogging network (the last one was probably [Scientific American](https://web.archive.org/web/20101105204155/http://blog.coturnix.org/2010/09/15/alert-some-big-and-important-and-exciting-news/) in September). So I thought today would be a good day to start a new one. Earlier today I wrote [the first post](https://web.archive.org/web/20101105204155/http://blogs.mh-hannover.de/tumorzentrum/2010/10/15/herzlich-willkommen/) on the first blog hosted by [my institution](https://web.archive.org/web/20101105204155/http://www.mh-hannover.de/index.php?id=2&L=1). The blog runs on a WordPress 3.0 installation that I hope will see more blogs in the future -- our library will probably be next (they are currently [hosted on WordPress.com](https://web.archive.org/web/20101105204155/http://mhhbibliothek.wordpress.com/)).\n\nThe new blog is the official blog of our Comprehensive Cancer Center (my day job). I will write about various aspects of the work there -- something I wanted to do for a while. This is also the first time that I write in German, which will be much easier, but at the same time will reach a smaller audience. Writing for my institution will also be an interesting experience. Although I don't think that this will start something big at our institution, institutions are in fact a good place for blogging networks. Special thanks go to Stefan Zorn in our PR department for encouraging words, and to [Henry Scowcroft](https://web.archive.org/web/20101105204155/http://scienceblog.cancerresearchuk.org/about-the-authors/) from Cancer Research UK for many good tips about blogging for an institution.\n\nThe new blog of course doesn't mean that I stop writing here. I'm too deep into this.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw8a","guid":"62d42bbd41e317003df48e65","id":"3e735e23-1af9-4718-8854-a1fd875dd434","image":"https://blog.front-matter.io/content/images/2022/08/5001818922_f30d953f07.jpeg","indexed_at":1,"language":"en","published_at":1287100800,"reference":[],"relationships":[],"summary":"In the last few weeks I haven\u2019t seen any announcement for a new science blogging network (the last one was probably Scientific American in September). So I thought today would be a good day to start a new one. Earlier today I wrote the first post on the first blog hosted by my institution.\n","tags":["News"],"title":"Today I started a new blogging network","updated_at":1660743111,"url":"https://blog.front-matter.io/posts/today-i-started-a-new-blogging-network"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/ncbi-adds-searchable-images-database","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"On Wednesday the NCBI released an [Images database](https://web.archive.org/web/20101124191025/http://www.ncbi.nlm.nih.gov/images), compiled from full text resources at the NCBI -- initially PubMed Central articles. The images can be searched by several parameters, e.g. figure caption or author.\n\nUsing this database, images are now displayed together with the PubMed abstract for PubMed Central articles. More info about these changes can be found in the [NLM Bulletin](https://web.archive.org/web/20101124191025/http://www.nlm.nih.gov/pubs/techbull/so10/so10_pm_display_ncbi_images.html).\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw82","guid":"62d42bbd41e317003df48e5d","id":"9d1843f1-59e7-4f4a-abfb-825a031dd199","image":"https://blog.front-matter.io/content/images/2022/08/images.jpeg","indexed_at":1,"language":"en","published_at":1288310400,"reference":[],"relationships":[],"summary":"On Wednesday the NCBI released an Images database, compiled from full text resources at the NCBI \u2013 initially PubMed Central articles. The images can be searched by several parameters, e.g. figure caption or author. Using this database, images are now displayed together with the PubMed abstract for PubMed Central articles. More info about these changes can be found in the NLM Bulletin.\n","tags":["News"],"title":"NCBI adds searchable images database","updated_at":1660742735,"url":"https://blog.front-matter.io/posts/ncbi-adds-searchable-images-database"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/researchers-reasons-for-publishing-their-work","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"When we want to change something, we have to look at the incentives for those involved.\n\n## References\n\nSwan, A. (2006) The culture of Open Access: researchers' views and responses. In: **Open Access: Key Strategic, Technical and Economic Aspects**, Chandos. [http://eprints.ecs.soton.ac.uk/12428](https://web.archive.org/web/20120611024948/http://eprints.ecs.soton.ac.uk/12428)\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw7s","guid":"62d42bbd41e317003df48e54","id":"927a5dd8-9224-4263-a4c4-c016ed06b1ec","image":"https://blog.front-matter.io/content/images/2022/08/swan-1.jpeg","indexed_at":1,"language":"en","published_at":1290902400,"reference":[{"key":"ref1","url":"https://web.archive.org/web/20120611024948/http:/eprints.ecs.soton.ac.uk/12428"}],"relationships":[],"summary":"When we want to change something, we have to look at the incentives for those involved.References  Swan, A. (2006) The culture of Open Access: researchers\u2019 views and responses. In:\n<em>\n <em>\n  Open Access: Key Strategic, Technical and Economic Aspects\n </em>\n</em>\n, Chandos.\n","tags":["Chart"],"title":"Researchers\u2019 reasons for publishing their work","updated_at":1660742539,"url":"https://blog.front-matter.io/posts/researchers-reasons-for-publishing-their-work"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/submission-fees-for-open-access-journals","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"In early December [Knowledge Exchange](https://web.archive.org/web/20120611025454/http://www.knowledge-exchange.info/), a partnership of JISC (United Kingdom), SURF (Netherlands), DEFF (Denmark), and DFG (Germany) [released a report](https://web.archive.org/web/20120611025454/http://www.knowledge-exchange.info/Default.aspx?ID=413) on submission fees that they had commissioned to [Mark Ware Consulting](https://web.archive.org/web/20120611025454/http://mrkwr.wordpress.com/mark-ware-consulting/). The report was also discussed by Robert Kiley on the [UK PubMed Central blog](https://web.archive.org/web/20120611025454/http://ukpmc.blogspot.com/2010/12/submission-fees-viable-business-model.html) and by Phil Davis on the [Scholarly Kitchen blog](https://web.archive.org/web/20120611025454/http://scholarlykitchen.sspnet.org/2010/12/09/open-access-submission-fees/).\n\nSubmission fees are more common than I thought, particularly in economics and the life sciences. The American Physiological Society journals, **Cancer Research**, **FASEB Journal**, **Journal of Clinical Investigation**, **Journal of Immunology** and **Journal of Neuroscience** all charge submission fees between \\$50 and \\$100, the **Journal of Biological Chemistry** dropped the \\$60 submission fee in 2010. Most journals that charge submission fees are society journals.\n\nThe report finds that submission fees would be particularly interesting for Open Access journals with high rejection rates (70% and more), as this would greatly reduce the article-processing charges for accepted manuscripts. A journal that accepts 10% of submitted papers could use a \\$150 submission fee to reduce the fee for accepted manuscripts from \\$2500 to \\$1150. There wouldn't really be a price reduction for journals that accept 50% of submitted papers.\n\nMark Ware reports that the Open Access publishers he talked to weren't really interested in starting submission fees for their journals, mainly because of the risks involved in changing their business model. I personally believe that submission fees may be the only option for journals with high rejection rates to become Open Access journals (unless you want to cross-subsidize those journals). I like submission fees because they help to cover the actual costs involved, instead of the costs of handling manuscripts that are ultimately rejected being paid either by journal subscribers or the authors of accepted manuscripts.\n\nThe full 13-page report can be downloaded [here](https://web.archive.org/web/20120611025454/http://www.knowledge-exchange.info/Files/Filer/downloads/Open%20Access/KE_Submission_fees_Short_Report_2010-11-25.pdf).\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw7m","guid":"62d42bbd41e317003df48e4f","id":"78eb4b31-8acf-46e4-b30e-0b42160708d5","image":"https://blog.front-matter.io/content/images/2022/08/2800029836_f351e8c826-1.jpeg","indexed_at":1,"language":"en","published_at":1291939200,"reference":[],"relationships":[],"summary":"In early December Knowledge Exchange, a partnership of JISC (United Kingdom), SURF (Netherlands), DEFF (Denmark), and DFG (Germany) released a report on submission fees that they had commissioned to Mark Ware Consulting. The report was also discussed by Robert Kiley on the UK PubMed Central blog and by Phil Davis on the Scholarly Kitchen blog. Submission fees are more common than I thought, particularly in economics and the life sciences.\n","tags":["Feature"],"title":"Submission Fees for Open Access Journals?","updated_at":1660742484,"url":"https://blog.front-matter.io/posts/submission-fees-for-open-access-journals"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/citations-are-links-so-where-is-the-problem","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"Citations are a fundamental concept of scholarly works. Unfortunately they are also difficult to do. Traditional writing tools such as Microsoft Word can't really handle them in a way that is appropriate for a scientific manuscript, and that is why we have reference managers such as Endnote, Zotero or Mendeley. And the lack of this functionality is a major reason that Google Docs and other online collaborative writing tools haven't become popular for writing scholarly works.\n\nUsing citations is hard for paper authors. The process is still complicated when using a reference manager, and it remains one of the more time consuming aspects of writing a manuscript. The main reason is that something always seems to go wrong with the formatting of the bibliography, but there are also issues of wrong or duplicate citations (including [citation mutations](https://web.archive.org/web/20120611074314/http://www.the-scientist.com/news/display/57698/)), correct citation styles, etc. I can't comment on how well BibTeX integrates citation management into LaTeX, but the main issue seems to be that citations usually are not one of the core functions of the writing tool.\n\n### WordPress and reference managers\n\nThe blogging platform ****WordPress**** could [become an excellent authoring platform](https://web.archive.org/web/20120611074314/http://blogs.plos.org/mfenner/2010/12/05/blogging-beyond-the-pdf/) for scientific papers. But to become successful, WordPress has to handle scholarly citations, and not just with copy and paste. Carl Boettinger [has written about doing citations in WordPress](https://web.archive.org/web/20120611074314/http://www.carlboettiger.info/archives/570) ealier this week and there is also an [ongoing FriendFeed discussion](https://web.archive.org/web/20120611074314/http://friendfeed.com/science-2-0/deef8494/how-do-you-manage-citations-when-writing-on-web). I have also looked at the available plugins, in particular [papercite](https://web.archive.org/web/20120611074314/http://wordpress.org/extend/plugins/papercite/) (based on [bib2html](https://web.archive.org/web/20120611074314/http://wordpress.org/extend/plugins/bib2html/)) which uses the BibTex format and is giving me some problems. I can't get the [CrossRef Citation plugin](https://web.archive.org/web/20120611074314/http://labs.crossref.org/site/blog_plugins.html) to work (SyntaxError: Parse error) and the [Mendeley Plugin](https://web.archive.org/web/20120611074314/http://wordpress.org/extend/plugins/mendeleyplugin/) is displaying bibliographies, rather than inserting citations. There is currently probably no easy solution to cite scholarly works in WordPress and I don't think that creating a WordPress Plugin for one of the reference managers is the right approach.\n\n### Citations are links\n\nIf we think about it, citations are nothing more than specialized links that contain additional information and formatting. And the references section is a list of footnotes. Links are a genuine part of WordPress, and this system should therefore also be used when writing scholarly works with WordPress. A Citation Plugin should extend this system, and solve these issues:\n\n-   WordPress isn't very smart about footnotes. I use the [WP-Footnotes](https://web.archive.org/web/20120611074314/http://www.elvery.net/drzax/wordpress-footnotes-plugin) Plugin, but we need additional functionality: avoid duplicates, formatting options of in-text citations (e.g. range of citations or author-year) and sorting of footnotes by occurence or name.\n-   The tool to create links in articles is not really integrated with the WordPress Links system (in contrast to images, where you have access to the media gallery when inserting an image).\n\nBoth of \u00a0these issues can be solved, especially since they are not specific to scholarly works and could be tackled by thousands of WordPress developers out there.\n\nWe don't want to use WordPress as a reference manager, as there are already many tools out there that can do this job much better. We rather want reference manager integration with WordPress, and the easiest way to do this would be an automatic synchronization with the WordPress Links database. We can already do this with the social bookmarking tool ****delicious**** (I use [DeliciousLinkSync](https://web.archive.org/web/20120611074314/http://wordpress.org/extend/plugins/wp-deliciouslinks/)), so it shouldn't be difficult to do this with the social bookmarking tools for scientists such as ****CiteULike**** (you can [sync CiteULike with delicious](https://web.archive.org/web/20120611074314/http://blog.citeulike.org/?p=174), a workaround I currently use), ****Connotea**** or ****BibSonomy****.\n\n### Links are powerful\n\nUsing the WordPress Links system makes it very easy to extend the core functionality, and many interesting tools are already out there. A good example is the [Broken Link Checker](https://web.archive.org/web/20120611074314/http://wordpress.org/extend/plugins/broken-link-checker/). The Plugin can regularly check the links in your blog posts, but could also be used to check DOIs for references in a semi-automated way. The Broken Link Checker found 30 broken links in the [Blogging Beyond the PDF sample article](https://web.archive.org/web/20120611074314/http://blogs.xartrials.org/2010/12/05/the-mycobacterium-tuberculosis-drugome-and-its-polypharmacological-implications-2/) (all my fault), and automatically changed the display style for them.\n\nAnd there is so much more that can be done with links. I am particularly interested in adding meaning to links using the Citation Typing Ontology ([CiTO](https://web.archive.org/web/20120611074314/http://dx.doi.org/10.1186/2041-1480-1-S1-S6)). And I want to be able to cite specific parts of an article. Dave Winer has [introduced](https://web.archive.org/web/20120611074314/http://scripting.com/stories/2010/10/21/newBloggingTechniques.html) paragraph-level permalinks to blogs, and I can do this on WordPress using the [WinerLinks Plugin](https://web.archive.org/web/20120611074314/http://danielbachhuber.com/2010/10/27/winerlinks-v0-2-released/). The broken links in my Blogging Beyond the PDF sample article are all internal links, and I can now use WinerLinks to fix them. An example where I have already done this is the reference to Table S8 in [this paragraph](https://web.archive.org/web/20120611074314/http://blogs.xartrials.org/2010/12/05/the-mycobacterium-tuberculosis-drugome-and-its-polypharmacological-implications-2/#p16).\n\n**Update on 12/11/10: I've installed the [Anotar Plugin](https://web.archive.org/web/20120611074314/http://ptsefton.com/2010/12/09/beyond-the-pdf-proposed-session-bring-the-web-to-the-researcher-mainly-on-authoring-tools.htm) by Peter Sefton that adds paragraph-level commenting.**\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw7n","guid":"62d42bbd41e317003df48e50","id":"8624943a-4621-42a3-8eab-95927c9388ea","image":"https://blog.front-matter.io/content/images/2022/08/4363633528_5026a5ce8b.jpeg","indexed_at":1,"language":"en","published_at":1292025600,"reference":[],"relationships":[],"summary":"Citations are a fundamental concept of scholarly works. Unfortunately they are also difficult to do. Traditional writing tools such as Microsoft Word can\u2019t really handle them in a way that is appropriate for a scientific manuscript, and that is why we have reference managers such as Endnote, Zotero or Mendeley.\n","tags":["Feature"],"title":"Citations are links, so where is the problem?","updated_at":1660742332,"url":"https://blog.front-matter.io/posts/citations-are-links-so-where-is-the-problem"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/occams-typewriter-please-welcome-a-new-science-blogging-network","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"Last Friday the latest science blogging network officially launched: [Occam's Typewriter](https://web.archive.org/web/20120612092936/http://occamstypewriter.org/). The independent blogging network started out with eight bloggers and one guest blog, [all of them well characterized](https://web.archive.org/web/20120612092936/http://scientopia.org/blogs/thisscientificlife/2010/12/12/occams-typewriter-here-at-last/) by Bob O'Hara. Most of the bloggers have moved their blogs from [Nature Network](https://web.archive.org/web/20120612092936/http://network.nature.com/), where I wrote next to them from 2007 until September this year.\n\nRichard, Jenny, Stephen, Austin, Frank, Erika, Cath and Henry, I wish you all good luck with the new blogging network.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw7k","guid":"62d42bbd41e317003df48e4e","id":"74f220b0-73f8-4c7a-8c1b-a4d9cf006a8f","image":"https://blog.front-matter.io/content/images/2022/08/occam.png","indexed_at":1,"language":"en","published_at":1292198400,"reference":[],"relationships":[],"summary":"Last Friday the latest science blogging network officially launched: Occam\u2019s Typewriter. The independent blogging network started out with eight bloggers and one guest blog, all of them well characterized by Bob O\u2019Hara. Most of the bloggers have moved their blogs from Nature Network, where I wrote next to them from 2007 until September this year.\n","tags":["News"],"title":"Occam\u2019s Typewriter: please welcome a new science blogging network","updated_at":1660742266,"url":"https://blog.front-matter.io/posts/occams-typewriter-please-welcome-a-new-science-blogging-network"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/digital-science-launched-closing-the-gap-between-science-and-technology","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"Two weeks ago ****Eva Amsen**** wrote in a thoughtful [blog post](https://web.archive.org/web/20120612094223/http://blogs.nature.com/eva/2010/12/05/a-metaphor-for-science-and-technology):\n\n> There's a gap between science and technology, and it's growing.\n\nEva argues that -- contrary to popular belief -- there is actually a divide between science and technology. Scientists are on average not really comfortable using technology, and many computing tools aimed for scientists really miss the point of what scientists really care about.\n\nTwo days later, on December 7, [Digital Science](https://web.archive.org/web/20120612094223/http://www.digital-science.com/), a new division of Macmillan Publishing launched. From the [press release](https://web.archive.org/web/20120612094223/http://international.macmillan.com/MediaArticle.aspx?id=2598):\n\n> Digital Science will focus on providing world-class software tools and services to scientists, managers and funders with the ultimate aim of making research more productive through the use of technology.\n\nInitial products include the chemical text-mining tool [SureChem Portal](https://web.archive.org/web/20120612094223/http://www.surechem.org/), the laboratory research management system [BioData](https://web.archive.org/web/20120612094223/http://www.biodata.com/) and the research information system [Symplectic Elements](https://web.archive.org/web/20120612094223/http://www.symplectic.co.uk/products/publications.html). You might see some familiar faces when you look at the Digital Science [team pictures](https://web.archive.org/web/20120612094223/http://www.digital-science.com/meet-the-team/).\n\nAs a big fan of using technology for science I am looking forward to what Digital Science will do in the coming months. I am particularly interested in their answer to the questions asked by Eva. Have they found a better way to understand what technologies scientists really want? Or are tools for digital science something that the majority of scientists don't really care about?\n\nRelated posts:\n\n-   Cameron Neylon: [Macmillan do interesting stuff](https://web.archive.org/web/20120612094223/http://cameronneylon.net/blog/macmillan-do-interesting-stuff/)\n-   Benjamin Good: [Digital Science launches](https://web.archive.org/web/20120612094223/http://i9606.blogspot.com/2010/12/digital-science-launches.html)\n-   John Dupuis: [Open Science Digital Computation Research](https://web.archive.org/web/20120612094223/http://scienceblogs.com/confessions/2010/12/open_digital_research_science.php)\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw7j","guid":"62d42bbd41e317003df48e4d","id":"718bdeaa-eac4-42db-9f4f-d6028fd7ca1b","image":"https://blog.front-matter.io/content/images/2022/08/3877930229_a84a550d0e.jpeg","indexed_at":1,"language":"en","published_at":1292630400,"reference":[],"relationships":[],"summary":"Two weeks ago\n<strong>\n <strong>\n  Eva Amsen\n </strong>\n</strong>\nwrote in a thoughtful blog post:There\u2019s a gap between science and technology, and it\u2019s growing. Eva argues that \u2013 contrary to popular belief \u2013 there is actually a divide between science and technology. Scientists are on average not really comfortable using technology, and many computing tools aimed for scientists really miss the point of what scientists really care about.\n","tags":["News"],"title":"Digital Science launched: closing the gap between science and technology?","updated_at":1660742178,"url":"https://blog.front-matter.io/posts/digital-science-launched-closing-the-gap-between-science-and-technology"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/paperpile-an-open-source-reference-manager-for-mac-and-linux","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"Last week the first public beta (version 0.5) of [Paperpile](https://web.archive.org/web/20120612092613/http://paperpile.com/) was released (available for Mac and Linux). Paperpile is a desktop reference manager with typical features: search in PubMed, Google Scholar or ArXiv, import PDF files, support for BibTex and other standard file formates, etc. Paperpile currently doesn't sync with a web-based version, and Paperpile doesn't insert citations into manuscripts.\n\nWhat is interesting about Paperpile is that the source code is available at [github](https://web.archive.org/web/20120612092613/https://github.com/wash/paperpile) (using the [GNU Affero General Public License](https://web.archive.org/web/20120612092613/http://www.gnu.org/licenses/)). Other reference managers that make their source code available include [Zotero](https://web.archive.org/web/20120612092613/https://www.zotero.org/trac), [JabRef](https://web.archive.org/web/20120612092613/http://sourceforge.net/apps/mediawiki/jabref/index.php?title=Developing_and_extending_JabRef) and [Connotea](https://web.archive.org/web/20120612092613/http://www.connotea.org/code).\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw7h","guid":"62d42bbd41e317003df48e4c","id":"a47f0f42-db90-41b4-95e2-a3908c191874","image":"https://blog.front-matter.io/content/images/2022/08/paperpile.jpeg","indexed_at":1,"language":"en","published_at":1293062400,"reference":[],"relationships":[],"summary":"Last week the first public beta (version 0.5) of Paperpile was released (available for Mac and Linux). Paperpile is a desktop reference manager with typical features: search in PubMed, Google Scholar or ArXiv, import PDF files, support for BibTex and other standard file formates, etc. Paperpile currently doesn\u2019t sync with a web-based version, and Paperpile doesn\u2019t insert citations into manuscripts.\n","tags":["News"],"title":"Paperpile: an open source reference manager for Mac and Linux","updated_at":1660742071,"url":"https://blog.front-matter.io/posts/paperpile-an-open-source-reference-manager-for-mac-and-linux"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/html5-or-messages-from-beyond-the-pdf","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"In 1990 Tim Berners-Lee and others started HTML and the world wide web to facilitate scientific communications at CERN, the world's largest particle physics laboratory.\n\nAlthough the world wide web profoundly changed scholarly publishing (and of course many other things), HTML did not become the standard document format for scientific papers. In fact, there is no standard document format. We have document formats for authors, for the internal workflow of publishers, and for the distribution and reading of papers.\n\nThere are of course many good reasons to use LaTeX for writing, XML for workflows, PDF to print papers or ePub for mobile devices. But reformatting a manuscript into different formats several times is both expensive (in terms of time and costs) and means that the formatting options used will be a compromise of what is available in all formats.\n\n<figure class=\"kg-card kg-image-card\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/5327592909_f00585d28e.jpeg\" class=\"kg-image\" loading=\"lazy\" width=\"500\" height=\"350\" alt=\"Scholarly Publishing Workflow\" />\n</figure>\n\nAll this would be much easier if we just used HTML. With HTML, authors, publishers and readers can all use the same document format. And they will have an endless number of tools at their hands, including of course [WordPress](https://web.archive.org/web/20120611084546/http://blogs.plos.org/mfenner/2010/12/05/blogging-beyond-the-pdf/) for writing and the web browser of choice for reading. HTML in 2010 is very different from HTML in 1990. HTML5 supports new semantic elements such as \\<article\\>, microdata, embedding of video without plugins, geolocation, and offline web applications.\n\nAn HTML-based scholarly publishing workflow will make it\n\n-   faster and cheaper to publish a paper,\n-   easier to create rich interactive documents,\n-   easier to add additional steps, such as integration of data from [lab notebooks](https://web.archive.org/web/20120611084546/http://www.axiope.com/), [publishing of pre-prints](https://web.archive.org/web/20120611084546/http://www.arxiv.org/), etc.\n-   easier to integrate additional services, from [data visualization](https://web.archive.org/web/20120611084546/http://cran.r-project.org/web/packages/googleVis/vignettes/googleVis.pdf) to [language editing](https://web.archive.org/web/20120611084546/http://languageediting.nature.com/editing-services).\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw7d","guid":"62d42bbd41e317003df48e48","id":"915028c9-1de5-4db2-a322-6b6fca6c602b","image":"https://blog.front-matter.io/content/images/2022/08/2429771653_68e45ff431.jpeg","indexed_at":1,"language":"en","published_at":1294185600,"reference":[],"relationships":[],"summary":"In 1990 Tim Berners-Lee and others started HTML and the world wide web to facilitate scientific communications at CERN, the world\u2019s largest particle physics laboratory. Although the world wide web profoundly changed scholarly publishing (and of course many other things), HTML did not become the standard document format for scientific papers. In fact, there is no standard document format.\n","tags":["Meeting Report"],"title":"HTML5 or messages from beyond the PDF","updated_at":1660741814,"url":"https://blog.front-matter.io/posts/html5-or-messages-from-beyond-the-pdf"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/having-fun-with-citations-at-scienceonline2011","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"[ScienceOnline2011](https://web.archive.org/web/20120611072611/http://scienceonline2011.com/), the fifth annual international meeting on Science and the Web, is only two days away. I am very excited for many reasons, most importantly because it gives me the chance to meet many online friends in person -- again or for the first time.\n\nOn Saturday I will help moderate two (related) sessions: ****How is the Web changing the way we identify scientific impact**** and ****Having fun with citations****. The first session will be about alternative ways to measure scientific impact, and about the alternative types of publications we can measure. The second session is all about citations. We use them all the time in scholarly communications, but we don't really think about them. To give a couple of examples: why are there so many different citation styles, why is it so difficult to find open bibliographic data, how can we describe why we decided to cite something, or how can we cite things that are not publications?\n\nSince I suggested this session a few months ago, my thinking about citations has changed. Citations should be easy to use, wherever we need them. Even though he have a number of clever [reference management tools](https://web.archive.org/web/20120611072611/http://blogs.plos.org/mfenner/reference-manager-overview/), the process is still too complicated. What would really help is an easier format for references, and the best format I can think of is the ubiquitous internet link. I have [written about links](https://web.archive.org/web/20120611072611/http://blogs.plos.org/mfenner/2010/12/11/citations-are-links-so-where-is-the-problem/) before, and I have spent the last few weeks to work on WordPress plugins to better handle links for scholarly works. Today I released the [Link to Link](https://web.archive.org/web/20120611072611/http://wordpress.org/extend/plugins/link-to-link/) plugin:\n\n<figure class=\"kg-card kg-image-card kg-card-hascaption\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/screenshot-1-500x432-1.png\" title=\"screenshot-1\" class=\"kg-image\" loading=\"lazy\" width=\"500\" height=\"432\" />\n<figcaption><em><em>Some science-related references in my WordPress Links Manager.</em></em></figcaption>\n</figure>\n\nThe Link to Link window in the WordPress editor should look familiar to users of traditional reference managers. You search for references and then insert them into the text. The references are stored in the WordPress Links Manager, and you can get them in there using the [BibTeX Importer](https://web.archive.org/web/20120611072611/http://wordpress.org/extend/plugins/bibtex-importer/) plugin I wrote two weeks ago. Both plugins are available from the WordPress plugins directory and can be installed directly from WordPress.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw7a","guid":"62d42bbd41e317003df48e45","id":"4eddf67c-29e9-4844-bca7-b2823e2fb8d9","image":"https://blog.front-matter.io/content/images/2022/08/screenshot-1-500x432.png","indexed_at":1,"language":"en","published_at":1294704000,"reference":[],"relationships":[],"summary":"ScienceOnline2011, the fifth annual international meeting on Science and the Web, is only two days away. I am very excited for many reasons, most importantly because it gives me the chance to meet many online friends in person \u2013 again or for the first time.\n","tags":["Meeting Report"],"title":"Having fun with citations at ScienceOnline2011","updated_at":1660741728,"url":"https://blog.front-matter.io/posts/having-fun-with-citations-at-scienceonline2011"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/datacite-visit-their-new-blog","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"[DataCite](https://web.archive.org/web/20120611041541/http://datacite.org/whatisdc.html) is an international consortium for data citation. DataCite originally started as a [project](https://web.archive.org/web/20120611041541/http://www.std-doi.de/front_content.php) at the [German National Library of Science and Technology (TIB)](https://web.archive.org/web/20120611041541/http://www.tib-hannover.de/).\n\nSince 2005 the TIB was providing digital object identifiers (DOIs) to research datasets. In December 2009 research libraries and technical information centres from 6 countries founded the DataCite initiative. In December 2010 DataCite reach an important milestone by registering the 1,000,000th DOI name.\n\nMany people are familiar with [CrossRef](https://web.archive.org/web/20120611041541/http://www.crossref.org/) which is providing DOIs for research papers. CrossRef is operated by Publishers International Linking Association (PILA), a non-profit organization formed by scholarly publishers in 2000. Think of DataCite as the counterpart that is providing DOIs for research data. And as research data are typically stored in data centers associated with technical information centers \u00a0- e.g. the British Library or the \u00a0Canada Institute for Scientific and Technical Information (CISTI) - and large research libraries (e.g. California Digital Library), DataCite members come from the academic community.\n\nThe TIB is located in Hannover, just a few miles away from Hannover Medical School where I work. In December I sat down with Jan Brase from the TIB, one of the driving forces behind DataCite and on its Board of Directors. We talked not only about DataCite, but also how DataCite could interoperate with [ORCID](https://web.archive.org/web/20120611041541/http://www.orcid.org/), the unique author identifier initiative (where I am a member of the Board). One of the [aims](https://web.archive.org/web/20120611041541/http://www.orcid.org/principles) of ORCID is to create a **permanent, clear and unambiguous record of scholarly communication,** and this of course includes not only publications, but also the contribution of research datasets. Gudmundur Thorisson gave a [nice presentation](https://web.archive.org/web/20120611041541/http://blogs.plos.org/mfenner/2010/09/07/orcid-as-unique-author-identifier-what-is-it-good-for-and-should-we-worry-or-be-happy/) about the possible integration of DataCite and ORCID in September.\n\nEarlier this week, Jan presented about DataCite at the [Academic Publishing in Europe](https://web.archive.org/web/20120611041541/http://www.ape2011.eu/) conference in Berlin. His slides are available on SlideShare, the video of his talk (like all the other presentations) will soon be available [here](https://web.archive.org/web/20120611041541/http://river-valley.tv/).\n\nAlso this week Jan started the [DataCite blog](https://web.archive.org/web/20120611041541/http://datacite.wordpress.com/). In his [first post](https://web.archive.org/web/20120611041541/http://datacite.wordpress.com/2011/01/13/some-more-details-on-2011/) (after the obligatory welcome post) Jan talks about the plans DataCite has for 2011. I am particularly excited about the central metadata repository that should be up and running by June. DataCite has allowed Thomson Reuters to crawl the repository so that the metadata will also appear in the [Web of Science](https://web.archive.org/web/20120611041541/http://thomsonreuters.com/products_services/science/science_products/a-z/web_of_science/). A lot of interesting stuff is going to happen in 2011 around unique identifiers for researchers and their scholarly works.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw79","guid":"62d42bbd41e317003df48e44","id":"8bdda369-ebe9-4a2d-ad47-9b27a5bdd828","image":"https://blog.front-matter.io/content/images/2022/08/datacite-screen-225.jpeg","indexed_at":1,"language":"en","published_at":1294963200,"reference":[],"relationships":[],"summary":"DataCite is an international consortium for data citation. DataCite originally started as a project at the German National Library of Science and Technology (TIB). Since 2005 the TIB was providing digital object identifiers (DOIs) to research datasets. In December 2009 research libraries and technical information centres from 6 countries founded the DataCite initiative.\n","tags":["News"],"title":"DataCite: visit their new blog","updated_at":1660741556,"url":"https://blog.front-matter.io/posts/datacite-visit-their-new-blog"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/epub-wordpress-plugin-released-today","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"The [Beyond the PDF](https://web.archive.org/web/20120628132920/https://sites.google.com/site/beyondthepdf/) workshop took place a little over a week ago. One take-home message for me was that [ePub is a very interesting](https://web.archive.org/web/20120628132920/http://blogs.plos.org/mfenner/2011/01/23/beyond-the-pdf-%E2%80%A6-is-epub) document format for scholarly publishing and has several advantages over PDF. The workshop had a wonderful spirit **to do something**, and in this spirit I wrote a WordPress plugin that automatically creates ePub files from blog posts. The plugin was [released today](https://web.archive.org/web/20120628132920/http://wordpress.org/extend/plugins/epub-export), and can be installed directly from your WordPress installation. A sample ePub can be downloaded from [this blog post](https://web.archive.org/web/20120628132920/http://blogs.xartrials.org/2011/01/09/embedding-adobe-illustrator-charts-in-wordpress-using-html5/), using the link at the bottom.\n\n<figure class=\"kg-card kg-image-card kg-card-hascaption\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/5406202716_43d1b632e0.jpg\" class=\"kg-image\" loading=\"lazy\" width=\"500\" height=\"375\" alt=\"Wordpress as ePub\" />\n<figcaption><em><em>The workshop example paper from PLoS Comp Biol, as seen on the iPad.</em></em></figcaption>\n</figure>\n\nThis is version 1.0 of the plugin, and there are a still a number of small bugs, mainly because ePub is a complex format. A big problem is page breaks, and [widows and orphans](https://web.archive.org/web/20120628132920/http://en.wikipedia.org/wiki/Widows_and_orphans) can currently only be avoided by workarounds. You can also see in the screenshot that the shortcode wasn't parsed for the ePub.\n\nBut these are minor issues that can be solved in the coming weeks. More interesting for version 1.1 is the inclusion of attachments (other than images) in the ePub. I have to do some more thinking on how to do this, especially how to handle all the possible mime types.\n\nI like reading science blogs in ePub format, using either Adobe Digital Editions on the Mac or iBooks on iPad and iPhone. This works particularly well for longer posts, e.g. those lovely posts from my science writer colleagues here on PLoS Blogs. If you have access to WordPress, then this plugin is one of the easiest ways to produce content in ePub format.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw76","guid":"62d42bbd41e317003df48e41","id":"221a671e-1805-4888-964d-abd1d5804358","image":"https://blog.front-matter.io/content/images/2022/08/5406202716_43d1b632e0.jpeg","indexed_at":1,"language":"en","published_at":1296518400,"reference":[],"relationships":[],"summary":"The Beyond the PDF workshop took place a little over a week ago. One take-home message for me was that ePub is a very interesting document format for scholarly publishing and has several advantages over PDF. The workshop had a wonderful spirit\n<em>\n <em>\n  to do something\n </em>\n</em>\n, and in this spirit I wrote a WordPress plugin that automatically creates ePub files from blog posts.\n","tags":["News"],"title":"ePub WordPress plugin released today","updated_at":1660741079,"url":"https://blog.front-matter.io/posts/epub-wordpress-plugin-released-today"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/opds-rss-for-epub-or-how-to-distribute-epub-files","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"ePub is a great [format for scholarly content](https://web.archive.org/web/20120611043846/http://blogs.plos.org/mfenner/2011/01/23/beyond-the-pdf-%E2%80%A6-is-epub/), and there are a [number of tools](https://web.archive.org/web/20120611043846/http://blogs.plos.org/mfenner/2011/02/01/epub-wordpress-plugin-released-today/) to create ePub files. But creating content is only half the story, at least as important is an easy mechanism for distribution. This is particularly true if your ePub files are not books, but shorter pieces of content: journal articles, blog posts or even output from your ongoing research. [RSS](https://web.archive.org/web/20120611043846/http://en.wikipedia.org/wiki/RSS) or the related Atom protocol has of course become the standard mechanism to publish frequently updated works.\n\nOpen Publication Syndication System ([OPDS](https://web.archive.org/web/20120611043846/http://code.google.com/p/openpub/wiki/CatalogSpecDraft#Introduction)) is a syndication format for electronic publications based on Atom. OPDS is a relatively new format, but is supported by a growing number of (book) publishers, ePub tools and readers. If you want to try OPDS for yourself, pick one the feeds listed [here](https://web.archive.org/web/20120611043846/http://code.google.com/p/openpub/wiki/AvailableFeeds) and add the feed as a Book source in the Stanza reader (in the ****Shared**** section). Alternatively, install the [EPUBReader plugin](https://web.archive.org/web/20120611043846/http://www.epubread.com/de/manual.php) for Firefox. As you can see, OPDS does more than just list titles with a summary and image, you can also categorize the content by author (or tag), and provide a search interface.\n\nI'm looking forward to the first scholarly publisher that not only provides ePub files of his journal articles, but also makes them available via OPDS. Although OPDS is currently used mostly for electronic books, I think that this is a very interesting protocol for scholarly publishers. Did I mention that OPDS also provides facilities for buying or lending content? And that you probably shouldn't expect OPDS support in the Apple iBooks application for iPhone and iPad anytime soon as they don't seem to like distributed content delivery? I would like to see scholarly publishers providing their journal content via ePub and OPDS that can be consumed with one of the many available readers, rather than everybody creating his own little app that only works with a single publisher on a single platform.\n\nOPDS is a relatively simple protocol and similar to RSS should make it easy for everybody to provide his content in catalog form. It should be straightforward to add OPDS support to the WordPress [ePub plugin](https://web.archive.org/web/20120611043846/http://wordpress.org/extend/plugins/epub-export/) that I released last week, thus making a blog (or blog network) available directly in the ePub reader. While I expect that we will continue to read most blogs via the Web or RSS reader, ePub might be the better format for longer posts and the posts you want to store on your computer.\n\nePub is a very interesting format for packaging research objects, e.g. the description and data files from an experiment. OPDS would be very helpful as a distribution mechanism for these ePubs, and also works on the small scale of a research group. You can for example use the Calibre eBook management tool -- which can create not only ePub files but also OPDS catalogs -- together with Dropbox to [share your content](https://web.archive.org/web/20120611043846/http://dearauthor.com/wordpress/2010/02/14/create-your-own-cloud-of-ebooks-with-calibre-calibre-opds-dropbox/). The [calibre2opds](https://web.archive.org/web/20120611043846/http://wiki.mobileread.com/wiki/Calibre2opds) tool also creates an OPDS catalog from the Calibre metadata database but doesn't require Calibre to run in order to use the OPDS catalog. And the [Pincette](https://web.archive.org/web/20120611043846/http://www.pincette.biz/index.xhtml) document management system automatically creates an OPDS catalog for the ePub files dropped into a Pincette folder. I hope that more tools for researchers start to support not only ePub but also OPDS. An OPDS interface to the data produced by your favorite piece of lab equipment (gel documentation system, microarray reader, etc.) would be an interesting sight.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw74","guid":"62d42bbd41e317003df48e3f","id":"8e38d9c5-ac81-479f-8a7d-4985a874d39f","image":"https://blog.front-matter.io/content/images/2022/08/OPDS-500x371.jpeg","indexed_at":1,"language":"en","published_at":1296950400,"reference":[],"relationships":[],"summary":"ePub is a great format for scholarly content, and there are a number of tools to create ePub files. But creating content is only half the story, at least as important is an easy mechanism for distribution. This is particularly true if your ePub files are not books, but shorter pieces of content: journal articles, blog posts or even output from your ongoing research.\n","tags":["Science Hack"],"title":"OPDS: RSS for ePub or how to distribute ePub files","updated_at":1660740954,"url":"https://blog.front-matter.io/posts/opds-rss-for-epub-or-how-to-distribute-epub-files"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/how-to-use-citation-typing-ontology-cito-in-your-blog-posts","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"One of the annoyances with bibliographies as we use them for scholarly papers is that is usually unclear why a particular paper was cited. It is often possible for readers to gather this information by looking at the citation in the context of the surrounding text, but this is very difficult to automate. A highly cited paper might contain a method that everybody uses, might be a review, or it might contain information that everybody disagrees with. David Shotton has thought a lot about this problem and has come up with [CiTO](https://web.archive.org/web/20120611093455/http://dx.doi.org/10.1186/2041-1480-1-S1-S6), the Citation Typing Ontology:\n\n> CiTO, the Citation Typing Ontology, is an ontology for describing the nature of reference citations in scientific research articles and other scholarly works, both to other such publications and also to Web information resources, and for publishing these descriptions on the Semantic Web.\n\nUsing CiTO obviously means extra work for the author, so for widespread use it is very important that CiTO is as easy to use as possible. The first step would be to reduce the number of possible relationships to a manageable number, e.g. not more than ten (CiTO defines more than 20 relationships). Following a dinner discussion at the [Beyond the PDF](https://web.archive.org/web/20120611093455/http://blogs.plos.org/mfenner/2010/11/06/beyond-the-pdf-it-is-time-for-a-workshop/) workshop, David Shotton kindly provided 10 popular CiTO relationships to Alex Wade from Microsoft Research and me. I made three little changes to the list: added \"cites\" as the default generic relationship, dropped \"shares authors with\", as this can be done better with [unique author identifiers](https://web.archive.org/web/20120611093455/http://blogs.plos.org/mfenner/2010/09/07/orcid-as-unique-author-identifier-what-is-it-good-for-and-should-we-worry-or-be-happy/), and added \"disagrees with\" to have at least one relationship that expresses disagreement.\n\nIn the next step I added these relationships to my [Link to Link](https://web.archive.org/web/20120611093455/http://blogs.plos.org/mfenner/2011/01/11/having-fun-with-citations-at-scienceonline2011/) WordPress plugin, and I released the updated version (1.1) today. Using CiTO is an option that can be turned off, but the plugin makes it very easy to use CiTO relationships when inserting references into a blog post.\n\nThe CiTO relationship is stored in the ****rel**** attribute of the link that is created -- currently as free-form text, but this can be changed to the ****cito:DisagreesWith**** format. This information can easily be extracted by computers, or made available in the bibliography to readers. The Reference Manager CiteULike is [also supporting CiTO](https://web.archive.org/web/20120611093455/http://opencitations.wordpress.com/2010/10/21/use-of-cito-in-citeulike/), but we need many more CiTO tools for authors.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw73","guid":"62d42bbd41e317003df48e3e","id":"222aa28e-eddf-493e-a5b9-9c70c2606863","image":"https://blog.front-matter.io/content/images/2022/08/cito-500x433-1.jpeg","indexed_at":1,"language":"en","published_at":1297641600,"reference":[],"relationships":[],"summary":"One of the annoyances with bibliographies as we use them for scholarly papers is that is usually unclear why a particular paper was cited. It is often possible for readers to gather this information by looking at the citation in the context of the surrounding text, but this is very difficult to automate.\n","tags":["Science Hack"],"title":"How to use Citation Typing Ontology (CiTO) in your blog posts","updated_at":1660740911,"url":"https://blog.front-matter.io/posts/how-to-use-citation-typing-ontology-cito-in-your-blog-posts"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/the-trouble-with-bibliographies","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"The bibliography of a scholarly paper is interesting and important reading material. You can see whether the authors have cited the relevant literature, and you often find references to interesting papers you didn't know about. Bibliographies are obviously also needed to count citations, and then do all kinds of useful and not so useful things with them.\n\nUnfortunately almost all bibliographies are in the wrong format. What you want is at least a direct link to the cited work using the DOI (if available), and a lot of journals do that. You don't want to have a link to PubMed using the PubMed ID as the only option (as in PubMed Central), as this requires a few more mouse clicks to get to the full-text article. And you don't want to go to an extra page, then use a link to search the PubMed database, and then use a few more mouse clicks to get to the full-text article (something that could happen to you with a PLoS journal).\n\nA bibliography should really be made available in a downloadable format such as BibTeX. Unfortunately journal publishers -- including Open Access publishers -- in most cases don't see that they can provide a lot of value here without too much extra work. One of the few publishers offering this service is BioMed Central -- feel free to mention other journals that do the same in the comments.\n\nThis weekend [Peter Murray-Rust invited Peter Sefton and me to Cambridge](https://web.archive.org/web/20120610124417/http://blogs.ch.cam.ac.uk/pmr/2011/03/04/scholarly-html-hackfest-and-visit-of-peter-sefton-and-martin-fenner/) (UK) for a very interesting workshop about ****Scholarly HTML****. Our goal is to discuss how we can define standards and build tools to make HTML the best platform for scholars and scholarly works. The event is in fact a hackfest, and we hope to have something to show by Sunday evening.\n\nMy idea for the hackfest is a tool that extracts all links (references and weblinks) out of a HTML document (or URL) and creates a bibliography. The generated bibliography should be both in HTML (using the [Citation Style Language](https://web.archive.org/web/20120610124417/http://blogs.plos.org/mfenner/2010/09/24/citation-style-language-an-interview-with-rintze-zelle-and-ian-mulvany/) ) and BibTex formats, and should ideally also support the Citation Typing Ontology ([CiTO](https://web.archive.org/web/20120610124417/http://blogs.plos.org/mfenner/2011/02/14/how-to-use-citation-typing-ontology-cito-in-your-blog-posts/)) and [COinS](https://web.archive.org/web/20120610124417/http://ocoins.info/) - \u00a0a standard to embed bibliographic metadata in HTML. I will use PHP as a programming language and will try to build both a generic tool and something that can work as a WordPress plugin. Obviously I will not start from scratch, but will reuse several already existing libraries. Any feedback or help for this project is much appreciated.\n\nIf I had a tool with which I could create my own bibliographies (and in the formats I want), I would no longer care so much about journals not offering this service. One big problem would still persist, and that is that most subscription journals wouldn't allow the redistribution of the bibliographies to their papers. A single citation can't have a copyright, but a compilation of citations can. I'm sure we will also discuss this topic at the workshop, as Peter Murray-Rust is one of the biggest proponents of [Open Bibliographic Data](https://web.archive.org/web/20120610124417/http://openbiblio.net/principles/).\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw72","guid":"62d42bbd41e317003df48e3d","id":"0876e02d-472e-4851-959a-01644098264a","image":"https://blog.front-matter.io/content/images/2022/08/5124103273_968a3c50cc.jpeg","indexed_at":1,"language":"en","published_at":1299456000,"reference":[],"relationships":[],"summary":"The bibliography of a scholarly paper is interesting and important reading material. You can see whether the authors have cited the relevant literature, and you often find references to interesting papers you didn\u2019t know about. Bibliographies are obviously also needed to count citations, and then do all kinds of useful and not so useful things with them. Unfortunately almost all bibliographies are in the wrong format.\n","tags":["Feature"],"title":"The Trouble with Bibliographies","updated_at":1660740856,"url":"https://blog.front-matter.io/posts/the-trouble-with-bibliographies"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/papers-2-the-reference-manager-made-with-love","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"The reference management software [Papers](https://web.archive.org/web/20120525044214/http://www.mekentosj.com/papers/) has been a regular topic on this blog. I wrote about Papers in one of my first blog posts in May 2008, [interviewed](https://web.archive.org/web/20120525044214/http://blogs.plos.org/mfenner/2008/10/03/interview_with_alexander_griekspoor/) main developer Alex Griekspoor in October 2008, and held a [poetry contest](https://web.archive.org/web/20120525044214/http://blogs.plos.org/mfenner/2009/02/19/papers_for_iphone_released_time_for_more_poetry/) when Papers for iPhone was released in February 2009 (Stephen Curry won the first price for [this poem](https://web.archive.org/web/20120525044214/http://blogs.plos.org/mfenner/2009/02/19/papers_for_iphone_released_time_for_more_poetry/#comment-898)).\n\n<figure class=\"kg-card kg-image-card\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/Papers-2c.jpg\" title=\"Papers 2c\" class=\"kg-image\" loading=\"lazy\" width=\"185\" height=\"263\" />\n</figure>\n\nToday Papers 2 [was released](https://web.archive.org/web/20120525044214/http://news.mekentosj.com/), and with this major update Papers has grown into a full-fledged reference manager for the Macintosh (there is no Windows or Linux version). Papers 1 was released in 2007 as a tool to manage the PDF files of scholarly papers on your hard drive. Papers 1 did this job very well, but it was not a reference manager in the strict sense, because you couldn't use Papers to insert citations into the manuscripts you were writing.\n\nIn order to add this feature, Papers first had to be completely rewritten to not only handle journal articles and the associated PDF files, but also all the other common reference formats -- conference proceeding, book chapter, website, etc. A nice side effect that I haven't fully explored yet is that Papers can now also store all your Powerpoint or Keynote presentations (but fulltext search in these presentations doesn't seem to work yet).\n\nInserting references into manuscripts is done using a floating window activated from the menu bar or with a shortcut:\n\n<figure class=\"kg-card kg-image-card\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/papers2-500x475-1.jpeg\" title=\"papers2\" class=\"kg-image\" loading=\"lazy\" width=\"500\" height=\"475\" />\n</figure>\n\nThis feature works similar to the plugins used by Endnote, Mendeley, Zotero, etc., but in typical Papers fashion the implementation is much nicer. The plugin is available to all applications, e.g. other word processors besides Microsoft Word, your blogging software or your email program.\n\nThe other big limitation of Papers 1 wasn't so obvious when Papers originally launched in 2007. But today most major reference managers allow users to [share their references](https://web.archive.org/web/20120525044214/http://blogs.plos.org/mfenner/reference-manager-overview/) in private and/or public groups, as most research is done in groups and most manuscripts are written by multiple authors.\n\nThe sharing feature of Papers 2 is called ****Livfe****. It is not as complete as the sharing features of some other reference managers (e.g. CiteULike or Mendeley). It is for example not yet possible to upload a complete Papers library to Livfe. And Livfe doesn't have a web interface, but only works through Papers.\n\n<figure class=\"kg-card kg-image-card\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/Papers-2a-500x243.jpg\" title=\"Papers 2a\" class=\"kg-image\" loading=\"lazy\" width=\"500\" height=\"243\" />\n</figure>\n\nThe difference between Papers 2 and other reference managers is not so much the feature set. What sets Papers really apart is the love that went into the design of the program. Papers doesn't just get the job done, it allows you to have fun searching for references or reading -- and now also writing -- a paper. This makes Papers 2 a strong competitor against some of the other established programs that for example have more than 25 years of experience with reference management (Endnote), think that reference management should be done as Open Source software (Zotero), do everything in the browser (Refworks), or see reference management primarily as a social application (Mendeley).\\\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw71","guid":"62d42bbd41e317003df48e3c","id":"3e701a53-cdcb-43da-969d-583e3796121d","image":"https://blog.front-matter.io/content/images/2022/08/papers2-500x475.jpeg","indexed_at":1,"language":"en","published_at":1299542400,"reference":[],"relationships":[],"summary":"The reference management software Papers has been a regular topic on this blog.\n","tags":["News"],"title":"Papers 2: the reference manager made with love","updated_at":1660740790,"url":"https://blog.front-matter.io/posts/papers-2-the-reference-manager-made-with-love"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/a-very-brief-history-of-scholarly-html","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"The history of HTML begins 1989 at [CERN](https://web.archive.org/web/20120610122136/http://info.cern.ch/), the European Laboratory for Particle Physics in Geneva. ****Tim Berners-Lee****, ****Robert Cailliau**** and colleagues invented HTML (as well as the transport protocol HTTP and the web browser) to facilitate collaboration between CERN physicists.\n\nHTML was originally invented for scholarly communication, but of course by the mid-1990s was also used by everybody else. But when electronic distribution of scholarly journal articles became possible, most publishers switched to PDF instead of HTML as the electronic document format of choice.\n\nIn April 2003 Inera, Mulberry Technologies and the NCBI published the [NLM Journal Archiving and Interchange DTD Suite](https://web.archive.org/web/20120610122136/http://www.inera.com/nlmresources.shtml) (NLM-DTD, read [here](https://web.archive.org/web/20120610122136/http://old.diglib.org/preserve/hadtdfs.pdf) about the history of this DTD Suite). The NLM-DTD has become the de facto XML standard for scholarly publishing and archiving. Although some tools for authors can write articles in this format (including Microsoft Word with the [Article Authoring Add-In](https://web.archive.org/web/20120610122136/http://blogs.plos.org/mfenner/2008/11/07/interview_with_pablo_fernicola/)), the NLM-DTD has never caught on as an authoring format for scholars and I'm not aware of any publisher accepting manuscripts written in this format.\n\nIn April 2009 \u00a0**Learned Publishing** published a paper by ****David Shotton**** titled [Semantic publishing: the coming revolution in scientific journal publishing](https://web.archive.org/web/20120610122136/http://dx.doi.org/10.1087/2009202){rel=\"cito:discusses\"}. David listed six rules for semantic publishers:\n\n1.  Start simply and improve functionality incrementally.\n2.  Expect greater things of your authors.\n3.  Exploit your existing in-house skills fully.\n4.  Use established standards wherever possible.\n5.  Publish raw datasets to the Web.\n6.  Release article metadata, particularly reference lists, in machine-readable form.\n\nAlthough the paper focuses on scholarly publishers, these rules also very much apply to what we could call Scholarly HTML today.\n\nAt about the same time (March 31, 2009) ****Peter Sefton**** for the first time used the term **Scholarly HTML** in a [blog post](https://web.archive.org/web/20120610122136/http://ptsefton.com/2009/03/31/scholarly-html.htm). He thinks that Scholarly HTML should allow the following:\n\n1.  Documents should definitely have headings.\n2.  Protocols for representing things like examples.\n3.  Metadata, using a linked data approach.\n4.  Links from terms mentioned in the text to ontologies that describe them.\n5.  Linkable paragraphs.\n6.  Dead simple reference management via links to trusted sources.\n\nIn January 2011 ****Phil Bourne**** organized the [Beyond the PDF](https://web.archive.org/web/20120610122136/http://blogs.plos.org/mfenner/2010/11/06/beyond-the-pdf-it-is-time-for-a-workshop/) workshop, and I was lucky to attend. We had a number of [interesting sessions](https://web.archive.org/web/20120610122136/http://river-valley.tv/conferences/beyondthepdf-2011) about how to improve the current scholarly paper published as PDF. I was involved in the working group thinking about better authoring tools, and one of my personal conclusions was that [ePub](https://web.archive.org/web/20120610122136/http://blogs.plos.org/mfenner/2011/01/23/beyond-the-pdf-%E2%80%A6-is-epub/) is a very interesting alternative to PDF if we need a packing format for HTML, e.g. for journal submission or archiving.\n\n****Peter Murray-Rust**** was able to capture the ideas of the authoring working group with a [drawing](https://web.archive.org/web/20120610122136/http://blogs.ch.cam.ac.uk/pmr/2011/02/09/scholarly-html-hackfest-cambridge-uk-march/), and he picked the term **Scholarly HTML** as the best description of what we want to achieve. He subsequently invited Peter Sefton, Brian McMahon and me (and a number of other people interested in Scholarly HTML) to a workshop that took place last weekend in Cambridge. Some of the thoughts of Peter Murray-Rust and Peter Sefton are summarized [here](https://web.archive.org/web/20120610122136/http://blogs.ch.cam.ac.uk/pmr/2011/03/14/scholarly-html-%e2%80%93-major-progress/) and [here](https://web.archive.org/web/20120610122136/http://ptsefton.com/2011/03/18/scholarly-html-fraglets-of-progress.htm). Two outcomes of the workshop are Scholarly HTML [Principles](https://web.archive.org/web/20120610122136/http://okfnpad.org/schtml-principles) and a [FAQ](https://web.archive.org/web/20120610122136/http://okfnpad.org/schtml-faqs).\n\nMy approach to Scholarly HTML is through developing WordPress plugins. The future will hopefully bring of a number of Scholarly HTML authoring tools, and WordPress will be just one of them. But Wordpress is a great platform to test ideas and improve them over time, or to quote David Shotton: **start simply and improve functionality incrementally**. One starting point has been citations in Scholarly HTML and we have already made [good progress](https://web.archive.org/web/20120610122136/http://okfnpad.org/schtml-citations).\n\nThe idea behind Scholarly HTML is not to build alternatives for Microsoft Word or LaTeX for authoring, but instead to build tools that will allow us to do something new and exciting with scholarly content. The trick here is to improve the scholarly document -- and the author should see the immediate benefit - without putting too much extra burden on the author. And this might in fact be the big challenge for Scholarly HTML.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw6z","guid":"62d42bbd41e317003df48e3a","id":"bfbf9416-36b1-4a1d-8b23-378e1405241b","image":"https://blog.front-matter.io/content/images/2022/08/4268841912_c2b34ca43c.jpeg","indexed_at":1,"language":"en","published_at":1300492800,"reference":[],"relationships":[],"summary":"The history of HTML begins 1989 at CERN, the European Laboratory for Particle Physics in Geneva.\n<strong>\n <strong>\n  Tim Berners-Lee\n </strong>\n</strong>\n,\n<strong>\n <strong>\n  Robert Cailliau\n </strong>\n</strong>\nand colleagues invented HTML (as well as the transport protocol HTTP and the web browser) to facilitate collaboration between CERN physicists.\n","tags":["Feature"],"title":"A very brief history of Scholarly HTML","updated_at":1660740657,"url":"https://blog.front-matter.io/posts/a-very-brief-history-of-scholarly-html"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/web-tools-for-searching-the-biomedical-literature-part-ii","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"Ten days ago I [mentioned](https://web.archive.org/web/20120610114233/http://blogs.plos.org/mfenner/2011/04/29/web-tools-for-searching-the-biomedical-literature-part-i/) a paper by Zhiyong Lu that gives an overview over the available web tools to search the biomedical literature. Most of these tools enhance the PubMed service, and Zhiyong Lu in fact works for the NCBI, the developer of PubMed. In this post I want to take a more detailed look at the available tools.\n\nA good starting point is the [companion webpage](https://web.archive.org/web/20120610114233/http://www.ncbi.nlm.nih.gov/CBBresearch/Lu/search/) to the paper, listing 28 services. One of the most painful shortcomings of PubMed is the sorting of results by date. Zhiyong lists 8 tools that can present search results sorted by relevance. Semantic search, seeking relevant concepts, and visualization of search results are all offered by several tools. Three tools will identify similar publications, and three tools will find potential experts, reviewers or collaborators. It is a good sign that there are so many tools that integrate with PubMed -- in addition to the reference managers (e.g. Endnote, Papers) that do the same.\n\nThe analysis has one important shortcoming: only tools that specifically cover the biomedical literature are discussed. General purpose search tools such as ****Web of Science****, ****Scopus****, ****Google Scholar**** or ****Microsoft Academic Search**** are therefore not covered, neither are online bibliographic tools such as ****Mendeley**** and ****CiteULike****. All of them also include biomedical literature -- although the coverage at the fairly new Microsoft Academic Search is still limited. They all offer unique features not found in Pubmed or the 28 tools discussed in the paper.\n\nWhen I think about how I find interesting articles, then it is increasingly through my social networks - including this paper by Zhiyong Lu. His paper unfortunatel fails to discuss this important search strategy. Twitter, FriendFeed, science blogs, etc. are strange places to find interesting literature, but they work for me. [This April 22 post](https://web.archive.org/web/20120610114233/http://www.massgenomics.org/2011/04/whole-genome-sequencing-for-cancer-patients.html) on the wonderful ****Massgenomics**** blog alerted me to two interesting papers published in JAMA on April 20 that describe the use of whole-genome sequencing in the care of two patients with acute leukemia. I presented the paper by Welch et al. in a journal club last Friday and we had a very interesting discussion.\n\nThe paper has also been discussed in the following places: [Dragonfly](https://web.archive.org/web/20120610114233/http://nnlm.gov/pnr/dragonfly/2011/02/15/beyondpubmed/), [Center on Media and Child Health](https://web.archive.org/web/20120610114233/http://cmch.typepad.com/cmch/2011/03/res.html), [Bernard Becker Medical Library](https://web.archive.org/web/20120610114233/http://beckerinfo.net/scp/2011/04/29/pubmed-and-beyond-a-survey-of-web-tools-for-searching-biomedical-literature/), [Medical Information Matters](https://web.archive.org/web/20120610114233/http://laikaspoetnik.wordpress.com/2011/05/08/3rd-call-for-submissions-for-medical-information-matters-tools-for-searching-the-biomedical-literature/), [Friendly Fire](https://web.archive.org/web/20120610114233/http://autoimmunbuch.de/?p=447) (German), [Usalbiomedica](https://web.archive.org/web/20120610114233/http://usalbiomedica.wordpress.com/2011/05/05/pubmed-and-beyond-a-survey-of-web-tools-for-searching-biomedical-literature/) (Spanish). This post is my much-delayed contribution to the [medlib's round](https://web.archive.org/web/20120610114233/http://blogcarnival.com/bc/cprof_6092.html) blog carnival. Unfortunately I haven't received any submissions since my call on April 29, but I probably didn't do enough advertising.\n\n## References\n\n****Lu Z.**** PubMed and beyond: a survey of web tools for searching biomedical literature. **Database**. 2011 Jan;2011. doi: [http://doi.org/10.1093/database/baq036](https://doi.org/10.1093/database/baq036).\n\n****Welch JS, Westervelt P, Ding L, Larson DE, Klco JM, Kulkarni S, et al****. Use of whole-genome sequencing to diagnose a cryptic fusion oncogene. **JAMA : the journal of the American Medical Association**. 2011 Apr;305(15):1577-1584. doi: \u00a0[http://doi.org/10.1001/jama.2011.497](https://doi.org/10.1001/jama.2011.497).\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw6s","guid":"62d42bbd41e317003df48e34","id":"16838fc4-94c6-44c2-8621-b6e657f331a1","image":"https://blog.front-matter.io/content/images/2022/08/pubmed-500x177.png","indexed_at":1,"language":"en","published_at":1304899200,"reference":[{"doi":"https://doi.org/10.1093/database/baq036","key":"ref1"},{"doi":"https://doi.org/10.1001/jama.2011.497","key":"ref2"}],"relationships":[],"summary":"Ten days ago I mentioned a paper by Zhiyong Lu that gives an overview over the available web tools to search the biomedical literature. Most of these tools enhance the PubMed service, and Zhiyong Lu in fact works for the NCBI, the developer of PubMed. In this post I want to take a more detailed look at the available tools. A good starting point is the companion webpage to the paper, listing 28 services.\n","tags":["Feature"],"title":"Web Tools for Searching the Biomedical Literature \u2013 part II","updated_at":1660740429,"url":"https://blog.front-matter.io/posts/web-tools-for-searching-the-biomedical-literature-part-ii"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/schema-org-for-scholarly-html","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"Last Thursday the search engines Google, Bing and Yahoo [announced](https://web.archive.org/web/20120525041638/http://googleblog.blogspot.com/2011/06/introducing-schemaorg-search-engines.html) [schema.org](https://web.archive.org/web/20120525041638/http://schema.org/), a new initiative for structured data markup on the web. Websites that use this schema to markup their data (more than 100 data types are supported) will make it easier for the three largest web search engines to find their content. Schema.org uses microdata, not microformats or RDFa, according to the [FAQ](https://web.archive.org/web/20120525041638/http://schema.org/docs/faq.html#15) this was a pragmatic decision.\n\nSchema.org also defines the [ScholarlyArticle](https://web.archive.org/web/20120525041638/http://schema.org/ScholarlyArticle), but unfortunately this data type doesn't add any properties beyond those of the parent [Article](https://web.archive.org/web/20120525041638/http://schema.org/Article) (e.g. the Digital Object Identifier). The [Person](https://web.archive.org/web/20120525041638/http://www.schema.org/Person) data type is also interesting (and uses a professor as an example), but for example doesn't include an ****isAuthor**** relationship.\n\nIt will be interesting to see whether future versions of the schema.org standard will have better support for scholarly content, and how well this microformat can be integrated into our efforts to create [Scholarly HTML](https://web.archive.org/web/20120525041638/http://scholarlyhtml.org/). And how quickly scholarly publishers and other providers of scholarly content will adopt this new standard., which in its current form already is a big improvement over plain HTML.\n\n*Update (6/7/11): Google today [announced](https://web.archive.org/web/20120525041638/http://insidesearch.blogspot.com/2011/06/authorship-markup-and-web-search.html) support for authorship markup, either via the schema.org format or using the ****rel**** attribute.*\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw6r","guid":"62d42bbd41e317003df48e33","id":"5c398d37-cdf3-4078-86d6-5b0c7207b632","image":"https://blog.front-matter.io/content/images/2022/08/schema-500x456.jpeg","indexed_at":1,"language":"en","published_at":1307404800,"reference":[],"relationships":[],"summary":"Last Thursday the search engines Google, Bing and Yahoo announced schema.org, a new initiative for structured data markup on the web. Websites that use this schema to markup their data (more than 100 data types are supported) will make it easier for the three largest web search engines to find their content. Schema.org uses microdata, not microformats or RDFa, according to the FAQ this was a pragmatic decision.\n","tags":["News"],"title":"Schema.org for Scholarly HTML?","updated_at":1660733475,"url":"https://blog.front-matter.io/posts/schema-org-for-scholarly-html"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/google-scholar-citations-researcher-profiles-and-why-we-need-an-open-bibliography","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"Last week Google Scholar [announced a new feature](https://web.archive.org/web/20120610140256/http://googlescholar.blogspot.com/2011/07/google-scholar-citations.html) on the Google Scholar Blog: ****Google Scholar Citations****. The stated purpose of this tool is to allow researchers to calculate their citation metrics, e.g. their [Hirsch index](https://web.archive.org/web/20120610140256/http://blogs.plos.org/mfenner/2007/08/17/do_you_know_your_hirsch_number/) (H-index).\n\nThis is an interesting new service, that not only helps with calculating citation metrics, but also shows you who is citing your papers -- a great discovery tool. Signup to Google Scholar Citations is currently limited, but I was able to create a profile [here](https://web.archive.org/web/20120610140256/http://scholar.google.com/citations?user=N05QljgAAAAJ&hl=en).\n\nThe problem? We have this service already. ****Scopus****, ****Researcher ID**** and others have provided this information for some time, and Google Scholar Citations looks very much like a response to the recently launched Microsoft Academic Search:\n\n<figure class=\"kg-card kg-image-card\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/SafariSnapshot002-500x349.jpeg\" title=\"SafariSnapshot002\" class=\"kg-image\" loading=\"lazy\" width=\"500\" height=\"349\" />\n</figure>\n\nWill we soon see a similar offering from ****Mendeley**** or ****ResearchGate****? There is of course nothing wrong with competition, and there is no reason why we can't have more than one place that provides researcher profiles. But as I have [argued before](https://web.archive.org/web/20120610140256/http://blogs.plos.org/mfenner/scientific-attribution-principles/),\n\n****Systems that measure and evaluate scientific contributions can and should be separate from the databases that hold the scholarly record.****\n\nIt is not only a waste of resources (both Google Scholar's and the individual researchers' who maintain their profiles) to many many different bibliographic databases, but it also makes it impossible to compare citation metrics. In the examples above Alonzo Church has a H-index of 19 at Google Scholar, but only 11 at Microsoft Academic Search (and probably again a different one somewhere else). This means that we can only use an H-index when we mention where (and when) it was calculated.\n\nThe better solution is a common [open bibliography](https://web.archive.org/web/20120610140256/http://3lib.org/), and the difference between the various service would be how they calculate the citation metric or present the bibliographic data -- you can see the different approaches taken by Google Scholar and Microsoft Academic Search in the screenshots above. This is a difficult task, but not impossible to do. The first step would be to realize that having a common open bibliography would create tremendous value for everybody as we can start building tools on top this bibliography without requiring to collect all the bibliographic data ourselves. We see something like this happening in smaller domains, and the [tools using the PubMed database](https://web.archive.org/web/20120610140256/http://blogs.plos.org/mfenner/2011/04/29/web-tools-for-searching-the-biomedical-literature-part-i/) are a good example.\n\nFrom a researcher perspective it makes little sense to have many different places where you can maintain your publications. It makes much more sense to do this once and then see the information reused in different services. This is the approach the Open Researcher & Contributor ID initiative is [taking](https://web.archive.org/web/20120610140256/http://www.orcid.org/principles):\n\n****All profile data contributed to ORCID by researchers or claimed by them will be available in standard formats for free download (subject to the researchers' own privacy settings) that is updated once a year and released under the CC0 waiver.****\n\n**Disclaimer: I sit on the Board of Directors of the Open Researcher & Contributor ID (ORCID) initiative which aims to help solve this and related problems.**\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw6h","guid":"62d42bbd41e317003df48e2c","id":"bdc80f85-777e-41ce-b06c-99895c113182","image":"https://blog.front-matter.io/content/images/2022/08/SafariSnapshot001-500x306.jpeg","indexed_at":1,"language":"en","published_at":1311724800,"reference":[],"relationships":[],"summary":"Last week Google Scholar announced a new feature on the Google Scholar Blog:\n<strong>\n <strong>\n  Google Scholar Citations\n </strong>\n</strong>\n. The stated purpose of this tool is to allow researchers to calculate their citation metrics, e.g. their Hirsch index (H-index). This is an interesting new service, that not only helps with calculating citation metrics, but also shows you who is citing your papers \u2013 a great discovery tool.\n","tags":["News"],"title":"Google Scholar Citations, Researcher Profiles, and why we need an Open Bibliography","updated_at":1660733291,"url":"https://blog.front-matter.io/posts/google-scholar-citations-researcher-profiles-and-why-we-need-an-open-bibliography"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/book-review-visualize-this-by-nathan-yau","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"In July Wiley published the book ****[Visualize This -- The Flowing Data Guide to Design, Visualization and Statistics](https://web.archive.org/web/20120611111645/http://book.flowingdata.com/)****. The book is written by **Nathan Yau**, and he is of course also behind the popular [FlowingData](https://web.archive.org/web/20120611111645/http://flowingdata.com/) blog about the same topic. This is a short review of the book.\n\nPlease keep in mind that I'm no expert in data visualization. The book is written for people like me, an expert in the topic will probably look at the book differently.\n\nAnd the book is intended as an introduction to important concepts. It is probably the wrong book if you are interested in using a particular tool -- e.g. Adobe Illustrator, R or Flash -- for Data Visualization.\n\nThe examples in the book are about topics similar to those used in the FlowingData blog, most of them are about data journalism. This is not a book about visualization of scientific experiments.\n\nThe first chapter of the book talks about how to tell stories with data. This is a very important chapter, as learning how to tell a good story is more important than knowing all the details on how to use a tool for visualization.\n\nNathan continues with a chapter on how to find and format data for data visualization. We are then introduced to a number of important visualization tools, and their particular strengths. Nathan uses a large number of tools in the book, but seems to particularly like Python for formatting data, R for for calculation and visualization, and Adobe Illustrator for perfecting the result for publication. This is one of the take-home messages of the book for me: instead of perfecting the use of one particular tool, learn to decide what works best for a particular problem. R and Illustrator are a good start for most problems.\n\nThe next few chapters look at visualizations in different contexts: patterns over time, proportions, relationships, differences and spatial relationships. All chapters are written with examples that you can follow along, and with enough basic information that you can start solving similar problems on your own. Below is a chart I tried myself after reading the book. It looks at the number of member organizations of the non-profit ORCID over time (more info [here](https://web.archive.org/web/20120611111645/http://www.orcid.org/news/250-participating-organizations-have-joined-orcid)).\n\n<figure class=\"kg-card kg-image-card\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/orcid-500x400.png\" title=\"orcid\" class=\"kg-image\" loading=\"lazy\" width=\"500\" height=\"400\" />\n</figure>\n\nI can highly recommend ****Visualize This**** to anybody interested in learning about data visualization. I found only two things I didn't like. I wish Nathan had spent more time explaining how a data graph can be improved visually. In many examples he shows how small changes in color or font size can make a big difference in presentation, but I would prefer to see a more systematic approach to this important topic. I wouldn't mind if he would drop the chapter on [Chernoff faces](https://en.wikipedia.org/wiki/Chernoff_face) instead -- fun stuff, but not really important in an introductory text.\n\nMy other problem is with the publisher. I read the book as ePub on my iPad. It is nice to have web links you can click in the text, but it would have been even nicer if the ePub had ben prepared with a little bit more care. Most images in the text (there are many) are too small -- in an ePub you expect figures to enlarge and show more detail when you click on them. And figure headings were regularly orphaned (on a different page than the figure itself). ePub is an evolving standard, but a little bit of consideration for typography and layout would go a long way.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw6f","guid":"62d42bbd41e317003df48e2a","id":"38cc803d-be7b-413a-bc4f-ded000c2b120","image":"https://blog.front-matter.io/content/images/2022/08/visualize-this-drop.jpg","indexed_at":1,"language":"en","published_at":1313193600,"reference":[],"relationships":[],"summary":"In July Wiley published the book\n<strong>\n <strong>\n  Visualize This \u2013 The Flowing Data Guide to Design, Visualization and Statistics\n </strong>\n</strong>\n. The book is written by\n<em>\n <em>\n  Nathan Yau\n </em>\n</em>\n, and he is of course also behind the popular FlowingData blog about the same topic. This is a short review of the book. Please keep in mind that I\u2019m no expert in data visualization.\n","tags":["Book Review","Chart"],"title":"Book Review: Visualize This by Nathan Yau","updated_at":1660733108,"url":"https://blog.front-matter.io/posts/book-review-visualize-this-by-nathan-yau"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/personal-names-around-the-world","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"Yesterday I discovered (via a tweet by [Owen Stephens](https://web.archive.org/web/20120610133741/https://twitter.com/#!/ostephens)) a very interesting document [Personal names around the world](https://web.archive.org/web/20120610133741/http://www.w3.org/International/questions/qa-personal-names) that discusses the following question:\n\n> How do people's names differ around the world, and what are the implications of those differences on the design of forms, databases, ontologies, etc. for the Web?\n\nThe document was written by [Richard Ishida](https://web.archive.org/web/20120610133741/http://rishida.net/), Internationalization Activity Lead at the [W3C](https://web.archive.org/web/20120610133741/http://www.w3.org/International/) (World Wide Web Consortium). The document was published on July 26, and Richard was seeking comments until August 7 before finalizing the document.\n\nThe document is a good summary how names for people differ around the world, e.g. multiple family names (Spain, Latin America), no family name (Iceland), different ordering of names (China, Korea, Japan), non-latin characters in names (many countries), and other issues.\n\nThe second part of the document makes a few suggestions of how these variations in names could be handled on the web. The text should be required reading for anybody who is designing databases that handle international names -- and there are a lot of them. A form that asks for ****first name****, ****middle initial**** and ****last name**** will just not be appropriate for a lot of people.\n\nI am lucky that my German name doesn't contain any German umlauts (\u00e4, \u00f6, \u00fc) or the letter \u00df, so I haven't had any bad (or funny) experiences with my name. But I know that it can be a big problem for a lot of people. The result is that people end up having several spellings for their name, or write their name in ways that were not intended, e.g. a hyphen between the two family names in Spain. The name is something very personal, and I think the least we can do is to allow people to use their name appropriately.\n\nScience is probably no better or worse in this regard than other domains. If we are lucky, we find a journal that prints our name correctly, or have a database that understands that \u00fc should be sorted as ue. But for the most part, this seems to be an unresolved issue. And I don't want everybody to start using a first name and last name in that order and only with ASCII or latin characters. That would be boring. So please start thinking about this issue when you design systems that use personal names, and use the W3C document by Richard Ishida as a starting point.\n\n**Disclaimer: I sit on the Board of Directors of the Open Researcher & Contributor ID (ORCID) initiative which aims to help solve this and related problems.**\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw6e","guid":"62d42bbd41e317003df48e29","id":"26df5759-b960-4945-b24e-8d4c4faaf5ce","image":"https://blog.front-matter.io/content/images/2022/08/noname.jpeg","indexed_at":1,"language":"en","published_at":1313280000,"reference":[],"relationships":[],"summary":"Yesterday I discovered (via a tweet by Owen Stephens) a very interesting document Personal names around the world that discusses the following question:How do people\u2019s names differ around the world, and what are the implications of those differences on the design of forms, databases, ontologies, etc. for the Web?\n","tags":["Feature"],"title":"Personal names around the world","updated_at":1660732956,"url":"https://blog.front-matter.io/posts/personal-names-around-the-world"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/zotero-3-0-beta-released-works-with-chrome-and-safari","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"The first beta of the reference manager Zotero 3.0 was [released](https://web.archive.org/web/20120525045252/http://www.zotero.org/blog/announcing-zotero-3-0-beta-release/) yesterday. The big news is that Zotero 3.0 no longer only runs within the Firefox browser, but is now also available as a standalone version similar to other reference managers.\n\nZotero Connectors integrate with the Chrome and Safari browser. They also allow saving directly to your Zotero library at zotero.org. Zotero does not support Internet Explorer. Users of this blog are not representative of all internet users, and Zotero 3.0 would offer browser support for more than 80% of them.\n\n<figure class=\"kg-card kg-image-card\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/YNgML-web-browsers-used-by-gobbledygook-readers-august-2011.png\" title=\"analytics\" class=\"kg-image\" loading=\"lazy\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/YNgML-web-browsers-used-by-gobbledygook-readers-august-2011.png 600w, https://blog.front-matter.io/content/images/size/w1000/2022/08/YNgML-web-browsers-used-by-gobbledygook-readers-august-2011.png 1000w, https://blog.front-matter.io/content/images/2022/08/YNgML-web-browsers-used-by-gobbledygook-readers-august-2011.png 1240w\" sizes=\"(min-width: 720px) 720px\" width=\"1240\" height=\"1096\" />\n</figure>\n\nZotero 3.0 is beta software and you should expect bugs. One small problem I discovered is that the German translation is incomplete, e.g. in the menus. But overall Zotero looks and feels very similar to the familiar Zotero 2.1 -- just as a standalone version. One new feature I like is duplicate detection, an experimental feature of earlier versions.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw6d","guid":"62d42bbd41e317003df48e28","id":"239e5c98-8eae-41f8-9c32-ad8b2f9596ed","image":"https://blog.front-matter.io/content/images/2022/08/zotero-500x328-1.png","indexed_at":1,"language":"en","published_at":1314057600,"reference":[],"relationships":[],"summary":"The first beta of the reference manager Zotero 3.0 was released yesterday. The big news is that Zotero 3.0 no longer only runs within the Firefox browser, but is now also available as a standalone version similar to other reference managers. Zotero Connectors integrate with the Chrome and Safari browser. They also allow saving directly to your Zotero library at zotero.org. Zotero does not support Internet Explorer.\n","tags":["News"],"title":"Zotero 3.0 Beta released, works with Chrome and Safari","updated_at":1660732816,"url":"https://blog.front-matter.io/posts/zotero-3-0-beta-released-works-with-chrome-and-safari"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/announcing-sciencecard","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"Metrics for scholarly works are used for evaluation and discovery. The Journal Impact Factor is widely used, but is not the best tool to look at the metrics of an individual article. In the past few years we finally started to have the technology to do article-level metrics (citations, downloads, etc.) and PLoS has [pushed this concept](https://web.archive.org/web/20120610140041/http://article-level-metrics.plos.org/) since at least 2009. I first heard about the PLoS Article-Level Metrics project in a presentation given by Pete Binfield in July 2009, and a month later I [interviewed him](https://web.archive.org/web/20120610140041/http://blogs.plos.org/mfenner/2009/08/15/plos_one_interview_with_peter_binfield/) about this project.\n\nArticle-level metrics are a major step forward from journal-level metrics, but I always wanted to extend this concept to authors. Three events in the past few weeks worked nicely together and made me start an author-level metrics project myself: [programming contest by Mendeley and PLoS](https://web.archive.org/web/20120610140041/http://dev.mendeley.com/api-binary-battle) with a September 30 deadline, a hackfest following the [Science Online London Conference](https://web.archive.org/web/20120610140041/http://www.scienceonlinelondon.org/) in early September, and two conferences (in [Helsinki](https://web.archive.org/web/20120610140041/http://irisc-workshop.org/irisc2011-helsinki/) and [Geneva](https://web.archive.org/web/20120610140041/http://www.orcid.org/civicrm/event/info?id=2&reset=1)) in mid-September discussing the value of unique author identifiers for researchers.\n\nI've taken the [Open Source Article-Level Metrics API Server](https://web.archive.org/web/20120610140041/http://code.google.com/p/alt-metrics/) from PLoS and added a few important features: metrics by author, additional metrics from Mendeley and Microsoft Academic Search, and a web-based interface that less authors register via their Twitter account. The result is [ScienceCard](https://web.archive.org/web/20120610140041/http://sciencecard.org/), a website I launched this weekend and today entered for the Mendeley/PLoS Binary Battle contest. ScienceCard currently uses [Microsoft Academic Search](https://web.archive.org/web/20120610140041/http://code.google.com/p/alt-metrics/) to find all papers of a particular author, the next version will allow users to retrieve info about their personal papers from Mendeley.\n\nWorking on ScienceCard has already taught me a lot about the problems we face when doing metrics for scholarly works. Most problems are social and not technical. Digital object identifiers (DOIs) for example have been the standard identifier for journal articles for ten years, but many places (including PubMed, Microsoft Academic Search and Mendeley) want users to use their own identifiers for journal articles. This makes it unnecessarily difficult to find articles and collect metrics. Identifiers for authors are even more complicated. ScienceCard will of course use [ORCID](https://web.archive.org/web/20120610140041/http://orcid.org/) identifiers when they become available in 2012, and I hope that I can make the transition to ORCID easier for ScienceCard users.\n\nLet me know what you think.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw6a","guid":"62d42bbd41e317003df48e25","id":"f55f9cf9-f30a-4ad9-9973-56bc2666ac08","image":"https://blog.front-matter.io/content/images/2022/08/sciencecard-500x345.jpeg","indexed_at":1,"language":"en","published_at":1317168000,"reference":[],"relationships":[],"summary":"Metrics for scholarly works are used for evaluation and discovery. The Journal Impact Factor is widely used, but is not the best tool to look at the metrics of an individual article. In the past few years we finally started to have the technology to do article-level metrics (citations, downloads, etc.) and PLoS has pushed this concept since at least 2009.\n","tags":["News"],"title":"Announcing ScienceCard","updated_at":1660732724,"url":"https://blog.front-matter.io/posts/announcing-sciencecard"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/the-trouble-with-dois","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"[ScienceCard](https://web.archive.org/web/20120610120821/http://sciencecard.org/) is a new service that I started last month with the simple idea to automatically track all journal articles of a given author, and to collect the article-level metrics (citations, bookmarks, etc.) for these papers. ScienceCard requires unique identifiers for articles and authors to work. Unique identifiers for authors is a difficult topic [regularly discussed](https://web.archive.org/web/20120610120821/http://blogs.plos.org/mfenner/tag/orcid/) in this blog. But I thought that using digital object identifiers (DOI) for journal articles would be easy. The system managed by CrossRef was started 10 years ago, and almost all journal publishers now use DOIs -- there were 49,350,542 registered CrossRef DOI links as of today.\n\nThe first problem I encountered is that many bibliographic databases don't fully support DOIs. Most of them store DOIs, but not all of them allow queries using DOIs, and very few services allow linking to them using DOIs. In the end I had to store various other article identifiers in ScienceCard (currently PubMed ID, PubMed Central ID, Microsoft Academic Search ID, Mendeley UUID, Scopus ID). One side effect of this proliferation of identifiers is that (in very rare cases) DOIs are not unique in these bibliographic services. And it makes it more complicated than necessary to build tools based on DOIs. The members of CrossRef are publishers, the other service providers (whether public or private) seem to be reluctant to fully support a service where they have no direct influence.\n\nThe second problem with DOIs is that they are often not web-friendly. DOIs are really permanent URLs, and CrossRef has recently changed the [display guidelines for DOIs](https://web.archive.org/web/20120610120821/http://www.crossref.org/help/Content/02_Getting_started/Displaying_DOIs_in_print_and_online.htm) to reflect this. Instead of ****[doi: 10.1371/journal.pcbi.0010057](https://web.archive.org/web/20120610120821/http://dx.doi.org/10.1371/journal.pcbi.0010057)**** we are supposed to show DOIs as ****[http://doi.org/10.1371/journal.pcbi.0010057](https://web.archive.org/web/20120610120821/http://dx.doi.org/10.1371/journal.pcbi.0010057)****. The problem is that DOIs can contain characters such as \"+\", \"(\", \".\" or \"/\" that need to be escaped when used as URLs. Some ScienceCard examples include the following:\n\n1.  [http://doi.org/10.1016/S0959-8049(05)80357-0](https://web.archive.org/web/20120610120821/http://dx.doi.org/10.1016/S0959-8049(05)80357-0)\n2.  [http://doi.org/10.1093/bioinformatics/12.4.357](https://web.archive.org/web/20120610120821/http://dx.doi.org/10.1093/bioinformatics/12.4.357)\n3.  [http://doi.org/10.1021/bi980175+](https://web.archive.org/web/20120610120821/http://dx.doi.org/10.1021/bi980175+)\n4.  [http://doi.org/10.1642/0004-8038(2002)119\\[0088:SSCPEO\\]2.0.CO;2](https://web.archive.org/web/20120610120821/http://dx.doi.org/10.1642/0004-8038(2002)119%5B0088:SSCPEO%5D2.0.CO;2)\n\nThese special characters can create problems when DOIs are used in software programs. ScienceCard for example wants to create links to articles in the format ****http://sciencecard.org/10.1642/0004-8038(2002)119\\[0088:SSCPEO\\]2.0.CO;2.xml****, but this function is currently broken.\n\nOne possible solution are [shortDOIs](https://web.archive.org/web/20120610120821/http://shortdoi.org/). Article (3) would for example become [http://doi.org/dcp](https://web.archive.org/web/20120610120821/http://doi.org/dcp), whereas article (4) is rejected as invalid DOI. I would love to use shortDOIs in ScienceCard and other places (e.g. Twitter), but haven't found an API yet that automatically returns shortDOIs for DOIs.\n\n[Component DOIs](https://web.archive.org/web/20120610120821/http://blogs.plos.org/mfenner/2011/03/26/direct-links-to-figures-and-tables-using-component-dois/) directly link to a figure or table of a paper. This is an underused, but very useful feature, and is for example provided by the **PLoS** journals. Unfortunately component DOIs can confuse bibliographic databases and make it more difficult to track all the links to a given article. I had to write a little routine to detect component DOIs imported into ScienceCard.\n\nArticles are sometimes updated or corrected, and many publishers will use a different DOI for the updated article. This is a problem when you want to track all references to this particular article. [http://doi.org/10.1371/journal.pcbi.0020121](https://doi.org/10.1371/journal.pcbi.0020121) and [http://doi.org/10.1371/journal.pcbi.0020181](https://web.archive.org/web/20120610120821/http://dx.doi.org/10.1371/journal.pcbi.0020181) are for example DOIs for the same **PLoS Computational Biology** article (the latter is the corrected version). **Nature Precedings** uses a format that is easier to understand for computers - [http://doi.org/10.1038/npre.2011.4479.3](https://web.archive.org/web/20120610120821/http://dx.doi.org/10.1038/npre.2011.4479.3) is for example a link to the third version of this particular manuscript. [CrossMark](https://web.archive.org/web/20120610120821/http://www.crossref.org/crossmark/index.html) is a new CrossRef service that will make it easier to track the different versions of a manuscript, including retractions.\n\nScienceCard should of course not be limited to journal articles. I'm also interested in other scholarly content, e.g. preprints from ****ArXiV**** or research datasets from ****DataCite****. But I want to first solve the problems with DOIs for journal articles, before I tackle the much bigger problems with uniquely identifying and tracking other scholarly contributions. Science blog posts are a good example. It would be wonderful to track them in ScienceCard, but I don't see how we can do that before we have a system in place that assigns unique and persistent identifiers to blog posts. For this and other reasons I really want unique identifiers for science blog posts, and we should also think about using DOIs for this purpose.\n\n****Update October 9****: A ScienceCard [example](https://web.archive.org/web/20120610120821/http://sciencecard.org/articles/804) of multiple identifiers for the same paper:\n\n-   DOI: 10.1007/s10654-011-9572-7\n-   PubMed ID: 21461943\n-   PubMed Central ID: 3115050\n-   Microsoft Academic Search: 48849734\n-   Mendeley: 5b0023f0-609e-11e0-8f54-0024e8453de6\n-   Mendeley URL: http://www.mendeley.com/research/informativeness-indices-blood-pressure-obesity-serum-lipids-relation-ischaemic-heart-disease-mortality-huntii-study/\n-   Scopus: 79959714408\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw69","guid":"62d42bbd41e317003df48e24","id":"c9d439b9-421b-4717-bb46-d2c6b4a642bc","image":"https://blog.front-matter.io/content/images/2022/08/4632436148_7795a0127c.jpeg","indexed_at":1,"language":"en","published_at":1318118400,"reference":[],"relationships":[],"summary":"ScienceCard is a new service that I started last month with the simple idea to automatically track all journal articles of a given author, and to collect the article-level metrics (citations, bookmarks, etc.) for these papers. ScienceCard requires unique identifiers for articles and authors to work. Unique identifiers for authors is a difficult topic regularly discussed in this blog.\n","tags":["Feature"],"title":"The trouble with DOIs","updated_at":1660732657,"url":"https://blog.front-matter.io/posts/the-trouble-with-dois"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/two-reviews-of-new-reference-manager-readcube","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"<figure class=\"kg-card kg-image-card\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/readcube3.jpeg\" title=\"readcube3\" class=\"kg-image\" loading=\"lazy\" width=\"220\" height=\"49\" />\n</figure>\n\nToday, [Digital Science](https://web.archive.org/web/20120610121628/http://www.digital-science.com/) announced an investment in startup [Labtiva](https://web.archive.org/web/20120610121628/http://www.labtiva.com/). And Labtiva released a \"community preview\" of their reference manager [ReadCube](https://web.archive.org/web/20120610121628/http://www.readcube.com/). The community preview is a free download for Windows and Mac, and this is the summary of my first impressions.\n\nYou could write two different reviews about ReadCube. The first version would mention the really slick interface, and the fun you have using the program. ReadCube is doing a good job importing the PDFs on your hard drive and adding bibliographic information to them. In addition to PDF import you can also search PubMed and Google Scholar. ReadCube helps you find related papers by listing the references and citing papers of the paper you imported. ReaderCube also gives recommendations based on the papers in your library.\n\n<figure class=\"kg-card kg-image-card\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/readcube1-500x276.jpg\" title=\"readcube\" class=\"kg-image\" loading=\"lazy\" width=\"500\" height=\"276\" />\n</figure>\n\nReadCube includes an integrated PDF viewer that also allows text highlighting and note taking.\n\n<figure class=\"kg-card kg-image-card\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/readcube-500x275-1.jpeg\" title=\"readcube\" class=\"kg-image\" loading=\"lazy\" width=\"500\" height=\"275\" />\n</figure>\n\nThe community preview is free, so please download ReadCube to find out whether you like it.\n\nThe second review would take a different approach. It would ask what problem ReadCube tries to solve, and why researchers should start using ReadCube rather than the tools they already use, maybe for many years. ReadCube is a reference manager with a particular focus on organizing the PDFs of scholarly papers. There a number of programs out there that can do the same. [Papers](https://web.archive.org/web/20120610121628/http://www.mekentosj.com/papers/) for Macintosh for example is a very similar program, but the first version of it has been released four years ago. Even more traditional reference managers now include inline PDF readers with annotation support, including the [latest version of Endnote](https://web.archive.org/web/20120610121628/http://www.endnote.com/enx5info.asp). Mendeley and Zotero are two other alternatives, and they are both free and available for Windows, Mac and Linux. It's difficult to see what is unique in ReadCube, and on the other hand some important features are missing (e.g. no bookmarklet to import from other sources, no reference type other than journal articles, no group sharing feature, no integration with Microsoft Word). And ReadCube is based on Adobe Air, a cross-platform development environment that you either love or hate.\n\nIt will be interesting to watch what direction ReadCube development will take. They started a few years later than their competitors, and it will be a lot of work to catch up. I wish the Labtiva team good luck.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw68","guid":"62d42bbd41e317003df48e23","id":"fc7fa308-457c-499c-92bc-871914254cbd","image":"https://blog.front-matter.io/content/images/2022/08/readcube-500x275.jpeg","indexed_at":1,"language":"en","published_at":1318291200,"reference":[],"relationships":[],"summary":"Today, Digital Science announced an investment in startup Labtiva. And Labtiva released a \u201ccommunity preview\u201d of their reference manager ReadCube. The community preview is a free download for Windows and Mac, and this is the summary of my first impressions. You could write two different reviews about ReadCube. The first version would mention the really slick interface, and the fun you have using the program.\n","tags":["News"],"title":"Two reviews of new reference manager ReadCube","updated_at":1660732569,"url":"https://blog.front-matter.io/posts/two-reviews-of-new-reference-manager-readcube"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/serving-shortdois","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"The shortDOI service was launched by the International DOI Foundation (IDF) in May 2010. The service creates short versions of the often long DOIs, e.g. ****10/dvq**** instead of ****10.1093/hmg/ddp202**** -- written as URL this would be [http://doi.org/dvq](https://web.archive.org/web/20120531234808/http://doi.org/dvq) instead of [http://doi.org/10.1093/hmg/ddp202](https://doi.org/10.1093/hmg/ddp202). shortDOIs started as a [CrossRef Labs project](https://web.archive.org/web/20120531234808/http://labs.crossref.org/site/toi_dois.html) in 2009 and were originally named TOI DOI -- TOI stands for tiny object identifier. For a good introduction I recommend [Eric Hellman's blog post](https://web.archive.org/web/20120531234808/http://go-to-hellman.blogspot.com/2010/05/long-handle-on-shortened-digital-object.html) written in May 2010 when the shortDOI service was launched.\n\n<figure class=\"kg-card kg-image-card\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/2093290327_0803f40005.jpeg\" class=\"kg-image\" loading=\"lazy\" width=\"320\" height=\"480\" alt=\"The long and the short of it\" />\n</figure>\n\nshortDOIs provide exactly the same service as normal DOIs, i.e. they redirect the user to the digital resource. They are convenient, particularly for email and Twitter where space is limited. Links to journal articles created by URL shorteners such as bit.ly or goo.gl look similar, but require two redirects (first to dx.doi.org, then to the journal article). But URL shorteners provide additional services to users, e.g. customized links and usage statistics.\n\nAs far as I can tell shortDOIs have not become popular since the service started more than a year ago. One important reason is certainly that publishers are not really using them for their journal articles. I don't think many users will go through the [extra steps creating a shortDOI](https://web.archive.org/web/20120531234808/http://shortdoi.org/) just to use a DOI with Twitter -- the Twitter URL shortener t.co will do this automatically for them. Michael Kuhn has created a [bookmarklet](https://web.archive.org/web/20120531234808/http://blog.mckuhn.de/2011/02/bookmarklet-for-shortdoiorg.html) that makes it a little bit easier to create shortDOIs. If we want shortDOIs to ever become popular, then we should ask journal publishers, bibliographic databases, reference managers and other places that currently use DOIs to enable them.\n\nStarting yesterday [ScienceCard](https://web.archive.org/web/20120531234808/http://sciencecard.org/) is using shortDOIs instead of DOIs, and is also using the shortDOI to link to individual articles on ScienceCard, e.g. [http://sciencecard.org/articles/dvq](https://web.archive.org/web/20120531234808/http://sciencecard.org/articles/dvq). Yesterday I've created about 750 shortDOIs for ScienceCard, and \u00a0this probably already makes ScienceCard one of the larger shortDOI users. I will decide in the coming months whether shortDOIs have improved the ScienceCard service. A nice feature would for example be the announcement of newly published papers via Twitter.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw67","guid":"62d42bbd41e317003df48e22","id":"8b2b3136-f7f5-4a37-b0fe-e46faf929ed4","image":"https://blog.front-matter.io/content/images/2022/08/2093290327_0803f40005.jpeg","indexed_at":1,"language":"en","published_at":1318809600,"reference":[],"relationships":[],"summary":"The shortDOI service was launched by the International DOI Foundation (IDF) in May 2010. The service creates short versions of the often long DOIs, e.g.\n<strong>\n <strong>\n  10/dvq\n </strong>\n</strong>\ninstead of\n<strong>\n <strong>\n  10.1093/hmg/ddp202\n </strong>\n</strong>\n\u2013 written as URL this would be http://doi.org/dvq instead of http://doi.org/10.1093/hmg/ddp202.\n","tags":["Feature"],"title":"Serving shortDOIs","updated_at":1660732470,"url":"https://blog.front-matter.io/posts/serving-shortdois"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/book-review-reinventing-discovery-by-michael-nielsen","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"Reinventing Discovery, the book by Michael Nielsen we all have been waiting for, has finally been published on Friday. Today I flew to Boston for the Microsoft Research eScience Workshop: Transforming Scholarly Communication, and reading the book on the plane was the perfect preparation for the workshop.\n\nMichael says in the book:\n\n> **I wrote this book with the goal of lightning an almighty fire under the scientific community. ... We have an opportunity to change the way knowledge is constructed.**\n\nYou can [download the chapter 1 as PDF](https://press.princeton.edu/chapters/s9517.pdf), and you can also watch the videos of two of his recent presentations: [TEDx Waterloo](https://www.youtube.com/watch?v=DnWocYKqvhw) in March and [Science Online London](https://web.archive.org/web/20120525040623/http://river-valley.tv/keynote-solo2011/) in September.\n\nThe book uses examples from science and related disciplines -- e.g. programming or chess -- to examine both the opportunities and challenges of doing Open Science. The book is good reading, because Michael is aware of the many challenges that we face before science can be done differently. One example for this is the peer-reviewed journal article as the main currency to evaluate researchers. Until scientists are also rewarded for producing or curating data, programming scientific software, etc., we will not be able to start a new era of networked science.\n\nHighly recommended reading.\n\nTimo Hannay has also written a [review of the book](https://doi.org/10.1038/nphys2109) for Nature Physics, and I'm sure we will soon see many more.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw65","guid":"62d42bbd41e317003df48e20","id":"a098579e-61bd-4e8e-afda-f86f11744791","image":"https://blog.front-matter.io/content/images/2022/08/Reinventing_Discovery.jpeg","indexed_at":1,"language":"en","published_at":1319241600,"reference":[],"relationships":[],"summary":"Reinventing Discovery, the book by Michael Nielsen we all have been waiting for, has finally been published on Friday. Today I flew to Boston for the Microsoft Research eScience Workshop: Transforming Scholarly Communication, and reading the book on the plane was the perfect preparation for the workshop. Michael says in the book:\n<em>\n <em>\n  I wrote this book with the goal of lightning an almighty fire under the scientific community.\n </em>\n</em>\n","tags":["Book Review"],"title":"Book Review: Reinventing Discovery by Michael Nielsen","updated_at":1660732387,"url":"https://blog.front-matter.io/posts/book-review-reinventing-discovery-by-michael-nielsen"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/introducing-annotum-to-wordpress-bloggers","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"Version 1.0 of [Annotum](https://web.archive.org/web/20120421012848/http://annotum.org/), the free WordPress theme for writing scholarly articles, was [announced](https://web.archive.org/web/20120421012848/http://googleblog.blogspot.com/2011/11/more-spring-cleaning-out-of-season.html) in late November. Back in June I [wrote about](https://web.archive.org/web/20120421012848/http://blogs.plos.org/mfenner/2011/06/30/annotum-publishing-with-wordpress-soon-coming-to-a-journal-near-you/) the first public version of Annotum, but until now using Annotum was experimental. Annotum is available in the [WordPress Themes Directory](https://web.archive.org/web/20120421012848/http://wordpress.org/extend/themes/annotum-base) at WordPress.org (and has been downloaded more than 9,000 times in the past three weeks), and is also available for users of WordPress.com. I have installed Annotum 1.0 [here](https://web.archive.org/web/20120421012848/http://blogs.scienceonlinelondon.org/annotum/), please drop me a note if you want an account.\n\nBut how is an Annotum blog different from a regular WordPress blog?\n\n### Annotum is a WordPress Theme\n\nWordPress can be extended via Plugins and Themes. Whereas Plugins add functionality, themes usually change the look and feel of a WordPress site. Annotum is a theme that includes a lot of plugin functionality. This strategy makes it easier to get started with Annotum, as there is only one theme to install and not a set of plugins that has to work with a particular theme. Annotum can still be extended via [child themes](https://web.archive.org/web/20120421012848/http://codex.wordpress.org/Child_Themes), e.g. if you want a different look for your blog. And of course you can still use other scholarly plugins.\n\n### Annotum uses articles and not posts\n\nAnnotum uses the custom post type **article** for scholarly content. This can be confusing in the beginning, but makes it easier to separate scholarly content from regular blog posts.\n\n### ****The Annotum editor knows about document structure****\n\nScholarly articles have more structure than blog posts, and you can add this structure with the Annotum editor (see below). This structure is enforced, and the WordPress HTML editor is disabled. This makes it easier to create content that conforms to the NLM-DTD XML format.\n\n<figure class=\"kg-card kg-image-card\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/annotum1.png\" title=\"annotum1\" class=\"kg-image\" loading=\"lazy\" width=\"487\" height=\"319\" />\n</figure>\n\n### Annotum can import and export in the NLM-DTD format\n\nMore specifically, Annotum supports the [Kipling subset](https://web.archive.org/web/20120421012848/http://dtd.nlm.nih.gov/ncbi/kipling/) of the NLM Journal Publishing DTD. NLM-DTD is the standard XML format for scholarly articles, and you can for example import published articles (with a license that allows reuse) into Annotum to get started. Unfortunately there aren't that many NLM-DTD tools for authors (I haven't tested the[Microsoft Word Article Authoring Add-In](https://web.archive.org/web/20120421012848/http://blogs.nature.com/mfenner/2008/11/07/interview-with-pablo-fernicola) with Annotum), but this is a great way to get content written somewhere else into Annotum.\n\n### Annotum knows that articles can have multiple authors\n\nThis is of course important for scholarly articles, and the [Co-Authors Plus Plugin](https://web.archive.org/web/20120421012848/http://wordpress.org/extend/plugins/co-authors-plus/) also adds this feature to any WordPress blog.\n\n<figure class=\"kg-card kg-image-card\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/annotum2.png\" title=\"annotum2\" class=\"kg-image\" loading=\"lazy\" width=\"416\" height=\"166\" />\n</figure>\n\n### Annotum knows about tables, figures, equations and references\n\nScholarly articles have special formatting requirements for these content types, particularly references. Annotum adds visual editors for all of them. Annotum also has an editor for LaTeX equations.\n\n<figure class=\"kg-card kg-image-card\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/annotum4-406x500-1.png\" title=\"annotum4\" class=\"kg-image\" loading=\"lazy\" width=\"406\" height=\"500\" />\n</figure>\n\nAnnotum currently does not integrate with reference managers (Endnote, Mendeley, Zotero, etc.) or other WordPress tools that insert citations into blog posts (e.g [kcite](https://web.archive.org/web/20120421012848/http://wordpress.org/extend/plugins/kcite/) or [Link to Link](https://web.archive.org/web/20120421012848/http://wordpress.org/extend/plugins/link-to-link/)), but you can look up references via DOI and PubMed ID.\n\n### Annotum knows about reviewers and editors\n\nAnnotum has \u00a0a built-in review system that knows about authors, reviewers and editors. Annotum allows comments only visible to authors and reviewers, and sends out notification emails. The [Edit Flow](https://web.archive.org/web/20120421012848/http://editflow.org/) plugin provides similar functionality.\n\n<figure class=\"kg-card kg-image-card\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/annotum3.png\" title=\"annotum3\" class=\"kg-image\" loading=\"lazy\" width=\"298\" height=\"206\" />\n</figure>\n\n### Annotum can export to PDF\n\nAnnotum automatically creates a PDF version of your article (using the [dompdf](https://web.archive.org/web/20120421012848/http://code.google.com/p/dompdf/) HTML to PDF converter). \u00a0Annotum also works with my [ePub Export plugin](https://web.archive.org/web/20120421012848/http://wordpress.org/extend/plugins/epub-export/), using [this hack](https://web.archive.org/web/20120421012848/https://gist.github.com/1046450) to display the ePub link next to the PDF link:\n\n<figure class=\"kg-card kg-image-card\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/annotum5-500x148.png\" title=\"annotum5\" class=\"kg-image\" loading=\"lazy\" width=\"500\" height=\"148\" />\n</figure>\n\n### Summary\n\nAnnotum is a complete and free solution for starting a scholarly journal using WordPress. It has everything you need to write great scholarly content with WordPress and improves a regular WordPress blog in several important ways. Thanks to the support for the NLM-DTD format, Annotum can also be used as a writing tool for articles intended for submission somewhere else. One of the biggest strengths of WordPress is that it is really a writing **platform** that can be extended in many interesting ways. Maybe we will see WordPress plugins that enhance the equation editor or the reference management -- or that connect Annotum to traditional journal submission systems.\n\nScience bloggers will also be interested in many of the features of Annotum, but they don't need the review workflow and might find that the support for NLM-DTD restricts them in how they can write content. Annotum is at version 1.0, and it is therefore not surprising that it still has a few rough edges. My biggest wish for a future version is better support for revisions and inline comments -- Google Docs and other collaborative writing tools do a much better job highlighting the changes made in a text.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw61","guid":"62d42bbd41e317003df48e1c","id":"01d1abf6-d68e-412b-ab58-813262179b4f","image":"https://blog.front-matter.io/content/images/2022/08/annotum4-406x500.png","indexed_at":1,"language":"en","published_at":1323302400,"reference":[],"relationships":[],"summary":"Version 1.0 of Annotum, the free WordPress theme for writing scholarly articles, was announced in late November. Back in June I wrote about the first public version of Annotum, but until now using Annotum was experimental. Annotum is available in the WordPress Themes Directory at WordPress.org (and has been downloaded more than 9,000 times in the past three weeks), and is also available for users of WordPress.com.\n","tags":["News"],"title":"Introducing Annotum to WordPress Bloggers","updated_at":1660732271,"url":"https://blog.front-matter.io/posts/introducing-annotum-to-wordpress-bloggers"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/crowdometer-goes-mobile","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"Two weeks ago Euan Adie from [altmetric.com](https://web.archive.org/web/20170107002621/http://altmetric.com/) and myself [launched](https://web.archive.org/web/20170107002621/http://blogs.plos.org/mfenner/2011/12/20/crowdometer-or-trying-to-understand-tweets-about-journal-papers/) the website [CrowdoMeter](https://web.archive.org/web/20170107002621/http://crowdometer.org/), a crowdsourcing project that tries to classify tweets about scholarly articles using the Citation Typing Ontology (CiTO). Despite the holidays we have gotten off to a good start with currently 597 classifications by 56 different users, already covering 93% of the tweets we wanted to classify. We will discuss the results of this project at the [ScienceOnline2012](https://web.archive.org/web/20170107002621/http://scienceonline2012.com/) conference in two weeks, but the most important findings can also be watched in real-time [here](https://web.archive.org/web/20170107002621/http://crowdometer.org/ratings).\n\nTo our knowledge this is the first time that CiTO has been used for the systematic classification of tweets, and the preliminary results seem to confirm what we and others had thought, i.e. that most tweets contain little semantic information and often only retweet the title of a paper. But not only do we now have numbers to confirm this, but we can also make some interesting additional observations. We find for example that only 1% of tweets disagree with the statements made in a paper -- most Twitter users don't seem to care telling others about papers they dislike or disagree with.\n\nThis project is far from over, ideally we want 3-5 classifications per tweet or an additional 1,000 classifications. It is a challenge to build a website so that enough people want to help with this project. One idea is to make the classifications as simple as possible, and to help further with this we today launched a mobile version of CrowdoMeter. Simply browse to [http://crowdometer.org](https://web.archive.org/web/20170107002621/http://crowdometer.org/) with your iPhone or Android phone, sign in via your Twitter account, and you should see something similar to this:\n\n<figure class=\"kg-card kg-image-card\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/crowdometer.png\" title=\"crowdometer\" class=\"kg-image\" loading=\"lazy\" width=\"320\" height=\"480\" />\n</figure>\n\nCrowdoMeter uses [jQuery Mobile](https://web.archive.org/web/20170107002621/http://jquerymobile.com/), a touch-optimized Javascript framework for smartphones and tablets. There are still some minor issues, but in general jQuery Mobile is a great tool to optimize a website for mobile users. Users are presented with 10 random tweets they haven't classified yet, and see a simple classification screen when clicking (touching) a tweet:\n\n<figure class=\"kg-card kg-image-card\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/crowdometer1-1.png\" title=\"crowdometer1\" class=\"kg-image\" loading=\"lazy\" width=\"320\" height=\"480\" />\n</figure>\n\nIt should not take longer than 15 minutes to classify 15-25 tweets, and this would be a tremendous help for the project.\n\nThe CrowdoMeter results page displayed the same information as in the desktop version of the website, the charts are produced by the [Highcharts](https://web.archive.org/web/20170107002621/http://www.highcharts.com/) Javascript library (and again jQuery).\n\n<figure class=\"kg-card kg-image-card\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/crowdometer2.png\" title=\"crowdometer2\" class=\"kg-image\" loading=\"lazy\" width=\"320\" height=\"480\" />\n</figure>\n\nI'm interested to see how well the crowdsourcing for CrowdoMeter will work in the coming weeks. We hope to finish the data gathering part in January. If this project generates enough interest I could imagine doing another crowdsourcing project, maybe again using the Citation Typing Ontology, but this time for blog posts about scholarly papers.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw2z","guid":"62d42bbd41e317003df48dba","id":"04828def-51f8-4a2d-b323-04e49fef2434","image":"https://blog.front-matter.io/content/images/2022/08/crowdometer1.png","indexed_at":1,"language":"en","published_at":1325635200,"reference":[],"relationships":[],"summary":"Two weeks ago Euan Adie from altmetric.com and myself launched the website CrowdoMeter, a crowdsourcing project that tries to classify tweets about scholarly articles using the Citation Typing Ontology (CiTO). Despite the holidays we have gotten off to a good start with currently 597 classifications by 56 different users, already covering 93% of the tweets we wanted to classify.\n","tags":["Feature"],"title":"CrowdoMeter goes Mobile","updated_at":1660732122,"url":"https://blog.front-matter.io/posts/crowdometer-goes-mobile"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/altmetrics-to-go-mobile-version-of-sciencecard-available","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"[ScienceCard](https://web.archive.org/web/20161027000751/http://sciencecard.org/) is a web service that collects all scientific articles published by an author and displays their aggregate article-level metrics. Yesterday I added a mobile version to ScienceCard, simply browse to ScienceCard with your mobile phone or go to [http://mobile.sciencecard.org](https://web.archive.org/web/20161027000751/http://mobile.sciencecard.org/). This is a first version based on my work with jQuery Mobile on [CrowdoMeter](https://web.archive.org/web/20161027000751/http://blogs.plos.org/mfenner/2012/01/04/crowdometer-goes-mobile/), but I think ScienceCard works really well on a small screen.My ScienceCard looks like [this](https://web.archive.org/web/20161027000751/http://mobile.sciencecard.org/mfenner). Further down the screen are the articles I have published and the collective metrics of these papers.\n\nOther ScienceCard users have much more impressive metrics, both in traditional citations, and in altmetrics such as PDF downloads of papers published with PLoS:\n\n<figure class=\"kg-card kg-image-card\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/sciencecard3.png\" title=\"sciencecard3\" class=\"kg-image\" loading=\"lazy\" width=\"320\" height=\"480\" />\n</figure>\n\nMetrics of an individual paper ([http://doi.org/dm9](https://web.archive.org/web/20161027000751/http://doi.org/dm9)), with links to the journal and metrics (e.g. CiteULike bookmarks) look like this:\n\n<figure class=\"kg-card kg-image-card\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/sciencecard.png\" title=\"sciencecard\" class=\"kg-image\" loading=\"lazy\" width=\"320\" height=\"480\" />\n</figure>\n\nOne idea behind ScienceCard is to make the collection and display of this kind of information as simple as possible. I hope this is another small step in the right direction.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw2y","guid":"62d42bbd41e317003df48db9","id":"62626fc4-6fda-48a5-bd26-5e5e495b7a49","image":"https://blog.front-matter.io/content/images/2022/08/sciencecard2.png","indexed_at":1,"language":"en","published_at":1325980800,"reference":[],"relationships":[],"summary":"ScienceCard is a web service that collects all scientific articles published by an author and displays their aggregate article-level metrics. Yesterday I added a mobile version to ScienceCard, simply browse to ScienceCard with your mobile phone or go to http://mobile.sciencecard.org.\n","tags":["News"],"title":"Altmetrics to go \u2013 mobile version of ScienceCard available","updated_at":1660731987,"url":"https://blog.front-matter.io/posts/altmetrics-to-go-mobile-version-of-sciencecard-available"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/figshare-interview-with-mark-hahnel","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"fig**share** *allows researchers to publish all of their research outputs in seconds in an easily citable, sharable and discoverable manner*. The service was started by Mark Hahnel last year while still a PhD student. Mark joined [Digital Science](https://web.archive.org/web/20161023171633/http://www.digital-science.com/) to work on fig**share** in September and last month relaunched a much improved version of the service. I asked Mark a few questions about fig**share** below. I also uploaded two datasetst to fig**share** and made them publicly available:\n\n-   [CrowdoMeter Tweets](https://web.archive.org/web/20161023171633/http://hdl.handle.net/10779/1c48a305c08c717fea3f6fe1687b3eff) -- all 467 tweets used in the CrowdoMeter project\n-   [CrowdoMeter Classifications](https://web.archive.org/web/20161023171633/http://hdl.handle.net/10779/01c28ce592291e7e294ed328208a5869) -- all 953 classifications from the CrowdoMeter project.\n\n## 1. What is figshare? {#1-what-is-figshare}\n\n[figshare](https://web.archive.org/web/20161023171633/http://figshare.com/) is a repository where users can make all of their research outputs available in a citable, sharable and discoverable manner. figshare allows users to upload any file format so that figures, datasets and media can be disseminated in a way that the current scholarly publishing model does not allow.\n\n<figure class=\"kg-card kg-image-card\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/screenshot.png\" title=\"screenshot\" class=\"kg-image\" loading=\"lazy\" width=\"500\" height=\"258\" />\n</figure>\n\n## 2. What is the right content for figshare? And what should rather go somewhere else? {#2-what-is-the-right-content-for-figshare-and-what-should-rather-go-somewhere-else}\n\nEvery experiment that is completed without error in the methods is valuable. Researchers investigate things because the question is interesting and supposedly unanswered. This means that other researchers will at some point ask that same question. Just because the hypothesis didn't turn out to be true, doesn't mean that this data should be thrown away.\n\nWith fig**share**, you can share your negative results or results that you were not planning to publish. You can make raw data available or supplementary material that journals cannot handle linked to from the published article. You can even make your papers and posters available and citable. People have uploaded whole chapters of their PhD thesis to share with the world and make sure that all of their hard work is not wasted.\n\nCurrently we are not focusing on handling massive datasets, whilst this is an aim for the future. These edge cases seem to be better handled by journals set up specifically for publishing these huge files, such as the excellent GigaScience.\n\n## 3. You relaunched figshare in January. What has changed to the previous version? {#3-you-relaunched-figshare-in-january-what-has-changed-to-the-previous-version}\n\nThe old site was a proof of concept based on Mediawiki software. The new site has been completely built from scratch so that it is rapidly extendable in terms of features and scale. This means that we can adapt quickly and easily to the needs of researchers. As well as being much more intuitive, the biggest new feature for fig**share** is the private space.\n\nWhilst we would like everyone to make all of their research objects available, we appreciate that some researchers would like to keep research private for many reasons. Because of this we set about giving users their own private repository to store their research objects. These objects can be uploaded in seconds and all objects are initially held in the private space, from where they can be made publicly available when the user decides. All research is easily tagged and categorizable, so that researchers can filter through their many files to find the one they were looking for in no time at all.\n\n## 4. How important is the user interface for figshare? What particular features do you like the most? {#4-how-important-is-the-user-interface-for-figshare-what-particular-features-do-you-like-the-most}\n\nThe user interface is essential, researchers are busy enough as it it. They haven't got the time to attend training course on how to use a repository. If this was the case with facebook, no one would use facebook. For this reason fig**share** is stupidly simple and allows users to get their research onto the site in seconds, even the PIs. At this point they can choose to make it publicly available and immediately citable, sharable and discoverable, or keep it private -- securely hosted, taggable and accessible when they need it, from anywhere in the world.\n\nThis is something we are constantly aiming to improve and we not only welcome feedback, we are actively seeking the thoughts of researchers on how we can make this a seemless part of their research process.\n\n## 5. Do you have plans for a desktop version of figshare, e.g. to watch folders for new figshare content? {#5-do-you-have-plans-for-a-desktop-version-of-figshare-e-g-to-watch-folders-for-new-figshare-content}\n\nWe do! By creating a desktop uploader, the process becomes even more intuitive for researchers, allowing them to make backups of their research in the cloud with no effort expenditure. Research data management is something I personally was terrible at. My research was organised into folders based on the month and the year I did that work. I lost days trying to find files that 'I know I worked on sometime last summer'. Hopefully a desktop uploader will add to the current simple management system so that researchers like me have no excuse when it comes to losing (often expensive) results files.\n\n## 6. How is figshare different from data repositories? {#6-how-is-figshare-different-from-data-repositories}\n\nfig**share** is not limited as many repositories are. It caters for all research domains, no matter where your research is carried out. Institutional repositories are often limited to members of said institution. Also, the majority of institutional repositories are built specifically for papers. The Dryad repository has been doing some great work making the datasets behind published articles available under CC0. fig**share** is not limited by the normal constraints of publishing, data generated in the lab can be shared and made available to the world as a citable object the same day.\n\n<figure class=\"kg-card kg-image-card\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/usermetrics.png\" title=\"usermetrics\" class=\"kg-image\" loading=\"lazy\" width=\"275\" height=\"115\" />\n</figure>\n\nfig**share** also gives the researchers the credit for their research. By adding metrics to the public uploads, and putting the cumulative metrics of a researcher's uploads on their profile, users can see the true impact and reach of the hard work they put in.\n\n## 7. You currently use handles for figshare content. What are your thoughts on persistent identifiers? Are the plans to use DOIs? {#7-you-currently-use-handles-for-figshare-content-what-are-your-thoughts-on-persistent-identifiers-are-the-plans-to-use-dois}\n\nPersistent identifiers are essential for the long term availability of research outputs. One of the reasons I set up figshare was because I wanted to cite a video in my thesis. Research data on [YouTube](https://web.archive.org/web/20161023171633/http://figshare.com/blog/A%20YouTube%20%20for%20Scientists/11) is not easily citable, by adding persitent identifiers and an organised citation structure, videos as well as any other file format can be easily cited. All citations can be exported to [Mendeley](https://web.archive.org/web/20161023171633/http://mendeley.com/), [Endnote](https://web.archive.org/web/20161023171633/http://www.endnote.com/) and [RefMan](https://web.archive.org/web/20161023171633/http://www.refman.com/)with one click. We use handles at the moment, but have noticed that researchers tend to be more familiar with DOI's and so will be making the move over to them shortly. We're currently working with [DataCite](https://web.archive.org/web/20161023171633/http://datacite.org/) through the British Library to get this set up.\n\n## 8. How does figshare guarantee long-term preservation of uploaded data? {#8-how-does-figshare-guarantee-long-term-preservation-of-uploaded-data}\n\nThe long term persistence of this research data is essential. The research is backed up locally as soon as it is uploaded. We are currently in talks with [Portico](https://web.archive.org/web/20161023171633/http://www.portico.org/) to back up all data and further guarantee this long term persistence.\n\n## 9. What are your responsibilities at figshare? What did you do before Figshare? {#9-what-are-your-responsibilities-at-figshare-what-did-you-do-before-figshare}\n\nI'm basically responsible for making the platform as useful for researchers as possible. I also love going to talk at Universities and conferences to researchers directly, to hear their thoughts/opinions. As a former life science researcher (I finished my PhD in stem cell biology at Imperial College London in September), I understand that what makes sense in a rational world does not make sense in the scientific world. You just have to look at the established model of scientific research dissemination to understand that. fig**share** is useful whether you want to make all of your research outputs available or none. Science would just be a lot more efficient and dynamic if they did.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw2r","guid":"62d42bbd41e317003df48db3","id":"64f41059-9d9d-49e6-b1e1-3df00adf7fe2","image":"https://blog.front-matter.io/content/images/2022/08/me1.png","indexed_at":1,"language":"en","published_at":1329350400,"reference":[],"relationships":[],"summary":"fig\n<strong>\n share\n</strong>\n<em>\n allows researchers to publish all of their research outputs in seconds in an easily citable, sharable and discoverable manner\n</em>\n. The service was started by Mark Hahnel last year while still a PhD student. Mark joined Digital Science to work on fig\n<strong>\n share\n</strong>\nin September and last month relaunched a much improved version of the service. I asked Mark a few questions about fig\n<strong>\n share\n</strong>\nbelow.\n","tags":["Interview"],"title":"Figshare: Interview with Mark Hahnel","updated_at":1660731872,"url":"https://blog.front-matter.io/posts/figshare-interview-with-mark-hahnel"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/altmetrics-where-do-we-go-from-here","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"The [ScienceOnline2012](https://web.archive.org/web/20161027000038/http://scienceonline2012.com/) conference last week again was a wonderful experience. This was my third time in North Carolina, and I had many great conversations in the sessions, hallways -- and bars. One of many highlights was a lunch meeting with fellow PLoS bloggers and staffers.\n\nTogether with [Euan Adie](https://web.archive.org/web/20161027000038/http://twitter.com/Stew) I moderated a session on Friday:\n\n## Using altmetrics tools to track the scholarly impact of your research. {#using-altmetrics-tools-to-track-the-scholarly-impact-of-your-research-}\n\nWe started the session by asking several people in the audience to demonstrate their altmetrics tools: [altmetric.com](https://web.archive.org/web/20161027000038/http://altmetric.com/) (Euan Adie), [ReaderMeter](https://web.archive.org/web/20161027000038/http://readermeter.org/) (Dario Taraborelli), [Total Impact](https://web.archive.org/web/20161027000038/http://total-impact.org/) (Jason Priem), [PLoS Article-Level Metrics](https://web.archive.org/web/20161027000038/http://article-level-metrics.plos.org/) (Jennifer Lin), and [ScienceCard](https://web.archive.org/web/20161027000038/http://sciencecard.org/) (me). We briefly showed our [CrowdoMeter](https://web.archive.org/web/20161027000038/http://crowdometer.org/) project where we crowdsourced the meaning of tweets about scholarly papers.\n\nThe discussion covered many interesting aspects. I would like to focus on three of them.\n\n### Gaming\n\nAltmetrics are still fairly new, and therefore not many people try to the cheat yet (but almost 1% of tweets in the [CrowdoMeter dataset](https://web.archive.org/web/20161027000038/http://crowdometer.org/ratings) were already spam). I'm sure that this will change over time, and some metrics will be more prone to gaming than others. Gaming is a particular problem for usage stats, as it is difficult to impossible to verify them. Metrics provided by the producer of a research object (author or publisher) will be more susceptible to gaming than metrics from an independent source. Anonymous metrics (e.g. Mendeley readers) are more susceptible to gaming than metrics that list the source of every citation (e.g. CiteULike bookmarks).\n\n### Context\n\nAltmetrics is currently at a stage where we collect various metrics, but don't really know what these numbers mean. Does 1,000 downloads, 10 Mendeley bookmarks or 50 tweets mean that the paper has impact? And how do we compare altmetrics from different disciplines? Does it make a difference if a [Fields Medalist](https://web.archive.org/web/20161027000038/http://www.mathunion.org/general/prizes/fields/details/) blogs about your paper (an example given in the session)? I think that the most interesting metrics are those that take into account who is citing the work, being it a regular citation, a social bookmark or a social media comment. This is of course how Google [PageRank](https://web.archive.org/web/20161027000038/http://de.wikipedia.org/wiki/PageRank) works for webpages, and how [Eigenfactor](https://web.archive.org/web/20161027000038/http://www.eigenfactor.org/) ranks scholarly journals. The context can be further improved by including the social networks of the person looking for information, e.g. how many people I follow on Twitter have bookmarked this particular paper.\n\n### Scope\n\nThe tools discussed in the ScienceOnline session all have a particular approach for gathering altmetrics: altmetrics over a given time period (*altmetric.com*), altmetrics for content produced by a particular publisher (*PLoS ALM*), altmetrics for a given researcher (*ReaderMeter* and *ScienceCard*), and altmetrics produced for a given dataset on demand (*Total-Impact*). One obvious advantage of this approach is that it reduces the number of datasets needed to run the service. Unfortunately, this is an arbitrary distinction, and it falls apart when you use a PageRank approach and also look at the metrics of citing sources.\n\n### Conclusions\n\nI think that altmetrics has made tremendous progress in 2011, but that there is a lot of work to do in 2012. I'm very interested in altmetrics based on PageRank, but also want to take social networks into consideration. This is of course how finding information on the web works -- scholarly communication is just a subset. Unfortunately, this approach requires a massive database of scholarly citations, something that is impossible to do for the small part-time altmetrics projects mentioned at the beginning of the post.\n\nI'm less interested in usage metrics because they are so prone to gaming and will probably become problematic in a few years, and I want to focus on a reasonable number of altmetrics. I hope that there will never be a single \"altmetric\", but I also don't think that we need 20 different altmetrics for every scholarly work. A lot of interesting work ahead for my ScienceCard project.\n\nI'm looking forward to the altmetrics session at ScienceOnline2013.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw2w","guid":"62d42bbd41e317003df48db7","id":"c6cffb68-921a-44cb-8c31-82168990de70","image":"https://blog.front-matter.io/content/images/2022/08/6732330879_726113a81d.jpeg","indexed_at":1,"language":"en","published_at":1327363200,"reference":[],"relationships":[],"summary":"The ScienceOnline2012 conference last week again was a wonderful experience. This was my third time in North Carolina, and I had many great conversations in the sessions, hallways \u2013 and bars. One of many highlights was a lunch meeting with fellow PLoS bloggers and staffers. Together with Euan Adie I moderated a session on Friday:Using altmetrics tools to track the scholarly impact of your research.\n","tags":["Meeting Report"],"title":"Altmetrics \u2013 Where Do We Go From Here?","updated_at":1660729136,"url":"https://blog.front-matter.io/posts/altmetrics-where-do-we-go-from-here"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/zotero-3-0-released","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"Zotero 3.0 was [officially released](https://www.zotero.org/blog/zotero-3-0-is-here/) today. The big change in version 3.0 of the reference manager is a standalone version that runs outside the Firefox browser. The [first beta](https://blog.front-matter.io/posts/zotero-3-0-beta-released-works-with-chrome-and-safari/) was released in August 2011.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw2t","guid":"62d42bbd41e317003df48db5","id":"3921492d-2f7f-4028-aaa5-b5db95f90fbd","image":"https://blog.front-matter.io/content/images/2022/08/zotero.png","indexed_at":1,"language":"en","published_at":1327968000,"reference":[],"relationships":[],"summary":"Zotero 3.0 was officially released today. The big change in version 3.0 of the reference manager is a standalone version that runs outside the Firefox browser. The first beta was released in August 2011.\n","tags":["News"],"title":"Zotero 3.0 Released","updated_at":1660729035,"url":"https://blog.front-matter.io/posts/zotero-3-0-released"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/crowdsourcing-the-analysis-of-scholarly-tweets","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"In December Euan Adie and I [started the CrowdoMeter projec](https://web.archive.org/web/20161027000313/http://blogs.plos.org/mfenner/2011/12/20/crowdometer-or-trying-to-understand-tweets-about-journal-papers/)t, an analysis of the semantic content of tweets linking to scholarly papers. Because classifying almost 500 tweets is a lot of work, we turned this into a crowdsourcing project. We got help from 36 people, who did 953 classifications, and we discussed the preliminary results (available [here](https://web.archive.org/web/20161027000313/http://crowdometer.org/ratings)) at the [ScienceOnline2012](https://web.archive.org/web/20161027000313/http://scienceonline2012.com/) conference.\n\nThere is no reason to stop the crowdsourcing here, so we have [uploaded the result set](https://web.archive.org/web/20161027000313/http://hdl.handle.net/10779/01c28ce592291e7e294ed328208a5869) to [figshare](https://web.archive.org/web/20161027000313/http://blogs.plos.org/mfenner/2012/02/16/figshare-interview-with-mark-hahnel/) and invite everybody to help us with the data analysis. For this purpose I have created a [public repository](https://web.archive.org/web/20161027000313/https://github.com/mfenner/crowdometer) on Github which contains not only the source code for the CrowdoMeter website, but also all data -- the same dataset made available on figshare. I have written a [first R script](https://web.archive.org/web/20161027000313/https://github.com/mfenner/crowdometer/blob/crowdometer/public/assets/shares_author.R) that produces the following pie chart:\n\nThe figure doesn't look all that exciting, but there is some calculation involved. There are different numbers of classifications per tweet and sometimes there is disagreement: true means at least 50% of classifications were true. It would be great if we find people willing to help with data analysis, preferably using [R](https://web.archive.org/web/20161027000313/http://rstudio.org/) and contributing their scripts to the Github repository. Please send me an email or contact me [via Twitter](https://web.archive.org/web/20161027000313/http://twitter.com/#!/mfenner) if you need write access to the repository.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw2p","guid":"62d42bbd41e317003df48db1","id":"c3c00883-c375-46f2-a642-f50eaad71562","image":"https://blog.front-matter.io/content/images/2022/08/authors.png","indexed_at":1,"language":"en","published_at":1329609600,"reference":[],"relationships":[],"summary":"In December Euan Adie and I started the CrowdoMeter project, an analysis of the semantic content of tweets linking to scholarly papers. Because classifying almost 500 tweets is a lot of work, we turned this into a crowdsourcing project. We got help from 36 people, who did 953 classifications, and we discussed the preliminary results (available here) at the ScienceOnline2012 conference.\n","tags":["Chart"],"title":"Crowdsourcing the analysis of scholarly tweets","updated_at":1660728788,"url":"https://blog.front-matter.io/posts/crowdsourcing-the-analysis-of-scholarly-tweets"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/why-i-still-like-friendfeed-why-twitter-is-important-and-other-thoughts-about-altmetrics","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"[Altmetrics](https://web.archive.org/web/20160528083343/http://altmetrics.org/) -- tools to assess the impact of scholarly works based on alternative online measures such as bookmarks, links, blog posts, etc. --have become a regular topic in this blog. The [altmetrics manifesto](https://web.archive.org/web/20160528083343/http://altmetrics.org/manifesto/) was published in October 2010, and in the last 18 months we have seen a [number of interesting new altmetrics services](https://web.archive.org/web/20160528083343/http://altmetrics.org/tools/), including the [ScienceCard](https://web.archive.org/web/20160528083343/http://blogs.plos.org/blog/tag/sciencecard/) service that I started six months ago. ScienceCard has been a very interesting learning experience, because I not only had to write the software, but also think about my perspective on altmetrics. Some of my recent thoughts are listed below.\n\n**FriendFeed still is a great model for a scholarly service**\\\nI have stopped using FriendFeed a few months ago in favor of Twitter, but I still very much like the design of the service. I think that the concept should also work very well for altmetrics, and I have therefore continued work on an [activity stream](https://web.archive.org/web/20160528083343/http://en.wikipedia.org/wiki/Activity_stream) for ScienceCard. At [http://sciencecard.org/works](https://web.archive.org/web/20160528083343/http://sciencecard.org/works) you find a listing of all recent scholarly works of your ScienceCard friends, and now you can like/comment/share them. ScienceCard friends are the people you follow on Twitter who also have a ScienceCard account and sharing is possible via Mendeley and CiteULike. Comments are still in the testing stage, and Twitter integration is also in the works. I also want to add more scholarly content including Slideshare presentations and blog posts, although the latter are really hard to do in an automated way.\n\nAltmetrics tools should not only present scholarly works and their metrics, but they should also allow users to interact with them via sharing, commenting, etc.\n\n**Altmetrics is about search**\\\nAltmetrics is really about two related concepts: reputation and discovery. ScienceCard tries to summarize the metrics available about a particular researcher, although much more work needs to be done to show that these numbers correlate with reputation. The discovery aspect of altmetrics is at least as important, and this means that these alternative metrics should help provide better search results. Some bibliographic databases let you sort your search results by number of citations -- the problem is of course that citations can have a delay of several years. Download counts, social bookmarks, Twitter links, etc. on the other hand can give information about the impact of a paper within days of publication. The search results can be improved further by personalizing them based on what the friends in your social network are publishing, bookmarking or discussing.\n\n**Altmetrics is expensive**\\\nIt is great to see so many altmetrics grassroots projects. Unfortunately it is resource-intensive and therefore costly to collect altmetrics, in particular if it is almost real-time numbers such as Twitter citations. I'm afraid that many people (including myself) will have a hard time providing this service in a sustainable way. There are two possible solutions: providing altmetrics as a commercial service, and providing altmetrics as a collaborative effort. Although I understand the reasoning behind commercial services, I would very much prefer the open and collaborative approach. Collaboration could mean that several people and/or organizations join forces and run an altmetrics service together, but it could also mean that we break altmetrics into smaller services connected via programming interfaces. A typical altmetrics service has at least these functions:\n\n-   an interface to add journal articles and other scholarly objects, whether it is manual input by users or via an API\n-   a searchable database with metadata about scholarly objects\n-   a background service that collects metrics from other sources\n-   a public interface that displays metrics for particular scholarly objects and collections\n-   an interface for visualization and analysis of aggregate numbers\n\nI don't think that all five functions (and possibly more) necessarily have to be provided by the same service. I'm sure that there are enough people that are only interested in providing interesting ways to add scholarly objects, or in visualization and analysis. The background service is probably the most boring and resource-intensive part.\n\n**I want second-order metrics**\\\nSecond-order metrics means the metrics for the scholarly works citing a particular paper or for the person bookmarking or tweeting a scholarly work. This approach would add valuable information and is obviously similar to the PageRank algorithm for web links. Unfortunately this approach also creates a lot of extra work, as this means collecting the metrics (or at least some metrics) for all citing works. Again something that makes altmetrics expensive.\n\n**Twitter is important**\\\nMany of the [recent altmetrics discussions](https://web.archive.org/web/20160528083343/http://blogs.lse.ac.uk/impactofsocialsciences/2012/02/09/more-tweets-more-citations/) have really been about the role of Twitter in scholarly communication. A lot of people are excited about the potential of Twitter to help discover interesting scholarly works, and to allow this within days after publication. It is still too early to know for sure whether [highly tweeted papers will be cited more often later on](https://web.archive.org/web/20160528083343/http://blogs.plos.org/mfenner/2011/12/20/crowdometer-or-trying-to-understand-tweets-about-journal-papers/). Better Twitter integration is high on my to do list for ScienceCard.\n\n**Yet another bibliographic database**\\\nThe core function of altmetrics is to build a database with metadata about scholarly objects, including a variety of metrics. There are of course a large number of bibliographic databases already out there, so maybe existing databases can also be extended to include metrics. Ideally the existing database should not be restricted to particular kinds of scholarly works (e.g. journal articles) or disciplines, should be free to use and should allow reuse of the data with an appropriate license. There are several candidates that fit this description, including [BibSoup](https://web.archive.org/web/20160528083343/http://bibsoup.net/) run by the Open Knowledge Foundation and possibly also the [Zotero](https://web.archive.org/web/20160528083343/http://www.zotero.org/) database allowing synchronization with the desktop reference manager. Both services focus on bibliographic collections uploaded by users, whereas my idea of an altmetrics database relies on disambiguated authors and scholarly works.\n\n**There are too many altmetrics**\\\nIt is great that altmetrics increases the variety of available metrics, but too many different metrics can be confusing to users. Although it is interesting that the number of citations for the same work vary widely between PubMed, Web of Science, Scopus, Microsoft Academic Search, Pubmed and Google Scholar, the typical user is probably only interested in one citation count. The same is true for usage metrics and number of social bookmarks. I think it would be helpful to consolidate the metrics about a scholarly work to maybe five numbers, including views/downloads, bookmarks, citations, comments, and tweets. This doesn't mean that the other information shouldn't be collected, just that the numbers will be consolidated for display.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw2m","guid":"62d42bbd41e317003df48daf","id":"081962e8-cbb3-46af-9071-c9b19869952e","image":"https://blog.front-matter.io/content/images/2022/08/activitystream-1.png","indexed_at":1,"language":"en","published_at":1330905600,"reference":[],"relationships":[],"summary":"Altmetrics \u2013 tools to assess the impact of scholarly works based on alternative online measures such as bookmarks, links, blog posts, etc. \u2013have become a regular topic in this blog. The altmetrics manifesto was published in October 2010, and in the last 18 months we have seen a number of interesting new altmetrics services, including the ScienceCard service that I started six months ago.\n","tags":["Feature"],"title":"Why I still like FriendFeed, why Twitter is important and other thoughts about Altmetrics","updated_at":1660728711,"url":"https://blog.front-matter.io/posts/why-i-still-like-friendfeed-why-twitter-is-important-and-other-thoughts-about-altmetrics"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/plos-article-level-metrics-interview-with-martin-fenner","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"This blog occasionally does interviews with people providing interesting tools for scholars. These [interviews](https://front-matter.io/interviews) have always been among my favorite blog posts. This now is obviously an interview with myself, but I felt this is the best format to explain some important news.\n\nStarting May 16 I will be working full-time as technical lead for the PLoS [Article Level Metrics](https://web.archive.org/web/20161226124822/http://article-level-metrics.plos.org/) (ALM) project. I will help with development of the [PLoS ALM application](https://web.archive.org/web/20161226124822/http://code.google.com/p/alt-metrics/), and will do community developer outreach for this project.\n\nThe PLoS ALM application is written in [Ruby on Rails](https://web.archive.org/web/20161226124822/http://rubyonrails.org/), an open-source web framework I have been working with since 2005. The ALM project was launched in 2009, and I first learned about ALM in a July 2009 presentation by Pete Binfield at [SciBarCamp Palo Alto](https://web.archive.org/web/20161226124822/http://blogs.plos.org/mfenner/2009/07/10/i_was_at_scibarcamp_palo_alto/). A month later I did an [interview with Pete](https://web.archive.org/web/20161226124822/http://blogs.plos.org/mfenner/2009/07/10/i_was_at_scibarcamp_palo_alto/) about Article Level Metrics and PLoS ONE.\n\n### What is Article Level Metrics?\n\nArticle Level Metrics *place transparent and \u00a0comprehensive information about the usage and reach of published articles onto the articles themselves, so that the entire academic community can assess their value* (from the [PLoS ALM website](https://web.archive.org/web/20161226124822/http://article-level-metrics.plos.org/)). A [November 2009 paper](https://web.archive.org/web/20161226124822/http://dx.doi.org/10.1371/journal.pbio.1000242) by Cameron Neylon and Shirley Wu gives a more detailed introduction. And a [recent presentation](https://web.archive.org/web/20161226124822/http://www.slideshare.net/kristenratan/metrics-the-new-black) by Kristen Ratan, PLoS Director of Product Management, given at the [2012 NFAIS meeting](https://web.archive.org/web/20161226124822/http://www.nfais.org/page/361-program-2012-nfais-annual-conference), provides an update for 2012.\n\nArticle Level Metrics is part of the larger [altmetrics](https://web.archive.org/web/20161226124822/http://altmetrics.org/manifesto/) movement, which also looks at metrics for other scholarly works besides journal articles.\n\n### Does this mean that you will be moving to San Francisco?\n\nFor personal reasons I will continue to live in Hannover, Germany and work from home as a contractor with occasional trips to San Francisco.\n\n### Will you miss treating cancer patients and doing cancer research?\n\nAbsolutely. This has not been an easy decision. To make the transition easier, I will continue to spend 10% of my time at Hannover Medical School. I will no longer be seeing patients, but this will allow me to conclude the RADIT [clinical trial](https://web.archive.org/web/20161226124822/http://clinicaltrials.gov/ct2/show/NCT01242631) for testicular cancer patients where I am the principal investigator.\n\nI hope to continue doing research in the new position, but with a focus on information science. There are for example still a lot of things we don't know about altmetrics. A more detailed analysis of our recent [CrowdoMeter](https://web.archive.org/web/20161226124822/http://blogs.plos.org/mfenner/2012/02/19/crowdsourcing-the-analysis-of-scholarly-tweets/) project (a crowdsourced analysis of tweets linking to scholarly papers) would be a good start.\n\n### What will happen with ScienceCard?\n\n[ScienceCard](https://web.archive.org/web/20161226124822/http://sciencecard.org/) is a website that collects author level metrics and was my entry into the [Mendeley/PLoS Binary Battle API contest](https://web.archive.org/web/20161226124822/http://blogs.plos.org/mfenner/2011/11/20/sciencecard-named-finalist-in-mendeleyplos-api-binary-battle/) last fall. ScienceCard is based on the PLoS ALM code (which is open source and [available via Google Code](https://web.archive.org/web/20161226124822/http://code.google.com/p/alt-metrics/)). I will decide in the coming months what to do with ScienceCard. This depends mainly on how much author level metrics make sense in the PLoS ALM project.\n\n### And what will happen to your other scholarly communication activities?\n\nThere is no reason not to continue my other activities, including involvement in the Open Researcher & Contributor ID ([ORCID](https://web.archive.org/web/20161226124822/http://about.orcid.org/)) initiative, and using WordPress as a [tool to write and publish manuscripts](https://web.archive.org/web/20161226124822/http://blogs.plos.org/mfenner/tag/wordpress/).\n\n### What are your future plans for this blog?\n\nI plan to continue this blog in a very similar format, and I will have more time for more in-depth articles. And of course I will indicate a conflict of interest when I write about Article Level Metrics.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw2j","guid":"62d42bbd41e317003df48dad","id":"acec12fb-40d3-4fd9-aba9-e5409fc1036b","image":"https://blog.front-matter.io/content/images/2022/08/429781913_9524791cff_c-1.jpg","indexed_at":1,"language":"en","published_at":1335139200,"reference":[],"relationships":[],"summary":"This blog occasionally does interviews with people providing interesting tools for scholars. These interviews have always been among my favorite blog posts. This now is obviously an interview with myself, but I felt this is the best format to explain some important news. Starting May 16 I will be working full-time as technical lead for the PLoS Article Level Metrics (ALM) project.\n","tags":["Interview"],"title":"PLoS Article-Level Metrics: Interview with Martin Fenner","updated_at":1660728624,"url":"https://blog.front-matter.io/posts/plos-article-level-metrics-interview-with-martin-fenner"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/random-notes-from-the-altmetrics12-conference","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"Last week I attended the [altmetrics12](https://web.archive.org/web/20160528073512/http://altmetrics.org/altmetrics12/) workshop in Chicago. You can read all 11 abstracts [here](https://web.archive.org/web/20160528073512/http://altmetrics.org/altmetrics12/program/), and the conference had good Twitter coverage (using the hashtag [#altmetrics12](https://web.archive.org/web/20160528073512/https://twitter.com/search/%23altmetrics12)), at least until Twitter had a total blackout around 12 PM our time.\n\nAll but two presenters used slides -- I have uploaded [my presentation](https://web.archive.org/web/20160528073512/https://speakerdeck.com/u/mfenner/p/altmetrics-will-be-taken-personally-at-plos) to Speaker Deck. Kelli Barr used the blackboard to explain that\n\n-   filtering (via altmetrics or any other means) by definition always selects out content and therefore runs against the democratization of science\n-   peer review is a black box. altmetrics is also a black box, only much bigger\n\n<figure class=\"kg-card kg-image-card kg-card-hascaption\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/barr.jpeg\" title=\"barr\" class=\"kg-image\" loading=\"lazy\" width=\"500\" height=\"373\" />\n<figcaption>Kelli Barr used the blackboard for two important points in <a href=\"https://web.archive.org/web/20160528073512/http://altmetrics.org/altmetrics12/barr/\">her talk</a>.</figcaption>\n</figure>\n\naltmetrics12 was one of the best conferences that I have attended recently. The intensity of the discussions was palpable. My only regrets are that there wasn't more time for discussions, but many of us convened in the bar afterwards.\n\nWe were off to a very strong start with two excellent keynote presentations by Johann Bollen ( Altmetrics: from usage data to social media) and Gregg Gordon ([Alternative is the new Grey](https://web.archive.org/web/20160528073512/http://ssrnblog.com/2012/05/18/alternative-is-the-new-grey/)). Johann emphasized why it is both important and fascinating to study how science is actually working. He stressed that science is a gift economy, where the currency is acknowledgement of influence in the form of citations. He sees two major problems with the present citation-based analysis of scientific impact: a) data and b) the metrics. Citation data are very domain specific (with very different citation practices in different disciplines), and delayed (several years after publication of the research they are citing). The problem with current citation-based metrics is that they ignore the network effect in science. Johann then went on to explain the [MESUR](https://web.archive.org/web/20160528073512/http://mesur.informatics.indiana.edu/) project, which studies the patterns of scientific activity on a very large scale (1 billion usage events, 500 million citations, 50 million papers).\n\n<figure class=\"kg-card kg-image-card kg-card-hascaption\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/journal.pone.0004803.g005-1.png\" title=\"Map of Science\" class=\"kg-image\" loading=\"lazy\" width=\"320\" height=\"305\" />\n<figcaption>Map of science from <a href=\"https://web.archive.org/web/20160528073512/http://dx.doi.org/10.1371/journal.pone.0004803\">2009 PLoS ONE paper</a>.</figcaption>\n</figure>\n\nJohann then briefly explained the results of another [2009 PLoS ONE paper](https://web.archive.org/web/20160528073512/http://dx.doi.org/10.1371/journal.pone.0006022) where he analyzed 39 metrics with principal component analysis. He found two major components in the metrics analysis: counting vs. social influence and fast vs. slow.\n\n<figure class=\"kg-card kg-image-card kg-card-hascaption\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/journal.pone_.0006022.g002.jpg\" title=\"PCA\" class=\"kg-image\" loading=\"lazy\" width=\"480\" height=\"340\" />\n<figcaption>Correlation of 37 metrics mapped onto first two principal components in another <a href=\"https://web.archive.org/web/20160528073512/http://dx.doi.org/10.1371/journal.pone.0006022\">2009 PLoS ONE paper</a>.</figcaption>\n</figure>\n\nJohann then told the interesting story behind a [2010 paper](https://web.archive.org/web/20160528073512/http://arxiv.org/abs/1010.3003) where he showed that **Twitter mood can predict the stock market**. The paper was rejected by all publishers and was finally published on ArXiV in October 2010. It immediately became very popular in terms of downloads and media attention (and was eventually [published](https://web.archive.org/web/20160528073512/http://dx.doi.org/10.1016/j.jocs.2010.12.007) in the *Journal of Computational Science* in March 2011).\n\nGregg Gordon has summarized his keynote in a May [blogpost](https://web.archive.org/web/20160528073512/http://ssrnblog.com/2012/05/18/alternative-is-the-new-grey/), so I will focus on a few highlights. Gregg Gordon runs the Social Science Research Network ([SSRN](https://web.archive.org/web/20160528073512/http://ssrn.com/)), a leading resource for sharing social sciences research. Gregg thinks that altmetrics can provide the compass to navigate the map of science described earlier. He told us some very interesting anecdotes of users trying to game SSRN by inflating their download counts (e.g. \"downloads for donuts\"), and mentioned a [research paper](https://web.archive.org/web/20160528073512/http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1346397)analyzing gaming at SSRN. Download counts are apparently taken very seriously by SSRN authors and are also used for hiring decisions. SSRN not only has written software to protect against gaming, but also has a person constantly looking over these numbers (Gregg feels that computer algorithms alone are not enough).\n\nThe two keynotes were followed by 11 short (10-15 minute) presentations, including two presentations about the PLoS [Article-Level Metrics](https://web.archive.org/web/20160528073512/http://article-level-metrics.plos.org/) project. Jennifer Lin spoke about [anti-gaming mechanisms](https://web.archive.org/web/20160528073512/http://altmetrics.org/altmetrics12/lin/) and I emphasized the importance of [personalizing altmetrics](https://web.archive.org/web/20160528073512/http://altmetrics.org/altmetrics12/fenner/) to fully understand the \"network of science\". All presentation abstracts are available [online](https://web.archive.org/web/20160528073512/http://altmetrics.org/altmetrics12/program/).\n\nAfter the lunch break (and some interesting discussions) we continued with demos of various altmetrics applications and users, including [Total Impact](https://web.archive.org/web/20160528073512/http://total-impact.org/), [Plum Analytics](https://web.archive.org/web/20160528073512/http://www.plumanalytics.com/), [altmetric.com](https://web.archive.org/web/20160528073512/http://www.altmetric.com/), the [PLoS Article-Level Metrics](https://web.archive.org/web/20160528073512/http://alm.plos.org/) application, [Knode](https://web.archive.org/web/20160528073512/http://knodeinc.com/), [Academia.edu](https://web.archive.org/web/20160528073512/http://academia.edu/), [BioMed Central](https://web.archive.org/web/20160528073512/http://www.biomedcentral.com/) and [Ubiquity Press](https://web.archive.org/web/20160528073512/http://www.ubiquitypress.com/) (example [here](https://web.archive.org/web/20160528073512/http://openarchaeologydata.metajnl.com/article/intensive-survey-data-from-antikythera-greece/)).\n\nIn the last our and a half we split up into several smaller group to discuss issues relevant for altmetrics. I was in the **standards** group and we all agreed that it is too early to sep up rigid standards for this evolving field, but not too early to start the discussion. The two standards experts in our group (Todd Carpenter from [NISO](https://web.archive.org/web/20160528073512/http://www.niso.org/home/) and David Baker from [CASRAI](https://web.archive.org/web/20160528073512/http://casrai.org/)) were of course very helpful with the discussion in our group. In the closing group discussion the breakout groups reported their major discussion points (which will hopefully be written up by someone). We also learned that the NIH is considering changing the Biosketch format for CVs and is looking for input via a [Request for Information](https://web.archive.org/web/20160528073512/http://grants.nih.gov/grants/guide/notice-files/NOT-OD-12-115.html) (RFI) until June 29.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw2g","guid":"62d42bbd41e317003df48dab","id":"223849a7-1686-47be-b9e2-b42730cb130d","image":"https://blog.front-matter.io/content/images/2022/08/journal.pone.0004803.g005.png","indexed_at":1,"language":"en","published_at":1340236800,"reference":[],"relationships":[],"summary":"Last week I attended the altmetrics12 workshop in Chicago. You can read all 11 abstracts here, and the conference had good Twitter coverage (using the hashtag #altmetrics12), at least until Twitter had a total blackout around 12 PM our time. All but two presenters used slides \u2013 I have uploaded my presentation to Speaker Deck.\n","tags":["Meeting Report"],"title":"Random notes from the altmetrics12 conference","updated_at":1660728540,"url":"https://blog.front-matter.io/posts/random-notes-from-the-altmetrics12-conference"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/visualizing-tweets-linking-to-a-paper","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"[DNA Barcoding the Native Flowering Plants and Conifers of Wales](https://web.archive.org/web/20170216233248/http://dx.doi.org/10.1371/journal.pone.0037945) has been one of the most popular new *PLoS ONE* papers in June. In the paper Natasha de Vere *et al.* describe a DNA barcode resource that covers the 1143 native Welsh flowering plants and conifers.\n\nMy new job as technical lead for the [PLoS Article Level Metrics (ALM) project](https://web.archive.org/web/20170216233248/http://article-level-metrics.plos.org/) involves thinking about how we can best display the ALM collected for this and other papers. We want these ALM to tell us something important and/or interesting, and it doesn't hurt if the information is displayed in a visually appealing way. There are many different ways this can be done, but here I want to focus on **Twitter** and **CiteULike**, the only two data sources where PLoS is currently storing every single event (tweet or CiteULike bookmark) with a date. Usage data (HTML and XML views, PDF downloads) are aggregated on a monthly basis, and PLoS doesn't store the publication dates of citations.\n\nWe know from the [work of Gunter Eysenbach](https://web.archive.org/web/20170216233248/http://blogs.plos.org/mfenner/2011/12/20/crowdometer-or-trying-to-understand-tweets-about-journal-papers/) and others that most tweets linking to scholarly papers are written in the first few days after publication. It therefore makes sense to display this information on a timeline covering the first 30 days after publication, and the tweets about the de Vere paper follow the same pattern.\n\n<figure class=\"kg-card kg-image-card\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/sparklines.png\" title=\"sparklines\" class=\"kg-image\" loading=\"lazy\" width=\"500\" height=\"375\" />\n</figure>\n\nI like the simplicity of sparklines. It would be interesting to also map the 274 Facebook **Likes, Comments,** and **Shares**, but we don't have date information for them. The same is true for the 9 Mendeley readers and groups.\n\nAnother way to display the time course of tweets (or bookmarks) is to use a calendar heat map (the paper was published on June 6).\n\n<figure class=\"kg-card kg-image-card\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/calendarPlot-1.png\" title=\"calendarPlot\" class=\"kg-image\" loading=\"lazy\" width=\"500\" height=\"320\" />\n</figure>\n\nThe chart looks a little bit empty, a calendar heat map probably works better for information with many daily data points. I would appreciate feedback on how these visualizations can be improved.\n\nThe charts were created with data from the [PLoS ALM API](https://web.archive.org/web/20170216233248/http://api.plos.org/) and the statistical computing package [R](https://web.archive.org/web/20170216233248/http://www.r-project.org/), the source code is available [here](https://web.archive.org/web/20170216233248/https://github.com/articlemetrics/plosOpenR/blob/master/sparkLines.R) and [here](https://web.archive.org/web/20170216233248/https://github.com/articlemetrics/plosOpenR/blob/master/calendarPlot.R).\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw2f","guid":"62d42bbd41e317003df48daa","id":"12f93167-269c-49b6-a10f-34cdefad0bcd","image":"https://blog.front-matter.io/content/images/2022/08/calendarPlot.png","indexed_at":1,"language":"en","published_at":1342224000,"reference":[],"relationships":[],"summary":"DNA Barcoding the Native Flowering Plants and Conifers of Wales has been one of the most popular new\n<em>\n PLoS ONE\n</em>\npapers in June. In the paper Natasha de Vere\n<em>\n et al.\n</em>\ndescribe a DNA barcode resource that covers the 1143 native Welsh flowering plants and conifers. My new job as technical lead for the PLoS Article Level Metrics (ALM) project involves thinking about how we can best display the ALM collected for this and other papers.\n","tags":["Chart"],"title":"Visualizing tweets linking to a paper","updated_at":1660728421,"url":"https://blog.front-matter.io/posts/visualizing-tweets-linking-to-a-paper"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/europe-pubmed-central-coming-in-november","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"The [European Research Council](https://web.archive.org/web/20160528080726/http://erc.europa.eu/) on Friday [announced](https://web.archive.org/web/20160528080726/http://erc.europa.eu/sites/default/files/press_release/files/EuropePMC_press_release_WT_ERC_FINAL.pdf) that they will participate in the UK PubMed Central (UKPMC) open access repository service. They become the third European funder to join UKPMC, and the existing UKPMC funders have agreed to rebrand UKPMC as Europe PubMed Central (abbreviated to EPMC?) on November 1st.\n\nMore information about these changes can be found on the [UKPMC blog](https://web.archive.org/web/20160528080726/http://ukpmc.blogspot.de/2012/07/european-research-council-renews-its.html) and in the [Wellcome Trust press release](https://web.archive.org/web/20160528080726/http://www.wellcome.ac.uk/News/Media-office/Press-releases/2012/WTVM055890.htm).\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw2e","guid":"62d42bbd41e317003df48da9","id":"8ece3fd3-7ab8-4e44-ae52-a6658aed9661","image":"https://blog.front-matter.io/content/images/2022/08/epmc.gif","indexed_at":1,"language":"en","published_at":1342396800,"reference":[],"relationships":[],"summary":"The European Research Council on Friday announced that they will participate in the UK PubMed Central (UKPMC) open access repository service. They become the third European funder to join UKPMC, and the existing UKPMC funders have agreed to rebrand UKPMC as Europe PubMed Central (abbreviated to EPMC?) on November 1st. More information about these changes can be found on the UKPMC blog and in the Wellcome Trust press release.\n","tags":["News"],"title":"Europe PubMed Central coming in November","updated_at":1660728053,"url":"https://blog.front-matter.io/posts/europe-pubmed-central-coming-in-november"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/more-fun-with-visualizations","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"This has been another week working on visualizations. I have summarised some of the results in a [blog post](https://web.archive.org/web/20160528080207/http://api.plos.org/2012/07/20/example-visualizations-using-the-plos-search-and-alm-apis/) over at the PLoS API website. One of my current favorites is the dot chart. PLoS Computational Biology publishes a [collection of Ten Simple Rules](https://web.archive.org/web/20160528080207/http://www.ploscollections.org/article/browseIssue.action?issue=info:doi/10.1371/issue.pcol.v03.i01). The dot chart below summarizes the HTML pageviews, PDF downloads and Mendeley readers for this collection.\n\nOn Wednesday I gave a presentation about Article-Level Metrics, using many of the same visualizations. You can find the slides over at [Speaker Deck](https://web.archive.org/web/20160528080207/https://speakerdeck.com/u/mfenner/p/article-level-metrics) (my new favorite to upload presentation slides).\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw2d","guid":"62d42bbd41e317003df48da8","id":"4232e361-242b-4949-9771-ead4418b668a","image":"https://blog.front-matter.io/content/images/2022/08/dotchart2-500x386.png","indexed_at":1,"language":"en","published_at":1342742400,"reference":[],"relationships":[],"summary":"This has been another week working on visualizations. I have summarised some of the results in a blog post over at the PLoS API website. One of my current favorites is the dot chart. PLoS Computational Biology publishes a collection of Ten Simple Rules. The dot chart below summarizes the HTML pageviews, PDF downloads and Mendeley readers for this collection.\n","tags":["Chart"],"title":"More fun with Visualizations","updated_at":1660728010,"url":"https://blog.front-matter.io/posts/more-fun-with-visualizations"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/persistent-identifiers-and-urls","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"Just like the rest of the internet, much of our scholarly infrastructure\nis built around the Hypertext Transfer Protocol (HTTP), increasingly\nHTTPS for security, and soon [HTTP/2](https://http2.github.io/) for\nbetter performance. In this infrastructure Universal Resource Locators\n(URLs) are essential to locate resources (sic) such as scholarly\narticles, datasets, researchers, organizations, or grants. Read\n[this](http://site.thomsonreuters.com/site/data-identifiers/) recent\nThomson Reuters report for a good recent perspective on this topic.\nWhile this works for the most part, there are some issues with URLs -\nnot specific to scholarly content, but particularly import here:\n\n1.  multiple URLs can point to the same resource\n2.  URLs can be long and look ugly\n3.  URLs can change or break, making it hard or impossible to locate the\n    resource\n4.  we are used to central indexes (or databases) describing these\n    resources, allowing us to do sophisticated queries not possible in a\n    generic web search, e.g. find all publications by author John Doe,\n    published since 2012.\n\nNo. 1 is a problem relevant to all URLs, e.g. web searches or\nliking/commenting a particular web page. Originally suggested by Google,\n[Canonical\nURLs](https://support.google.com/webmasters/answer/139066?hl=en) are\nessential for services such as Facebook or\n[Hypothes.is](https://hypothes.is/blog/cross-format-annotation/). They\nhave been formalized in [rfc6596](http://tools.ietf.org/html/rfc6596)\nand are commonly used.\n\nNo. 2 can be a problem, in particular if we are not careful in designing\nappropriate URLs for landing pages (see next paragraph), but rather use\nsomething long and unreadable that also includes query parameters, etc.\nIf we have no control over how the URL looks like, we can use URL\nshortener services such as [bit.ly](https://bitly.com/), which of course\nhave become a common sight on the web. [ShortDOIs](http://shortdoi.org/)\nare an URL shortener for DOIs, but they don't seem to have gained much\ntraction.\n\nNo. 3 is a particularly important issue, commonly referred to as\n****link rot**** and described extensively for the scholarly literature,\ne.g. by [Klein](https://doi.org/10.1371/journal.pone.0115253). There are\nseveral technical solutions to this problem, a common approach is to use\na landing page for the resource that will never change (and follows the\nrecommendations by Tim Berners-Lee for [Cool\nURIs](http://www.w3.org/Provider/Style/URI.html), and then use\nredirection to point to the current location of the resource. This is\neasily for changes of the URL path using web server [redirect\nrules](http://httpd.apache.org/docs/2.4/rewrite/remapping.html). It gets\nmore complicated if the server name also changes, in particular if it is\nthe server holding the landing page. Thinking this through you realize\nthat the only way this can be done on a larger scale is via one or more\ncentralized services that not only provide the technical infrastructure\nfor a central redirection (or resolver) service, but also come with a\nsocial contract of rules that everyone submitting URLs to the service\nhas to follow - a major difference to URL shorteners, which don't solve\nthe link rot problem.\n\nThe above is of course a description of the DOI service provided by\nCrossRef, DataCite, and others, as well as similar persistent identifier\nservices. Unfortunately some persistent identifier services don't do the\nabove: they create and use persistent identifiers, but there is no\ncentral resolver service that maps these identifiers back to URLs. This\nbreaks the integration with the bigger scholarly infrastructure based on\nURLs. One common example are nucleotide sequences such as U65091, there\nis no single corresponding URL because the sequence can be found in all\nthree main nucleotide databases:\n<http://www.ncbi.nlm.nih.gov/nuccore/U65091>. It would help to have a\ncentral resolver, e.g. http://nucleotide.org/U65091 that then redirects\nto one of the three databases based on geographical location or user\npreference.\n\nThere are also problems with DOIs. They use the\n[Handle](http://www.handle.net/) system to resolve the identifier to a\nlocation, and this system was built in the 1990s as infrastructure\n[independent of](http://www.handle.net/faq.html) URLs or DNS (Domain\nName Service), at a time when it wasn't clear yet that URLs and\nassociated standards would become ubiquitous. I don't have numbers, but\npractically all DOIs are of course now resolved to URLs using the [DOI\nproxy server](http://www.doi.org/factsheets/DOIProxy.html) at\nhttp://doi.org (preferred) or http://dx.doi.org. One main consequence of\nthis is that DOIs are frequently not written as URLs - e.g.\ndoi:10.5555/24242424x instead of <https://doi.org/10.5555/24242424x> -\nagain breaking the integration with the bigger scholarly infrastructure.\nThe CrossRef [DOI display\nguidelines](http://www.crossref.org/02publishers/doi_display_guidelines.html)\nclearly state that DOIs should be written as URLs in *the online\nenvironment*, which basically is whenever DOIs are used, as PDFs and\neven Word documents know how to handle URLs. Unfortunately this\nguideline is still frequently ignored. The above is of course also true\nfor other persistent identifiers using the Handle system, e.g.\n[ePIC](http://www.pidconsortium.eu/).\n\nThe other problem with the DOI system is that it doesn't address issue\nNo. 4, i.e. provide a central metadata index for the resources that use\nthe system. This job is left to the DOI registration agencies such as\nCrossRef and DataCite, who have implemented a central metadata store\n(e.g. [CrossRef](https://search.crossref.org/) or\n[DataCite](https://search.datacite.org/)) in different ways (e.g. using\ndifferent metadata schemata), or not at all. This means that we have to\nlook in several places to find all DOIs associated with author John Doe,\npublished since 2012. Obviously we are used to looking up information in\nmultiple places, but not being able to look up the metadata for a DOI\nwithout some extra work (finding out the registration agency for the DOI\nand then going to the respective metadata store) is a problem. One way\naround these problems is to use the [DOI Content Negotiation\nService](https://citation.crosscite.org/docs.html).\n\nAnother problem with the DOI system is more a social than a technical\nissue. Neither CrossRef nor DataCite seem to enforce that DOIs should\nalways resolve to URLs when using a computer program. DOI resolution for\nhumans works fine, but computers, e.g. command line tools such as cURL,\ncan run into issues such as requiring cookies, javascript or user input,\nor permission problems getting to the journal landing page (see [this\nearlier blog\npost](https://blog.front-matter.io/posts/challenges-in-automated-doi-resolution)\nfor some numbers). People seem to forget that a DOI that is not\nactionable is not really useful, and that scholarly infrastructure is\nnot only used by people, but of course also by automated tools.\n\nThe persistent identifiers used in our scholarly infrastructure would\nbenefit from a clearer focus on the problems they should solve, starting\nwith No. 1-4 above. One problem is that we probably focus too much on\nthe persistence problem, implied also by the term ****persistent\nidentifier**** or ****PID****. What we have neglected is the resolvable\nproblem, i.e. making as easy as possible to get from the persistent\nidentifier to the resource and/or its metadata. Based on the Den Haag\nManifesto and suggested by Todd Vision, we therefore proposed the term\n****trusted identifier**** with the following characteristics in the\n[conceptual model of\ninteroperability](https://doi.org/10.6084/m9.figshare.824314) for the\n[ODIN Project](http://odin-project.eu/):\n\n- are unique on a global scale, allowing large numbers of unique\n  identifiers\n- resolve as HTTP URI's with support for content negotiation, and these\n  HTTP URI's should be persistent.\n- come with metadata that describe their most relevant properties,\n  including a minimum set of common metadata elements. A search of\n  metadata elements across all trusted identifiers of that service\n  should be possible.\n- are interoperable with other identifiers through metadata elements\n  that describe their relationship.\n- are issued and managed by an organization that focuses on that goal as\n  its primary mission, has a sustainable business model and a critical\n  mass of member organizations that have agreed to common procedures and\n  policies, has a governing body, and is committed to using open\n  technologies.\n\nWhile not directly relevant for resolving persistent identifiers as\nURLs, the last point is really important for any persistent identifier\ninfrastructure, [described in detail\nrecently](https://doi.org/10.6084/m9.figshare.1314859).\n\nIf I would design a persistent identifier service today (as if we would\nneed yet another persistent identifier service), I would build the\nsystem around an URL shortening service that I control. The URLs could\nlook very similar to what we have with DOIs now, e.g.\n[https://doi.org/10.5555/12345678](http://doi.org/10.5555/12345678), but\nit would be clear that persistent identifiers are URLs, not something\nseparate. Plus we could take advantage of all the lessons learned - and\npossibly even reuse open source code - with URL shorteners, which are\nmuch more widely used than scholarly persistent identifiers.\n\n*Update 6/4/15: added link to Thomson Reuters\n[report](http://site.thomsonreuters.com/site/data-identifiers/) on\nidentifiers and open data.*\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cvzr","guid":"62d42bbd41e317003df48d53","id":"3dfe984a-3d73-43c3-8a6f-920faf128231","image":null,"indexed_at":1,"language":"en","published_at":1433328180,"reference":[],"relationships":[],"summary":"Just like the rest of the internet, much of our scholarly infrastructure is built around the Hypertext Transfer Protocol (HTTP), increasingly HTTPS for security, and soon HTTP/2 for better performance. In this infrastructure Universal Resource Locators (URLs) are essential to locate resources (sic) such as scholarly articles, datasets, researchers, organizations, or grants.\n","tags":["Feature"],"title":"Persistent Identifiers and URLs","updated_at":1660726369,"url":"https://blog.front-matter.io/posts/persistent-identifiers-and-urls"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/what-users-do-with-plos-one-papers","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"Inspired by four recent blog posts and their comments ([Comments at journal websites: just turn them off](https://web.archive.org/web/20170423155530/http://nsaunders.wordpress.com/2012/07/13/comments-at-journals-websites-just-turn-them-off/), [Open Access and The Dramatic Growth of PLoS ONE](https://web.archive.org/web/20170423155530/http://figshare.com/blog/Open_Access_and_The_Dramatic_Growth_of_PLoS_ONE/41), [No Comment?](https://web.archive.org/web/20170423155530/http://blogs.plos.org/everyone/2012/07/23/no-comment/), [If you email it, they will comment](https://web.archive.org/web/20170423155530/http://perlsteinlab.com/round-table/if-you-email-it-they-will-comment)), I created a graphic to show what users do with PLoS ONE papers. As always, the data behind the graphic are [openly available](https://web.archive.org/web/20170423155530/http://www.plosone.org/static/almInfo.action). I think that the number of times a paper is informally discussed (comments, Facebook, science blogs, etc.) should be much larger compared to the number of formal citations. The challenge is of course to have technology that captures all these discussions -- this is much more difficult than for bookmarks or citations, and is obviously what [altmetrics](https://web.archive.org/web/20170423155530/http://altmetrics.org/manifesto/) is all about. The blog posts I link to above also express another feeling: that there are still too many barriers for scientists to take part in the informal discussion of scholarly research on the web, in particular as comments on journal websites. Hat tip to [David McCandless](https://web.archive.org/web/20170423155530/http://www.davidmccandless.com/) for inspiration.\n\n*Update 08/02/12: The publication of the dataset used in this chart was delayed, but the data are now available at the [link](https://web.archive.org/web/20170423155530/http://www.plosone.org/static/almInfo.action) provided.*\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw2b","guid":"62d42bbd41e317003df48da6","id":"7a78be53-1e9c-4877-87b9-89ff238b3411","image":"https://blog.front-matter.io/content/images/2022/08/PLoS-ONE-summary-466x500-1.png","indexed_at":1,"language":"en","published_at":1343088000,"reference":[],"relationships":[],"summary":"Inspired by four recent blog posts and their comments (Comments at journal websites: just turn them off, Open Access and The Dramatic Growth of PLoS ONE, No Comment?, If you email it, they will comment), I created a graphic to show what users do with PLoS ONE papers. As always, the data behind the graphic are openly available.\n","tags":["Chart"],"title":"What Users do with PLOS ONE Papers","updated_at":1660725707,"url":"https://blog.front-matter.io/posts/what-users-do-with-plos-one-papers"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/bye-bye-nature-network-welcome-scilogs-com","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"The science blogging network Nature Network is [moving to a new home](http://blogs.nature.com/ofschemesandmemes/2012/07/26/a-new-era-for-the-nature-network-blogs). Today [SciLogs.com](http://www.scilogs.com/) launched as a new home for Nature Network bloggers. I have been blogging at Nature Network for three years, starting with my first blog post ([Open access may become mandatory for NIH-funded research](https://blog.front-matter.io/posts/open_access_may_become_mandatory_for_nih_funded_research/)) almost exactly 5 years ago to the day. My blog moved to PLOS BLOGS in September 2010 and all my old Nature Network content can be found here at PLOS BLOGS.\n\nBlogging at Nature Network has changed my life in many ways. Thank you Matt and Corie (and later Lou) to make this possible.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw2a","guid":"62d42bbd41e317003df48da5","id":"6a9abc29-7e72-4583-8237-f37c7896ab1d","image":"https://blog.front-matter.io/content/images/2022/08/nature-network.jpeg","indexed_at":1,"language":"en","published_at":1343260800,"reference":[],"relationships":[],"summary":"The science blogging network Nature Network is moving to a new home. Today SciLogs.com launched as a new home for Nature Network bloggers. I have been blogging at Nature Network for three years, starting with my first blog post (Open access may become mandatory for NIH-funded research) almost exactly 5 years ago to the day. My blog moved to PLOS BLOGS in September 2010 and all my old Nature Network content can be found here at PLOS BLOGS.\n","tags":["News"],"title":"Bye bye Nature Network, welcome SciLogs.com","updated_at":1660725572,"url":"https://blog.front-matter.io/posts/bye-bye-nature-network-welcome-scilogs-com"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/orcid-has-launched-whats-next","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"Last week has been busy. I went to Berlin for the launch of the [Open Researcher & Contributor ID (ORCID)](https://web.archive.org/web/20170518120701/http://orcid.org/) service. ORCID allows researchers to obtain a persistent identifier that can be used to claim publications and other scholarly works. I'm [0000-0003-1419-2405](https://web.archive.org/web/20170518120701/http://orcid.org/0000-0003-1419-2405), and we put the ID (and the QR code linking to the profile on the ORCID website) on the name tags for the ORCID Outreach Meeting last Wednesday (Geek alert: I also have received a T-shirt with my name, ORCID and QR code).\n\nI was invited to work with ORCID in early 2010 after writing about the initiative that was started in November 2009 on this blog ([ORCID or how to build a unique identifier for scientists in 10 easy steps](https://web.archive.org/web/20170518120701/http://blogs.plos.org/mfenner/2010/01/03/orcid_or_how_to_build_a_unique_identifier_for_scientists_in_10_easy_steps/)). And now, after three years and a lot of work by a lot of people, ORCID is real and everyone can use the system. As a researcher, you can go to the ORCID website and register.\n\n<figure class=\"kg-card kg-image-card\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/orcid-500x445-1.png\" class=\"kg-image\" loading=\"lazy\" width=\"500\" height=\"445\" />\n</figure>\n\nObtaining a number is of course not very interesting in itself, few people get excited about the fact of having a 16-digit unique identifier. What ORCID is really about is claiming your publications and other scholarly works, and **Connecting Research and Researchers** is the slogan of the organization. In the ORCID system you can now claim publications found in the CrossRef database, and other work types will be added over time.\n\nWhat I'm particularly interested in is the claiming of research datasets. Everyone wants to give researchers better credit for the data they have produced, transformed and annotated, but data citation is still not a widespread practice. I am therefore very excited to be involved in the [ORCID and DataCite Interoperability Network](https://web.archive.org/web/20170518120701/http://www.odin-project.eu/) (ODIN), a EU-funded project that had its kickoff meeting last week in Berlin.\n\n<figure class=\"kg-card kg-image-card\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/odin-500x319.png\" class=\"kg-image\" loading=\"lazy\" width=\"500\" height=\"319\" />\n</figure>\n\nIn the ODIN project we will work closely with [DataCite](https://web.archive.org/web/20170518120701/http://www.datacite.org/), an organization that provides digital object identifiers (DOIs) for research data. One of the many things I like about ODIN is that social sciences is one of the disciplines where we will build a proof of concept (with the British Library, the other discipline is high-energy physics and CERN). We also want to understand how to best link researchers, data and publications. [Dryad](https://web.archive.org/web/20170518120701/http://datadryad.org/) is an ODIN project partner and obviously has a lot of experience linking biological datasets to publications, and we will discuss how to integrate ORCID identifiers into the workflow.\n\nUnique identifiers for researchers are of course also an essential part of any work on article-level metrics. I [spoke about this](https://web.archive.org/web/20170518120701/http://blogs.plos.org/mfenner/2012/06/25/random-notes-from-the-altmetrics12-conference/) at the altmetrics12 conference in June, and I'm excited that we can now finally start linking things together. [ImpactStory](https://web.archive.org/web/20170518120701/http://impactstory.org/) was one of the ORCID launch partners, and I demoed their ORCID integration last week in Berlin.\n\n[ScienceCard](https://web.archive.org/web/20170518120701/http://sciencecard.org/) is a fork of the open source [PLOS Article-Level Metrics application](https://web.archive.org/web/20170518120701/http://article-level-metrics.plos.org/), and is a project I started [about a year ago](https://web.archive.org/web/20170518120701/http://blogs.plos.org/mfenner/2011/11/20/sciencecard-named-finalist-in-mendeleyplos-api-binary-battle/). ScienceCard allows researchers to list all their publications, and the metrics associated with them. With the launch of ORCID I was able to finally add one important missing piece. Through automatic lookup of the ORCID identifier and retrieval of the publications claimed in the ORCID profile is has become much easier to create and maintain a ScienceCard profile -- it shouldn't take more than 5 min and a few mouse clicks (collecting all metrics takes longer because that happens in the background). I added ORCID integration to ScienceCard over the weekend, using the [free public ORCID API](https://web.archive.org/web/20170518120701/http://dev.orcid.org/resources).\n\n<figure class=\"kg-card kg-image-card\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/sciencecard-500x438.png\" class=\"kg-image\" loading=\"lazy\" width=\"500\" height=\"438\" />\n</figure>\n\nScienceCard is a great tool to explore how research impact can be collected and displayed, and I appreciate feedback in the form of feature requests and bug reports, ideally in the [GitHub issue tracker](https://web.archive.org/web/20170518120701/https://github.com/mfenner/alm/issues) of the project. This will also provide very valuable feedback to improve the PLOS Article-Level Metrics application, as they use almost the same code base. The API is for example completely the same, [rplos](https://web.archive.org/web/20170518120701/https://github.com/ropensci/rplos) and other tools using the PLOS ALM API can be used with ScienceCard by just changing the URL. Another example is the [PLOS ALM WordPress Widget](https://web.archive.org/web/20170518120701/http://wordpress.org/extend/plugins/plos-alm-widget/), with minor modifications it can be also be used with ScienceCard, allowing a researcher to display the metrics for his publications from PLOS and other sources on his blog. The upcoming [Altmetrics workshop and hackathon](https://web.archive.org/web/20170518120701/https://sites.google.com/site/altmetricsworkshop/) (November 1-3 in San Francisco) will be a great opportunity to explore this further.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw28","guid":"62d42bbd41e317003df48da3","id":"1bb64b71-200a-48f4-9061-da59784f0472","image":"https://blog.front-matter.io/content/images/2022/08/nametag-500x283.png","indexed_at":1,"language":"en","published_at":1350864000,"reference":[],"relationships":[],"summary":"Last week has been busy. I went to Berlin for the launch of the Open Researcher &amp; Contributor ID (ORCID) service. ORCID allows researchers to obtain a persistent identifier that can be used to claim publications and other scholarly works.\n","tags":["Feature"],"title":"ORCID has launched. What\u2019s next?","updated_at":1660725314,"url":"https://blog.front-matter.io/posts/orcid-has-launched-whats-next"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/the-price-of-innovation-my-thoughts-for-beyond-the-pdf","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"The [Beyond the PDF Conference](https://web.archive.org/web/20170731155123/http://www.force11.org/taxonomy/term/27) is currently taking place in Amsterdam. Unfortunately, I am unable to attend in person this time (I took part in the first Beyond the PDF in January 2011), but I was watching the [livestream](https://web.archive.org/web/20170731155123/http://www.force11.org/beyondthepdf2/live) of the [Business Case](https://web.archive.org/web/20170731155123/http://blogs.plos.org/mfenner/2013/03/20/the-price-of-innovation-my-thoughts-for-beyond-the-pdf/ww.force11.org/Business_Case) panel discussion yesterday afternoon.\n\nHow to pay for the development of new scientific infrastructure and tools is something that I think a lot about science moving away from academia to become a developer of scientific software last year. I would assume three things:\n\n-   there are a lot of great ideas out there to improve scholarly communication\n-   there is enough money out there to pay for improvements in scholarly communication\n-   we are frustrated because progress is much slower than we anticipate\n\nIf we have enough great ideas and enough money, but don't see the results we expect, something must be going wrong. A simple answer would be that it is different people and organizations that have the ideas from those that have the money, but I don't think that this is the reason. My suspicion is that there is a deeper problem, and that the approach we take to scholarly innovation is broken. Below is how innovation is approached by the major players:\n\n-   individual scientists and/or software developers come up with great ideas, but don't get past the prototype stage because of limited resources\n-   academic tools and infrastructure are built as part of a funded project (anywhere from 6 months to a few years), but there are no resources to turn this into a service that is persistent beyond the project\n-   publishers and large academic institutions have the resources to build these tools. They are often less innovative because of their size\n-   funders pay for projects (see above), but rarely for infrastructure, and they rarely get involved in innovative projects themselves\n-   commercial organizations can quickly bring great ideas to market (in particular small startups), but it is often unclear how their services are paid for in the long run\n\nAt the end of the day it seems that we have a lot of great ideas, but many of them never reach critical mass, and an even smaller number has long-term sustainability. I can think of a number of great projects that have never gained traction, and of a number of great tools and services where I have no idea how their development and service is paid for. The idea to get to a large number of users no matter what it costs, and figure out the business plan later is popular with internet startups, but dangerous when we care about tools we want to still use two years from now. Two projects that are not specific to science, but are important for science and have made this work are **Wikipedia** and **Github**. From the long list of tools for scientists I would not pick **Mendeley** or **figshare** (both great services, but still in search of sustainability), but **ArXiV** and **Papers**.It also doesn't help that most scientists are a conservative bunch when it comes to technology, and that the scientific market is fairly small compared to the overall number of users. Another big challenge is to innovate in an open environment, i.e. to make the innovation available to as many people as possible without barriers of access. Some of my personal conclusions from all this are the following:\n\n-   we should acknowledge that we have an innovation problem, and it is not simply solved by getting more money\n-   we have a collaboration problem, too many people are doing similar things without talking to each other and working together\n-   scientific infrastructure and tools cost money. We need the right people to pay (ideally not the individual researcher), fair prices and intelligent business models\n-   funders should reconsider how they pay for scientific infrastructure, as the project-based approach is broken\n-   large organizations (commercial, non-commercial and academic) should think about their approach to innovation, in particular how they support innovation outside of their organization\n\nYou can follow the Beyond the PDF [livestream](https://web.archive.org/web/20170731155123/http://www.force11.org/beyondthepdf2/live) today or follow the Twitter hashtag [#btpdf2](https://web.archive.org/web/20170731155123/https://twitter.com/search?q=%23btpdf2&src=hash).\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw26","guid":"62d42bbd41e317003df48da1","id":"1b14c023-2919-418b-84e6-9076a797f0e3","image":"https://blog.front-matter.io/content/images/2022/08/291798596_dbfcfc26d7_c-1.jpg","indexed_at":1,"language":"en","published_at":1363737600,"reference":[],"relationships":[],"summary":"The Beyond the PDF Conference is currently taking place in Amsterdam. Unfortunately, I am unable to attend in person this time (I took part in the first Beyond the PDF in January 2011), but I was watching the livestream of the Business Case panel discussion yesterday afternoon.\n","tags":["Meeting Report"],"title":"The Price of Innovation \u2013 my Thoughts for Beyond the PDF","updated_at":1660725087,"url":"https://blog.front-matter.io/posts/the-price-of-innovation-my-thoughts-for-beyond-the-pdf"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/using-d3-js-to-visualize-article-level-metrics-over-time","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"PLOS Article-Level Metrics (ALM) are a great set of data (available via API and as [monthly data dump](https://web.archive.org/web/20170731170128/http://article-level-metrics.plos.org/plos-alm-data/)) for some nice data visualizations. I have recently become a big fan of the [d3.js](https://web.archive.org/web/20170731170128/http://d3js.org/) javascript library, and have now used d3 to look at some ALM data over time.\n\nI like simple visualizations without too many labels or axes, and wanted to do a visualization inspired by [sparklines](https://web.archive.org/web/20170731170128/http://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=0001OR) ever since we discussed this idea in our *altviz* breakout group at the [ALM workshop hackathon](https://web.archive.org/web/20170731170128/http://article-level-metrics.plos.org/alm-workshop-2012/hackathon/#altviz) in November 2012 (kudos in particular to Juan Alperin, Karthik Ram and Carl Boettiger). In the chart below every column represents the numbers for a given month, with alternating colors for the years (the article was published November 2009).\n\n<figure class=\"kg-card kg-image-card kg-card-hascaption\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/sparklines4-e1364338936408-1.png\" class=\"kg-image\" loading=\"lazy\" width=\"300\" height=\"263\" alt=\"sparklines4\" />\n<figcaption>CiteULike bookmarks, usage stats from PLOS website and blog posts for article <strong>Article-Level Metrics and the Evolution of Scientific Impact</strong> by month, available at <a href=\"https://web.archive.org/web/20170731170128/http://dx.doi.org/10.1371/journal.pbio.1000242\">http://dx.doi.org/10.1371/journal.pbio.1000242</a>.</figcaption>\n</figure>\n\nYou can see a pattern that is probably typical for many articles independent of the absolute numbers: most pageviews and downloads happen in the weeks after publication, as does academic bookmarking and science blogging.\n\nThe second example shows a very different pattern. This is not only the [most-downloaded](https://web.archive.org/web/20170731170128/http://alm.plos.org/sources/counter) PLOS article, but \u00a0the distribution of downloads over time is very different, with the number of monthly downloads actually higher the last two years (this article was published in August 2005). We also see a few spikes in the usage stats, probably indicating events that triggered usage. Academic bookmarking was most active from 2009 to 2011 and not right after publication, although that might also have to do with the relative popularity of CiteULike over time.\n\n<figure class=\"kg-card kg-image-card kg-card-hascaption\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/sparklines5-500x262.png\" class=\"kg-image\" loading=\"lazy\" width=\"500\" height=\"262\" alt=\"sparklines5\" />\n<figcaption>CiteULike bookmarks, usage stats from PLOS website and blog posts for article <strong>Why Most Published Research Findings Are False</strong> by month, available at <a href=\"https://web.archive.org/web/20170731170128/http://dx.doi.org/10.1371/journal.pmed.0020124\">http://dx.doi.org/10.1371/journal.pmed.0020124</a>.</figcaption>\n</figure>\n\nCitation data are unfortunately more difficult to get with exact publication dates (why is that so difficult?), but we can at least look at CrossRef numbers by year for the same article.\n\n<figure class=\"kg-card kg-image-card kg-card-hascaption\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/sparklines31-e1364340861413.png\" class=\"kg-image\" loading=\"lazy\" width=\"200\" height=\"169\" alt=\"sparklines3\" />\n<figcaption>CiteULike bookmarks, usage stats from PLOS website and blog posts for article <strong>Why Most Published Research Findings Are False</strong> by year, available at <a href=\"https://web.archive.org/web/20170731170128/http://dx.doi.org/10.1371/journal.pmed.0020124\">http://dx.doi.org/10.1371/journal.pmed.0020124</a>.</figcaption>\n</figure>\n\nThe citation numbers by year are still increasing (the last bar is for 2013), indicating that this article is still of general interest 8 years after publication. This would probably be unusual for a life sciences research article, but the article is an essay looking at common pitfalls in the statistical analysis of research data.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw24","guid":"62d42bbd41e317003df48d9f","id":"faec9558-0b53-438b-9f9a-4c81534ee1f4","image":"https://blog.front-matter.io/content/images/2022/08/sparklines4-e1364338936408.png","indexed_at":1,"language":"en","published_at":1364256000,"reference":[],"relationships":[],"summary":"PLOS Article-Level Metrics (ALM) are a great set of data (available via API and as monthly data dump) for some nice data visualizations. I have recently become a big fan of the d3.js javascript library, and have now used d3 to look at some ALM data over time.\n","tags":["Chart"],"title":"Using d3.js to visualize Article-Level Metrics over time","updated_at":1660724860,"url":"https://blog.front-matter.io/posts/using-d3-js-to-visualize-article-level-metrics-over-time"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/lemon8-xml-interview-with-mj-suhonos","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"Finishing an exciting research project and writing it up in a paper are the first two steps in getting your work published. The next two steps -- submitting your paper to a journal and getting it through the review process -- have changed dramatically in the last 10-15 years. No longer do we have to print out our manuscript using one of the few available laser printers in the department, paste our gel pictures on cardboard and number the figures with Letraset. And then send it off with the mail. And then repeat the process for every revision of the manuscript.\n\nNow of course we submit our manuscripts online using a manuscript submission system such as [Editorial Manager](https://web.archive.org/web/20151003091211/http://www.editorialmanager.com/homepage/home.htm) or [eJournalPress](https://web.archive.org/web/20151003091211/http://www.ejpress.com/index.shtml). Which is not to say that the process is necessarily easy or fun. Many of us can tell stories of spending hours or whole days until the manuscript is finally submitted. We struggle with the conversion of the different parts of the manuscript into a single PDF file, have problems with fonts, have to deal with different graphics formats (e.g. PDF, JPEG, EPS, TIFF), don't use the correct style for our references, etc.\n\nThe flip side of this is the time and money spent at the journal to format your accepted manuscript into something that can be turned into a journal article published online or in print.\n\nSome of these problems wouldn't exist if we used a common document format for manuscript writing, manuscript revisions and manuscript printing and online viewing. That common document format does exist and is called [NLM Journal Publishing DTD](https://web.archive.org/web/20151003091211/http://dtd.nlm.nih.gov/publishing/) (and no, it's not LaTex). This document format is used in the workflow of many journals, but until now has rarely been used by authors. Last November [I talked with Pablo Fermicola](https://web.archive.org/web/20151003091211/http://network.nature.com/people/mfenner/blog/2008/11/07/interview-with-pablo-fernicola) about a free tool that allows Microsoft Word to save manuscripts in that format ([Microsoft Word Authoring Add-In](https://web.archive.org/web/20151003091211/http://www.microsoft.com/DOWNLOADS/details.aspx?FamilyID=09c55527-0759-4d6d-ae02-51e90131997e&displaylang=en)). [eXtyles NLM](https://web.archive.org/web/20151003091211/http://www.inera.com/extylesinfo.shtml#NLM) is another tool for Microsoft Word with similar functionality.\n\n[Lemon8-XML](https://web.archive.org/web/20151003091211/http://pkp.sfu.ca/lemon8) takes a different approach in helping academic authors convert their manuscripts into the NLM DTD format. Version 1.0 of the software [was released today](https://web.archive.org/web/20151003091211/http://pkp.sfu.ca/node/1891), so this was a great opportunity to talk with the lead developer **MJ Suhonos** about Lemon8-XML.\n\n### 1. Can you describe what Lemon8-XML is and does? {#1-can-you-describe-what-lemon8-xml-is-and-does}\n\nLemon8-XML is a freely-available, open source web application that aims to help academic authors and editors convert scholarly articles from layout formats like Microsoft Word to structured XML formats without requiring a great deal of knowledge of XML or the schema that they're working with. It's based on the [OpenDocument](https://web.archive.org/web/20151003091211/http://opendocument.xml.org/overview) format internally, and the [NLM Journal Publishing DTD](https://web.archive.org/web/20151003091211/http://dtd.nlm.nih.gov/publishing/) as the default export format.\n\nOriginally, Lemon8-XML came from a bunch of scripts that performed a series of tasks:\n\n-   convert an author's article from a myriad of document formats to OpenDocument,\n-   parse the article and try to extract metadata, determine section structure based on layout information, and parse citations into their disparate elements,\n-   export this semantic data as XML.\n\nThe work to date on Lemon8-XML has been building these functions into an easy-to-use web UI that also provides some editing facilities; for example, to fix problems from incomplete or incorrect parsing. One of the most promising features of Lemon8-XML is its ability to parse citations in a wide range of formats, and automatically try to correct or enhance them by searching for their complete records in, eg. PubMed, CrossRef, and WorldCat.\n\n### 2. What are the advantages of using Lemon8-XML over traditional word processors such as Microsoft Word? {#2-what-are-the-advantages-of-using-lemon8-xml-over-traditional-word-processors-such-as-microsoft-word}\n\nI should start by clarifying that Lemon8-XML wasn't really intended to be used as a word processor, but rather a conversion tool to be used after the writing was done. This was to fit in with existing practices, where authors upload papers to a journal and the editing is done afterwards. Of course, the advent of online word processors challenges this notion, and has caused us to think differently about the editing aspects of Lemon8-XML. Cross-platform deployment and online collaboration are things that obviously the web is great for. An author could, for example, upload a paper to Lemon8-XML, and work together with an editor on that same copy, regardless of what desktop tools they have. One advantage of this idea is that the burden of work is shared between more people, whether that's an author and a copyeditor, or multiple editors. This is a big deal for small journals who don't have funds for dedicated staff.\n\nWithin PKP in general, we also try to keep the requirements for our software as low as possible, both technically and financially. So, for journals like [Open Medicine](https://web.archive.org/web/20151003091211/http://www.openmedicine.ca/), who are entirely volunteer-run, paying \\$230 per copy for Microsoft Word on each computer actually represents a significant cost. Using OpenOffice on the desktop and a single copy of Lemon8-XML on a server --- both of which are free --- lets them spend this out-of-pocket expense on other things to keep their journal alive and growing. Microsoft Word also has an unfortunate history of being variable and inconsistent across platforms and versions. We wanted to help people escape that, which is one of the reasons for converting everything to OpenDocument as early as possible. In addition, stewarding documents through an online workflow can be a laborious and frustrating process, so the possibility for journals to make the editing process more centralized and interactive by integrating Lemon8-XML is a compelling one.\n\n### 3. How does Lemon8-XML compare to the Microsoft Word Article Authoring Add-In, that also produces NLM Journal Publishing DTD output? {#3-how-does-lemon8-xml-compare-to-the-microsoft-word-article-authoring-add-in-that-also-produces-nlm-journal-publishing-dtd-output}\n\nIn many ways, we're working in parallel with Pablo Fermicola's group at Microsoft --- [they're basically building an editor](https://web.archive.org/web/20151003091211/http://perspectives.on10.net/blogs/jonudell/Word-for-scientific-publishing/) for placing a structured NLM schema on top of the Microsoft WordML (DOCX) XML format, while Lemon8-XML places the NLM schema on top of the OpenDocument (ODT) XML format. Of course, there's nothing saying that Lemon8-XML couldn't be modified to read DOCX files generated with the Article Authoring Add-In or vice-versa. This difference is really a reflection of the two competing standards, and the tools they use, with the same ultimate goal: to allow users to generate semantically-structured documents from layout-based ones. In addition, the Article Authoring Add-In is built on Microsoft Word 2007 as a platform, which I think has some limitations; for example, most of the PKP team don't use Windows, so the Article Authoring Add-In is basically inaccessible to us. But overall, our goals appear to be very similar.\n\nTo my mind, the main difference between the projects is in how they approach the user: the Article Authoring Add-In presents new tools for adding semantic mark-up in a (somewhat) familiar interface; many authors are already familiar with Microsoft Word and are comfortable working in that environment. My concern with this approach is that it still has strong ties to the layout paradigm, so, for example, marking text as \"article title\" may not be sufficiently different in authors' minds from marking text as \"16 point bold\". I also think the idea of presenting an entire document in a single free-form editor reinforces the layout paradigm, as opposed to identifying the distinct elements which comprise a scholarly article. Lemon8-XML, on the other hand, builds from these individual elements, and assembles them within the user interface based on their structural relations. You can see this reflected in the tabs in the current interface: \"Metadata, Sections, Citations\" --- these are the front, body, back matter of an article.\n\nThis places restrictions on how a user can edit their article, which is sometimes frustrating, but it forces them to think about what they're doing and the meaning of their content: why do I have to place it here, what content is valid in this element, etc. In a future version, this will all be on the same web page, similar to how it would appear in Microsoft Word, but again with the semantic structure visually enforced instead of being totally free-form.\n\n### 4. What is the difference between Lemon8-XML and online word processors such as Google Docs? {#4-what-is-the-difference-between-lemon8-xml-and-online-word-processors-such-as-google-docs}\n\nUnlike most word processor software, Lemon8-XML is built around the semantic notion of a document, not its appearance. We wanted to help people begin to think about the meaning and structure of their articles, not just whether they look good on the screen or as a PDF. It turns out this is a tough challenge, though --- people have a hard time with WYSIWYM (What You See Is What You Mean) editors, and there's often a lot of complex structure to present visually for editing. One thing people seem to be comfortable with, or at least used to, is entering metadata and information in web forms, so much of the Lemon8-XML user interface is built that way.\n\nLemon8-XML is also specifically aimed at modeling and editing scholarly articles, which have a long history of practice and some very rigid conventions that aren't applicable more broadly. This means it's not a general-purpose editor like most word processors, but that also means we can focus on the specific things it should do, and refine them rather than trying to please everyone and falling victim to feature-creep.\n\n### 5. Why did you pick the NLM Journal Publishing DTD as document format? {#5-why-did-you-pick-the-nlm-journal-publishing-dtd-as-document-format}\n\nI did a survey in 2003 of available DTDs to represent scholarly journal articles, looking for something I could use as a common source for generating HTML and PDF. I selected the NLM DTD above the others (eg. BioMed Central, [DocBook](https://web.archive.org/web/20151003091211/http://www.docbook.org/whatis), [Erudit](https://web.archive.org/web/20151003091211/http://www.erudit.org/apropos/info.html), [Text Encoding Initiative](https://web.archive.org/web/20151003091211/http://www.tei-c.org/index.xml)) since it seemed to strike a good balance between comprehensiveness and granularity; it can be as simple or as complex as you need it to be. It also had a very thorough citation model and a modular design, so extensibility wasn't a concern --- I liked the \"journal articles plus\" concept that it was built with. And, of course, being stewarded by the National Library of Medicine meant it would likely be well-maintained and remain open. The fact that it became [the central XML standard for PubMed Central as an archival format](https://web.archive.org/web/20151003091211/http://www.pubmedcentral.nih.gov/about/faq.html#q21) was just icing on the cake.\n\nAnother reason is that, among the STM journals at least, a lot of established practice has developed around generating HTML and PDF from NLM XML specifically, and we want to support that. Actually, we want to expand adoption of the NLM DTD by making it accessible to humanities and social science journals, as well. The information contained in the XML is essentially identical regardless of subject, which means we just need to develop discipline-specific rendering; for example, for different citation styles. I think there's an incredible amount of room for growth and improvement in this area in particular.\n\n### 6. Does Lemon8-XML integrate with manuscript submission systems such as Open Journal Systems? {#6-does-lemon8-xml-integrate-with-manuscript-submission-systems-such-as-open-journal-systems}\n\nNot yet, but that's the next major area of development immediately following the 1.0 release. [OJS](https://web.archive.org/web/20151003091211/http://pkp.sfu.ca/?q=ojs) has been so successful, one of our biggest challenges has been keeping it flexible enough to support a wide range of workflows, and we want to continue with that by taking as much of the technology from Lemon8-XML as possible and folding it into OJS. I don't know if we'll see a side-by-side kind of integration immediately, but rather strategic enhancements of certain aspects of OJS: automatic document conversion, annotation directly within articles, extraction and stripping of metadata to improve blindedness, automatically parsing and linking citations, etc. By going this way, we give users the ability to choose specific features that are useful for them, and at the same time build upon the huge community that already exists for OJS in terms of development, testing, and feedback.\n\nThere's definitely still value in a stand-alone Lemon8-XML for cases where people don't want journal workflow, or where they're integrating with a different kind of system. So, we will be working on a Lemon8-XML 2.0 that's built on the same modular, reliable framework as the rest of the PKP suite, and back-porting code from OJS.\n\n### 7. What is the Public Knowledge Project? {#7-what-is-the-public-knowledge-project}\n\n[PKP](https://web.archive.org/web/20151003091211/http://pkp.sfu.ca/node/1410) is a small research group distributed between Simon Fraser University, University of British Columbia, Stanford University and Arizona State University that has been quietly [developing open source software for online publishing and knowledge sharing](https://web.archive.org/web/20151003091211/http://www.openmedicine.ca/article/view/276) for the past 10 years, under the direction of Dr. [John Willinsky](https://web.archive.org/web/20151003091211/http://ed.stanford.edu/suse/faculty/displayRecord.php?suid=willinsk) at Stanford. Our major aim is to provide tools for improving access to academic research, as well as helping improve the quality and efficiency of its production. Our philosophy is also to create partnerships between researchers, librarians, publishers, to help them build sustainable and globally accessible scholarly infrastructure. In my mind, it's also about giving people options and choices aside from what's being offered commercially, especially to those who can't afford them, like a lot of developing-world journals.\n\nWe have four applications in addition to Lemon8-XML: [Open Journal Systems](https://web.archive.org/web/20151003091211/http://pkp.sfu.ca/?q=ojs), our most popular, is being used by over 2500 journals in over 50 countries. We also produce a conference management system ([Open Conference Systems](https://web.archive.org/web/20151003091211/http://pkp.sfu.ca/?q=ocs)), an OAI metadata indexing system ([Open Archives Harvester](https://web.archive.org/web/20151003091211/http://pkp.sfu.ca/?q=harvester)), and a monograph publishing system ([Open Monograph Press](https://web.archive.org/web/20151003091211/http://pkp.sfu.ca/omp)), currently under development. All of our software is freely available under the GPL open source license, and we have an active community of over 1500 users. We've worked with small, volunteer-run humanities journals, to major international society conferences, to high-profile, ISI-ranked medical journals.\n\n### 8. What are your responsibilities within the Lemon8-XML project? {#8-what-are-your-responsibilities-within-the-lemon8-xml-project}\n\nBecause our group's so small, we all share responsibilities --- there are only a handful of people to do almost all of the development, and that's in addition to handling the support, correspondence, and software maintenance of the rest of the PKP suite, not to mention providing various international workshops. So, we often divvy roles based on expertise or interest. Since bringing Lemon8-XML to PKP, I do the vast majority of Lemon8-XML development, but I also manage collaborations with our development and research partners, and write white papers on the software design we use to share our ideas, on top of contributing to the daily stuff above.\n\nProbably the biggest struggle in developing Lemon8-XML has been that it's one person, about half-time, doing all of the coding, testing, etc. We already have a number of very exciting partnerships with groups who will be testing and providing feedback, and have contributed a talented developer who's recently started half-time as well. Of course, we can always use more help with the coding side of things. Our team is quite spread-out geographically, so we have a lot of experience with working across time zones and with distributed development practices. I'm hoping that after the 1.0 release, more people will become interested and will want to help get involved. Whether contributing plugins for citation processing, or helping us improve the UI --- really, anything that helps the software grow will benefit more authors and editors, which is the main goal.\n\n### 9. What did you do before starting to work on Lemon8-XML? {#9-what-did-you-do-before-starting-to-work-on-lemon8-xml}\n\nI worked for a two-person medical informatics journal that was publishing around 50 articles a year using Microsoft FrontPage and managed entirely via email. My job was to transition it to an online manuscript management system (naturally, I chose OJS), convert around 300 back articles from FrontPage HTML into valid NLM XML, develop a custom rendering system that would create HTML and PDF galleys from that XML, get the journal accepted into PubMed Central, and establish an impact factor from ISI (which is now 3.0) --- oh, and continue publishing 50 articles a year. The journal also ran an international medical conference during that time (using OCS). Three years later, I left to do my Masters degree in Library/Information Studies, during which time I joined PKP and started working on Lemon8-XML, based on a lot of the things I'd learned from my time at the journal.\n\n### 10. Do you want to talk about future plans for Lemon8-XML? {#10-do-you-want-to-talk-about-future-plans-for-lemon8-xml}\n\nThe most common question I'm asked is, \"when will it be ready?\", which for many people really means, \"when will it be a one-click magic bullet for getting my journal into PubMed Central?\". I'm proud of the Lemon8-XML 1.0 release, and I feel that it represents a significant milestone given how far we've come --- but there's still a long way to go before we get to that point. I hope people will view the 1.0 version as a stable tool that's already being used in production by at least one journal, and a strong indicator of PKP's commitment to developing research and software in this area.\n\nI mentioned the Open Journal Systems integration, which is both a strategic and pragmatic move; this will be our main focus, as well as integration with OMP from its earliest inception. We also want to improve the editing aspect of Lemon8-XML --- there is some great work being done in the area of using style templates for providing structural mark-up in traditional word processors; we will be working more closely with Peter Sefton's group on the ICE project, who have a lot of experience. I'd also like to re-visit the idea of using web-based WYSIWYM editors like [WYMeditor](https://web.archive.org/web/20151003091211/http://www.wymeditor.org/) or an enhanced [TinyMCE](https://web.archive.org/web/20151003091211/http://tinymce.moxiecode.com/) as part of a user interface overhaul, and possibly integrating more closely with Google Docs if that's an option. Certainly, there's room for adding more citation lookup plugins: [OAIster](https://web.archive.org/web/20151003091211/http://www.oaister.org/about.html), Amazon.com, [CiteSeer](https://web.archive.org/web/20151003091211/http://citeseer.ist.psu.edu/citeseer.html), etc. as well as improving the existing ones. Finally, we want to try applying the approach we've used with citation parsing and lookup with other scholarly article elements; for example, checking quotations for correctness and plagiarism, extracting and linking author/contributor identifiers, and so on. We also have some ideas around [OpenURL](https://web.archive.org/web/20151003091211/http://www.dlib.org/dlib/may06/apps/05apps.html) that may or may not come into Lemon8-XML development.\n\nWe're also starting a major side-project based entirely around the NLM DTD in two parts: 1) building mappings from various other XML schemas to NLM; and 2) building a standard set of rendering tools for generating HTML and PDF from NLM XML, in a way that can be easily customized for an individual journal. There are already a lot of groups out there using NLM but currently the practice is quite fragmented --- we'd like to see these journals and publishers become more connected and share their work as a community. As I say, we want to help increase adoption as a way to raise the bar on journal quality and improve options for publishing and archiving.\n\nOne of the most important things we've learned during the development of Lemon8-XML has been the value of user feedback early and often, and remaining aware of related work that's going on, so we can remain efficient by building partnerships instead of working in parallel. We'll continue pursuing this approach, and I'd encourage anyone who is interested in any of these areas or has ideas of their own to contribute to [get in touch with us](https://web.archive.org/web/20151003091211/http://pkp.sfu.ca/contact).\n","doi":"https://doi.org/10.53731/ew3e999-93v00dz","guid":"62d42bbd41e317003df48ddf","id":"cccdd6ee-cc7c-4f6f-b69c-0c26fd0c629e","image":"https://blog.front-matter.io/content/images/2022/08/2276034665_456342fb50_c.jpg","indexed_at":1,"language":"en","published_at":1235692800,"reference":[],"relationships":[],"summary":"Finishing an exciting research project and writing it up in a paper are the first two steps in getting your work published. The next two steps \u2013 submitting your paper to a journal and getting it through the review process \u2013 have changed dramatically in the last 10-15 years.\n","tags":["Interview"],"title":"Lemon8-XML: Interview with MJ Suhonos","updated_at":1660722116,"url":"https://blog.front-matter.io/posts/lemon8-xml-interview-with-mj-suhonos"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/reference-manager-overview","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"**18 April 2009: I\\'ve updated the chart and added 2collab, the \"Read\" category, sharing of PDF files, and the Mendeley bookmarklet and full-text search.**\n\n**15 July 2009: I\\'ve updated the chart to indicate that Mendeley and* L*abmeeting have integrated PDF viewers and that 2collab can search Scopus.**\n\n**20 July 2009: I\\'ve added the offline version of RefWorks for Windows, EndNote OpenOffice plugin, and full-text search in several tools.**\n\n**22 February 2010: Many small changes, including a few more categories. Added Citavi and dropped 2collab, LabMeeting*, *and Connotea.**\n\n**6 August 2010: Added Mendeley API and iPhone app, EndNote X4 features.**\n\n**19 September 2010: Moved chart to [different location](https://web.archive.org/web/20150905233309/http://blogs.plos.org/mfenner/reference-manager-overview/), PDF download, Creative Commons license.**\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw42","guid":"62d42bbd41e317003df48ddd","id":"01b0e58d-17e8-4ae1-9c40-f569f3633f54","image":"https://blog.front-matter.io/content/images/2022/08/Reference-Manager-Overview.jpg","indexed_at":1,"language":"en","published_at":1237075200,"reference":[],"relationships":[],"summary":"<em>\n <em>\n  18 April 2009: I've updated the chart and added 2collab, the \u201cRead\u201d category, sharing of PDF files, and the Mendeley bookmarklet and full-text search.\n </em>\n</em>\n<em>\n <em>\n  15 July 2009: I've updated the chart to indicate that Mendeley and\n </em>\n L\n <em>\n  abmeeting have integrated PDF viewers and that 2collab can search Scopus.\n </em>\n</em>\n<em>\n <em>\n  20 July 2009: I've added the offline version of RefWorks for Windows, EndNote OpenOffice plugin, and\n </em>\n</em>\n","tags":["Feature"],"title":"Reference Manager Overview","updated_at":1660721984,"url":"https://blog.front-matter.io/posts/reference-manager-overview"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/word-processor-support-in-citation-managers-is-there-a-better-way","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"Citations of the relevant literature are an essential feature of scientific papers. Reference Manager software helps adding these citations and creating a bibliography. Are there differences in how reference managers work together with your word processor of choice?\n\n### Support for your favorite word processor\n\nSupport for word processors other than Microsoft Word is spotty. The [Mendeley plugin](https://web.archive.org/web/20150906104449/http://www.mendeley.com/download_client) is only a few months old, and the latest Zotero release (1.5b) [broke the plugin for Word 2004](https://web.archive.org/web/20150906104449/http://www.zotero.org/support/word_processor_integration). I expect the Word for Macintosh support of both these tools to become better over time. Google Docs doesn\\'t have any reference manager integration. This greatly limits its usefulness for writing scientific papers. The RefWorks plugin connects to an online database, so you can\\'t add or edit references without an internet connection.\n\nMost word processor plugins add an extra menu that allows to add and edit citations (allowing the user to search the reference manager database), and to add and edit bibliographies (allowing the user to pick a citation style, see below). Most reference managers also allow scanning for reference tags in documents produced by other word processors (e.g. in the .rtf format), but that process requires a few extra steps.\n\n### Support for your favorite journal\n\nI think it is very unfortunate that paper authors have to deal with a large number of different citation styles. All that we really need for paper references is the DOI (e.g. [doi:10.1038/455708a](https://web.archive.org/web/20150906104449/http://dx.doi.org/10.1038/455708a)) to make the reference automatically identifiable and some basic information (authors, title, journal, year, issue) to make the reference readable. But it is beyond my understanding why anybody would care about formatting details such as whether the pulication year appears before or after the journal name. There have been initiatives to standardize the formatting of references (e.g. [Citing Medicine](https://web.archive.org/web/20150906104449/http://www.nlm.nih.gov/citingmedicine/)), but for now paper authors have to format their bibliographies in the style required by the journal. Citation styles are an important asset for those that write reference manager software. Many people will recall that Thomson Reuters (who makes Endnote) [sued](https://web.archive.org/web/20150906104449/http://www.nature.com/nature/journal/v455/n7214/full/455708a.html) George Mason University (who makes Zotero) last year, because Zotero added a feature that could convert Endnote .ens citation style files into [Citation Style Language](https://web.archive.org/web/20150906104449/http://xbiblio.sourceforge.net/csl/) .csl files. Mendeley is also using .csl for citation styles.\n\n### Is there a better way?\n\nWord processor plugins are fragile and usually break when a new software version is released (see for example [this chart](https://web.archive.org/web/20150906104449/http://www.endnote.com/support/en_wpchart_mac.asp) for Endnote and Word for Macintosh). Native word processor support for references allows a much tighter integration into the word processor interface. Lastly, documents produced by different reference managers are not interchangeable, as each plugin uses a slightly different formatting approach. This means you can\\'t write on a paper using Endnote and send it to your coauthor who uses Zotero.\n\nThe latest versions of Microsoft Word (2007 and 2008 Macintosh) have [built-In support for citations and bibliographies](https://web.archive.org/web/20150906104449/http://blogs.msdn.com/joe_friend/archive/2006/07/13/664960.aspx), but this feature is severely limited for the requirements of academic papers. Only a handful of citation styles are supported, adding more styles is possible but requires [some serious skills in XML editing](https://web.archive.org/web/20150906104449/http://blogs.msdn.com/microsoft_office_word/archive/2007/12/14/bibliography-citations-1011.aspx). References are stored in one flat file ([Sources.xml](https://web.archive.org/web/20150906104449/https://www.uwec.edu/help/Word07/bib-srcfile.htm)) and can\\'t be searched. OpenOffice is also struggling with built-in [bibliographic support](https://web.archive.org/web/20150906104449/http://bibliographic.openoffice.org/).\n\nLaTex has long included support for references using [BibTex](https://web.archive.org/web/20150906104449/http://www.bibtex.org/About) and shows how citation support should be done. Tools like [JabRef](https://web.archive.org/web/20150906104449/http://jabref.sourceforge.net/) or [BibDesk](https://web.archive.org/web/20150906104449/http://bibdesk.sourceforge.net/) extend this functionality, and most reference managers will import/export bibtex files.\n\nBoth Microsoft Word and OpenOffice should open up their citation APIs to third-party tools. This would create better citation tools, allows the easier exchange of documents between authors (journal submissions), and would it make easier for smaller tools such as Papers to integrate with word processors (a workaround is described [here](https://web.archive.org/web/20150906104449/http://vnoel.wordpress.com/2008/02/14/papers-word-2008-bibliography-heaven/)). If they wait too long, we will probably see the online word processors such as Google Docs, Zoho Writer start adding an API for citations and bibliographies and all of the sudden become very serious alternatives for writing scientific papers. [Lemon8-XML](https://web.archive.org/web/20150906104449/http://network.nature.com/people/mfenner/blog/2009/02/27/lemon8-xml-interview-with-mj-suhonos) already has very good bibliography support.\n\n**P.S. Bruce D\\'Arcus has recently come to similar conclusions ([The Babel of Citations](https://web.archive.org/web/20150906104449/http://community.muohio.edu/blogs/darcusb/archives/2009/03/01/the-babel-of-citations)).**\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw41","guid":"62d42bbd41e317003df48ddc","id":"ba603d91-7498-43c5-8e85-7d307f1d16ed","image":"https://blog.front-matter.io/content/images/2022/08/3371450153_62cbe77494.jpeg","indexed_at":1,"language":"en","published_at":1237593600,"reference":[],"relationships":[],"summary":"Citations of the relevant literature are an essential feature of scientific papers. Reference Manager software helps adding these citations and creating a bibliography. Are there differences in how reference managers work together with your word processor of choice?Support for your favorite word processor  Support for word processors other than Microsoft Word is spotty.\n","tags":["Feature"],"title":"Word processor support in citation managers: Is there a better way?","updated_at":1660721722,"url":"https://blog.front-matter.io/posts/word-processor-support-in-citation-managers-is-there-a-better-way"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/faculty-of-1000-interview-with-richard-grant","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"[Richard Grant](https://web.archive.org/web/20151003075116/http://network.nature.com/people/rpg/blog), who needs no introduction here on Nature Network, has just moved to London [to start a new job](https://web.archive.org/web/20151003075116/http://network.nature.com/people/rpg/blog/2009/04/09/on-the-payroll) as **information architect** for [Faculty of 1000](https://web.archive.org/web/20151003075116/http://www.f1000biology.com/). I took this opportunity to ask Richard a few questions not only about Faculty of 1000, but also about his role in the company and future plans for the service that they have in mind.\n\n### 1. Can you describe what Faculty of 1000 is and does? {#1-can-you-describe-what-faculty-of-1000-is-and-does}\n\nThe scientific literature is immense, and growing. It has become very difficult to keep up, especially if you're going to keep an eye on developments not immediately in your own area. For someone new to a field it's almost impossible to know --- without insider knowledge --- what papers are important, which are the key publications; where a field is going and what are the key developments.\n\nSo what we do is provide a kind of 'filter' on top of the literature: we have about five thousand principle investigators, who we call 'Faculty', across biology and medicine, who in the course of their own reading will write short evaluations on the important and influential papers in their field. We're also recruiting [Associate Faculty members](https://web.archive.org/web/20151003075116/http://www.f1000biology.com/about/associateFMs): trusted junior members of a Faculty member's lab or practice who will write their own evaluations and increase our coverage. And we're not just talking about stuff that's published in **Nature** or **Cell** --- or **NEJM** or **The Lancet** --- but in the specialized, work-a-day journals. What's more, this expert opinion, or what we're calling 'post-publication peer review', gives our users a measure of the 'quality' of individual papers that is independent of, and much quicker than, the impact factor of the journal.\n\n### 2. What part of Faculty of 1000 is free and what part needs a paid subscription {#2-what-part-of-faculty-of-1000-is-free-and-what-part-needs-a-paid-subscription}\n\nYou can search or browse the entire database, and sign up for email alerts, so you can see which papers have been evaluated. You can't actually read the evaluations themselves unless you have an institutional or personal subscription.\n\n### 3. How does Faculty of 1000 integrate with reference managers such as Endnote, Refworks, Zotero or Connotea? {#3-how-does-faculty-of-1000-integrate-with-reference-managers-such-as-endnote-refworks-zotero-or-connotea}\n\nYou can download evaluations into a reference manager just like you can papers from PubMed. We're working on proper integration with online tools (such as [CiteULike](https://web.archive.org/web/20151003075116/http://www.citeulike.org/) and [Connotea](https://web.archive.org/web/20151003075116/http://www.connotea.org/)) and other 'social media' tools. I'm also keen to work with [Mendeley](https://web.archive.org/web/20151003075116/http://www.mendeley.com/) to improve the user experience.\n\n### 4. What are the incentives for faculty members to evaluate papers? {#4-what-are-the-incentives-for-faculty-members-to-evaluate-papers}\n\nExposure and kudos, mainly! The Faculty member's name is displayed prominently on the evaluations (you can see who's written an evaluation even without a subscription). Reputation is important to scientists and being invited to become a Faculty member says to the rest of the community that your opinion is respected and your peers think highly of you. We also profile Faculty members who write timely or important evaluations, or who have news of their own (grants, papers, awards) and give them publicity through press releases, etc.\n\nWhat's more, our Faculty members **like** the combination of expert opinion and original articles. They see a value in it, and realize that there's a kind of synergy going on here; if they contribute then others will be encouraged to too, and everybody wins.\n\nI'd like to explore how evaluations might become citable --- so that Faculty can put their work for us on their CV, how it might benefit their career, grant applications etc. We're also considering more tangible benefits.\n\n### 5. How are faculty members selected? {#5-how-are-faculty-members-selected}\n\nThe Heads of Faculty, for each subject or speciality, are elected or selected on the recommendation of large numbers of medics and scientists we talk to. They divide their Faculty into Sections and then select two or three Section Heads. These scientists in turn identify the sub-fields within their Section and select Faculty Members, checking with Heads of Faculty. The Section Heads select Faculty Members on the basis of various criteria:\n\n-   the number of Faculty Members should be proportionally representative of the number of papers published within that field;\n-   the selected Faculty Members should be well respected by their peers and perceived as being fair-minded;\n-   there must be a good representation of genders, nationalities and age/seniority.\n\nFaculty Members themselves are being asked to co-opt younger workers within their groups --- post-docs, say --- to help increase coverage and to write their own evaluations. We call these 'Associate Faculty'.\n\n### 6. Can Faculty of 1000 users comment on papers or paper evaluations? {#6-can-faculty-of-1000-users-comment-on-papers-or-paper-evaluations}\n\nNot at the moment, no. Faculty members can comment, or contribute a 'dissent' if they disagree with an evaluation, and authors of the evaluated papers are encouraged to respond, but we feel it's important for users to know that they can trust what we publish. However, we're currently planning to launch a forum whereby users **can** comment freely on evaluated papers. This would be open to anyone who registers, without a subscription, but kept distinct from the main evaluation.\n\n### 7. Can paper authors comment on evaluations of their papers? {#7-can-paper-authors-comment-on-evaluations-of-their-papers}\n\nYes! At the moment we get emails from authors saying that they're pleased to have their papers selected, but we're going to make it possible for them to comment on the evaluations directly so that a conversation with the Faculty can be initiated.\n\n### 8. What is Faculty of 1000 Reports? {#8-what-is-faculty-of-1000-reports}\n\nF1000 Reports carries short reviews, or commentaries, on emerging trends identified from within the F1000 database. [F1000 Medicine Reports](https://web.archive.org/web/20151003075116/http://f1000medicine.com/reports/) features studies that are likely to change clinical practice and summarizes implications for clinicians. [F1000 Biology Reports](https://web.archive.org/web/20151003075116/http://www.f1000biology.com/reports/) contextualizes important and exciting papers or clusters of publications. The Advisory Board (for [F1000 Biology Reports](https://web.archive.org/web/20151003075116/http://f1000biology.com/reports/advisoryboard) and [F1000 Medicine Reports](https://web.archive.org/web/20151003075116/http://f1000medicine.com/reports/advisoryboard)) identifies potential topics and invites appropriate Faculty members to write about them.\n\n### 9. What are your responsibilities at Faculty of 1000? {#9-what-are-your-responsibilities-at-faculty-of-1000}\n\nWell, my job title is 'Information Architect', which means quite a bit more than 'web manager'. I have overall responsibility for the presentation of the F1000 service, and I have to ensure that the web site is fast and intuitive, and that the content is suitable for both medics and biologists. I'm also keen to keep F1000 relevant in the Web 2.0 world.\n\n### 10. What did you do before starting to work for Faculty of 1000? {#10-what-did-you-do-before-starting-to-work-for-faculty-of-1000}\n\nI was at the University of Sydney for three years, the token cell biologist in an NMR lab, looking at RNA-binding zinc fingers. Before that I was at the MRC-LMB in Cambridge for six years, learning how to do X-ray crystallography and NMR and applying those techniques to cell biological questions.\n\n### 11. Do you want to talk about future plans for Faculty of 1000? {#11-do-you-want-to-talk-about-future-plans-for-faculty-of-1000}\n\nAs I've sorted of already hinted, we're in the middle of a major redesign. We have some new features that I hope you'll find very exciting --- one of which I really can't talk about yet! --- including forums, a re-vamped 'MyF1000\u2032 site, integration of F1000 Reports, more systematic literature scanning, talking to social media sites, RSS (at last!), a blog, and a lot of behind the scenes tweaks.\n\n### 12. Where can we provide feedback about Faculty of 1000? {#12-where-can-we-provide-feedback-about-faculty-of-1000}\n\nWrite to me! Or email info@f1000.com. The new site will also have a feedback form.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw3v","guid":"62d42bbd41e317003df48dd6","id":"011d22c5-719d-473c-b096-8f825e26eed1","image":"https://blog.front-matter.io/content/images/2022/08/f353fdfe5c24bfb525680563a4a5c04b3760fafd.jpeg","indexed_at":1,"language":"en","published_at":1240876800,"reference":[],"relationships":[],"summary":"Richard Grant, who needs no introduction here on Nature Network, has just moved to London to start a new job as\n<em>\n <em>\n  information architect\n </em>\n</em>\nfor Faculty of 1000. I took this opportunity to ask Richard a few questions not only about Faculty of 1000, but also about his role in the company and future plans for the service that they have in mind.1. Can you describe what Faculty of 1000 is and does?\n","tags":["Interview"],"title":"Faculty of 1000: Interview with Richard Grant","updated_at":1660721636,"url":"https://blog.front-matter.io/posts/faculty-of-1000-interview-with-richard-grant"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/conference-blogging-interview-with-alex-knoll","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"Blogging is [a great way to report from a scientific conference](https://web.archive.org/web/20120611105344/http://www.nature.com/news/2009/090624/full/4591050a.html). This could be done either with regular blog posts written in the evening or after the conference, and/or live-blogging using tools such as Friendfeed or Twitter. One or more blogging scientists can not only add a unique perspective to the reports about a conference, but for smaller conferences blogging might be the only way to learn more about a conference you were unable to attend in person.\n\nConference blogging (particularly live-blogging) basically requires four things:\n\n-   a wireless network,\n-   a computer or mobile phone with a full battery,\n-   a hashtag (and other tools to find the conference blog posts), and\n-   a blogging policy by the conference organizers.\n\nWireless networks are now commonplace, but enough battery power (or power outlets that conference participants can use) can be difficult. A hashtag such as **#solo09** for [Science Online London](https://web.archive.org/web/20120611105344/http://www.scienceonlinelondon.org/) is essential for live-blogging using Twitter.\n\nThe big problem is the blogging policy, or rather that there usually is a policy only for traditional media, but not for blogging. The blogging from the Cold Spring Harbor **Biology of Genomes** meeting in May by Daniel MacArthur [started a very helpful discussion about blogging policies](https://web.archive.org/web/20120611105344/http://scienceblogs.com/geneticfuture/2009/06/on_the_challenges_of_conferenc.php). It is impossible to write anything specific about a conference -- and that\\'s the stuff that is most interesting -- without a permission from the conference organizer and speaker. This is best done before the conference has started. A July **Nature** [editorial](https://web.archive.org/web/20120611105344/http://www.nature.com/nature/journal/v460/n7252/full/460152a.html) argues that an opt-out policy, where everything can be blogged about unless the speaker or poster presenter specifically says so, is a reasonable alternative.\n\nThe organizers of the [Annual Meeting of the German Genetics Society](https://web.archive.org/web/20120611105344/http://www.genetics2009.de/) that took place two weeks ago in Cologne did this right. Not only did they invite [Alex Knoll](https://web.archive.org/web/20120611105344/http://network.nature.com/people/alexander-knoll/profile) to become the official conference blogger, but they also put up a prominent link to his blog posts on the conference homepage, and they asked every speaker before the conference whether Alex would be allowed to blog about their talks. Because his blog on scienceblogs.de ([Alles was lebt](https://web.archive.org/web/20120611105344/http://www.scienceblogs.de/alles-was-lebt)) is in German, he decided to put up his blog posts here. I\\'ve asked him a few questions about this experience.\n\n### 1. Did you have fun being the official blogger for the [German Genetics Society Meeting](https://web.archive.org/web/20120611105344/http://www.genetics2009.de/)? {#1-did-you-have-fun-being-the-official-blogger-for-the-german-genetics-society-meeting}\n\nThis conference blogging job was a first for me in many ways. I usually blog in German, so I wasn\\'t sure if I would be able to bring more than my dry, scientific English. I also knew beforehand that there would be no theme, that the meeting was a general one. I would have at least to give the impression of having understood the basics of the talks. There would be no flitting about from talk to talk, I wanted to get whole sessions without interruption.\n\nBut on the other hand, I also got to know lots of people, many more than I would have as a lowly PhD student. I attended a conference I almost certainly would not have without the invitation to come and blog.\n\nAnd, as any other (science)blogger will tell you, blogging is a labour of love (don\\'t stab me in the back now!). So yes, I had a great time!\n\n### 2. Blogging about the conference must have been a lot of work! {#2-blogging-about-the-conference-must-have-been-a-lot-of-work-}\n\nAbout as much as I expected. I was frantically typing away at my little netbook keyboard during the talks to take notes, and used any spare time to put together the posts. So I did not have as easy a time as regular conference attendees. No problem, I came to do a job!\n\n### 3. Did you meet any other science bloggers at the conference? {#3-did-you-meet-any-other-science-bloggers-at-the-conference}\n\nAs far as I\\'m aware, I was the only blogger attending, and also the only one tweeting from the sessions (no worries, no unpublished data got out that route).\n\n### 4. What was the feedback from the speakers? What was your experience getting permissions from speakers to blog about their sessions? {#4-what-was-the-feedback-from-the-speakers-what-was-your-experience-getting-permissions-from-speakers-to-blog-about-their-sessions}\n\nI got the whole range. From the really open \"Go ahead! Write what you want, put it online. I\\'ll talk about some unpublished stuff as well, but I don\\'t mind\" to some who are not interested in getting their work out into a blog at all. Great news for the conference blogging crowd: the balance was tipped more to the pro side! Most of the speakers came out somewhere in between those two sides, probably being a bit cautious about that whole strange blogging stuff. But I got mostly positive feedback from them, and I believe the next blogger will have an easier time when blogging about their talks!\n\n### 5. What tips would you give a conference organizer who wants to promote blogging? {#5-what-tips-would-you-give-a-conference-organizer-who-wants-to-promote-blogging}\n\nThey should make clear from the start if blogging about the talks is generally OK. That doesn\\'t mean all of the speakers have to allow blogging about their talk, but an official position will help everyone involved. You also don\\'t need to have an **official** blogger, but especially at smaller meetings asking someone to blog beforehand is probably the only chance to get a blogger there at all.\n\nI also have advice for speakers: Start your talk by telling your audience if blogging about it is OK! If a part of your talk is unpublished, tell them that as well. Or put an icon on your slides to indicate which is good to blog about, for example as Daniel MacArthur from the Genetic Future blog [has proposed](https://web.archive.org/web/20120611105344/http://scienceblogs.com/geneticfuture/2009/07/conference_blogging_icons_for.php). If bloggers know beforehand if and what part of the talk is good to go, they will be more willing to take notes in earnest!\n\nNow that my guest posting here at Martin\\'s blog comes to an end, I would like to leave you with one of the last impressions, a rather lucky shot of Cologne Cathedral I took while leaving. Many thanks to Martin for hosting this conference blog!\n\n<figure class=\"kg-card kg-image-card\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/3969315341_4f8c590711.jpg\" class=\"kg-image\" loading=\"lazy\" width=\"500\" height=\"375\" />\n</figure>\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw39","guid":"62d42bbd41e317003df48dc4","id":"0751175e-f5c6-483f-a162-407e995098be","image":"https://blog.front-matter.io/content/images/2022/08/knoll.jpeg","indexed_at":1,"language":"en","published_at":1254355200,"reference":[],"relationships":[],"summary":"Blogging is a great way to report from a scientific conference. This could be done either with regular blog posts written in the evening or after the conference, and/or live-blogging using tools such as Friendfeed or Twitter.\n","tags":["Meeting Report","Interview"],"title":"Conference Blogging: Interview with Alex Knoll","updated_at":1660721456,"url":"https://blog.front-matter.io/posts/conference-blogging-interview-with-alex-knoll"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/uk-pubmed-central-interview-with-phil-vaughan","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"[PubMed Central](https://web.archive.org/web/20120611110953/http://www.ncbi.nlm.nih.gov/pmc/) was launched in February 2000 by the U.S. National Institutes of Health (NIH) as a free digital archive of journal articles. Just as PubMed, PubMed Central covers research in the life sciences, but not other areas of research, e.g. engineering, physical sciences or astronomy.\n\nSome journal articles are available as full text as soon as they are published, and most journals provide free access to full text articles within a year of publication. Some journals only provide the full text of some articles, including research funded by the NIH under the [NIH Public Access Policy](https://web.archive.org/web/20120611110953/http://publicaccess.nih.gov/policy.htm). The majority of fulltext articles in PubMed Central are not Open Access, but are protected by copyright. These articles are often made available under a license that allows redistribution and reuse.\n\nAll articles are deposited using the [NLM-DTD](https://web.archive.org/web/20120611110953/http://dtd.nlm.nih.gov/) XML format, which is a standard text format suitable for text mining and long-term archiving. Most articles are deposited directly by the journals, so that authors do not have to get involved in the technical aspects of article deposition.\n\nPubMed Central is a centralized archive of full text papers and not simply an interface to search these articles at the websites of the participating journals. Neither is PubMed Central an interface to search the various institutional repositories at universities and institutions. The NIH thinks that this centralized approach makes it easier to develop additional functionality, including the integration with other databases (e.g. the protein or nucleotide databases) hosted at the NIH.\n\nUK PubMed Central was launched in 2007 as the first PubMed Central outside the United States ([PubMed Central Canada](https://web.archive.org/web/20120611110953/http://pubmedcentralcanada.ca/), the second international PubMed Central, launched this week). In January 2010 UK PubMed Central will launch a number of new services, and I used the opportunity to ask UK PubMed Central Programme Manager Philip Vaughan a few questions.\n\n### 1. What is UK PubMed Central? {#1-what-is-uk-pubmed-central}\n\n[UK PubMed Central](https://web.archive.org/web/20120611110953/http://ukpmc.ac.uk/) offers free access to 1.6 million full-text journal articles in the fields of Life Sciences, Biomedicine and Health. Our content is free to read, print off and download. There is no registration process required: users can simply visit our site and start searching!It has been developed in consultation with the UK biomedical and health research community, and is about to launch some exciting new services in January 2010. Usage of our service has been growing steadily; we average 300,000 downloads a month currently.\n\n### 2. Why do we need more than one PubMed Central, and how are they connected {#2-why-do-we-need-more-than-one-pubmed-central-and-how-are-they-connected}\n\nUKPMC gives the UK research community access to all the content of [PMC](https://web.archive.org/web/20120611110953/http://www.ncbi.nlm.nih.gov/pmc/), but with added value specifically for the UK. For example, it offers Grant Reporting features, whereby users can search for current grants from all of our 8 Funders, can link the publications they produce to the grants they originated from, and view the impact of their work through access to citations. UK researchers can also [deposit their manuscripts directly](https://web.archive.org/web/20120611110953/https://ukmss.mimas.ac.uk/ukmss) into UKPMC.We will also be accessing additional content not in PMC; around 475,000 extra articles, reviews, guidelines and theses. Through the involvement of our funders, we are capturing around 90% of recently published journal articles from biomedical research conducted in the UK.We are therefore increasing the visibility of UK research in the field.\n\nOur colleagues at NCBI in the US have been very supportive of our activities: they have been keen for the PMC \"project\" to expand beyond the US. A Canadian version ([PMC Canada](https://web.archive.org/web/20120611110953/http://pubmedcentralcanada.ca/)) launched this week.\n\n### 3. Why does a search use PubMed Central and not the UK version? {#3-why-does-a-search-use-pubmed-central-and-not-the-uk-version}\n\nThe current UKPMC site searches PMC as it \"mirrors\" its content. But this about to change; from January UKPMC will be a \"stand alone\" service with its own up to date archive of content, as well as access to all the content of PubMed and PubMed Central.\n\n### 4. What is the relationship between UK PubMed Central and institutional repositories? {#4-what-is-the-relationship-between-uk-pubmed-central-and-institutional-repositories}\n\nUKPMC is a subject repository and as such receives content from researchers at Higher Education institutions across the UK. Deposition in UKPMC is mandatory if a researcher has a grant from any of our 8 Funders: [Wellcome Trust](https://web.archive.org/web/20120611110953/http://www.wellcome.ac.uk/), [Cancer Research UK](https://web.archive.org/web/20120611110953/http://www.cancerresearchuk.org/), [Medical Research Council](https://web.archive.org/web/20120611110953/http://www.mrc.ac.uk/), [British Heart Foundation](https://web.archive.org/web/20120611110953/http://www.bhf.org.uk/), [Arthritis Research Campaign](https://web.archive.org/web/20120611110953/http://www.arc.org.uk/), [Biotechnology and Biosciences Research Council](https://web.archive.org/web/20120611110953/http://www.bbsrc.ac.uk/), [National Institute for Health Research](https://web.archive.org/web/20120611110953/http://www.nihr.ac.uk/) and the [Chief Scientists Office](https://web.archive.org/web/20120611110953/http://www.sehd.scot.nhs.uk/cso/). Consequently we do not need to harvest content from other repositories. However, institutional repositories are welcome to harvest our content; we have an OAI-PMH interface to enable this. On the other hand, there are no plans to develop of institutional repositories from within UK PubMed Central.\n\n### 5. What is the material that can\\'t be put into UK PubMed Central? {#5-what-is-the-material-that-can-t-be-put-into-uk-pubmed-central}\n\nIf the material is not peer-reviewed research published in a recognized journal by a known publisher, it would not be deposited into UK PubMed Central. One aspect of our development programme has been to identify what further content we could provide links to, for example published research theses and NHS clinical guidelines. But, we have rigid quality control procedures in place even to provide links to material. That said, we do remain open minded, in terms of what material we may consider linking to in the future. And who knows what might arise in the future. For example, there does seem to be an appetite to include images.\n\n### 6. Can I submit my accepted manuscript if it was not funded by one of the UK PubMed Central funders? {#6-can-i-submit-my-accepted-manuscript-if-it-was-not-funded-by-one-of-the-uk-pubmed-central-funders}\n\nUnfortunately not at this time. We are hopeful that other UK research councils and funders of life sciences research will come on board in due course. The more funders that come on board, the stronger our service will become and the stronger our message on the importance of OA.\n\n### 7. What is the UK PubMed Central OAI service? {#7-what-is-the-uk-pubmed-central-oai-service}\n\nThe UK PubMed Central OAI service, ([UKPMC-OAI](https://web.archive.org/web/20120611110953/http://ukpmc.ac.uk/ppmc-localhtml/oai_service.html)) provides access to metadata of all items in the UKPMC archive, as well as to the full text of a subset of these items.\n\n### 8. What are your responsibilities at UK PubMed Central? {#8-what-are-your-responsibilities-at-uk-pubmed-central}\n\nI am the Programme Manager. I am responsible for the current service which has been in existence since January 2007. I also co-ordinate all our current development activities, which are undertaken by ourselves at the [British Library](https://web.archive.org/web/20120611110953/http://www.bl.uk/), by the University of Manchester ([MIMAS](https://web.archive.org/web/20120611110953/http://mimas.ac.uk/)), the National Centre for Text Mining ([NacTEM](https://web.archive.org/web/20120611110953/http://www.nactem.ac.uk/) -- based at the University of Manchester) and the European Bioinformatics Institute ([EBI](https://web.archive.org/web/20120611110953/http://www.ebi.ac.uk/)) based at Hinxton in Cambridgeshire.\n\n### 9. What did you do before starting to work on UK PubMed Central? {#9-what-did-you-do-before-starting-to-work-on-uk-pubmed-central}\n\nI originally trained as a librarian. Since then I have worked mainly in health and medical information work, both in Higher Education and in the National Health Service. My most recent post was for [JISC](https://web.archive.org/web/20120611110953/http://www.jisc.ac.uk/) (Joint Information Systems Committee) as a Programme Manager. I was responsible for a portfolio of development projects in the digital library sphere. I joined UKPMC at the [British Library](https://web.archive.org/web/20120611110953/http://www.bl.uk/) in May 2008.\n\n### 10. Do you want to talk about future plans for UK PubMed Central? {#10-do-you-want-to-talk-about-future-plans-for-uk-pubmed-central}\n\nYes please! We are soon to launch some exciting new initiatives in January 2010. Our website has been completely redesigned with a new more intuitive interface, and we will be expanding our content to include all content from PubMed (c. 18m references), patents, theses and [NHS Clinical Guidelines](https://web.archive.org/web/20120611110953/http://www.library.nhs.uk/GUIDELINESFINDER/). Consequently our users will be able to access a vast collection of relevant content through one portal.\n\nOur search engine will be utilising innovative new techniques such as text mining to retrieve more contextually relevant information, link to other relevant databases and provide a richer search experience for the user. We are also expanding our Grant Reporting functions to allow Grantees and Funders to assess the impact and value of their funded research, and increase their visibility.\n\nOur Funders are keen to expand the programme, possibly towards a future **European PubMed Central**.We are hopeful that as part of this process some European Funders may be joining the programme shortly. Our Funders hope to make an announcement regarding this shortly.\n\nWe are holding a Showcase event on January 12th at the British Library in London to highlight these new developments and the future potential of the service.\n\n### 11. Could you provide contact information for people that have further questions about PubMed Central? {#11-could-you-provide-contact-information-for-people-that-have-further-questions-about-pubmed-central}\n\nBy all means, people can email us at [ukpmc@bl.uk](https://web.archive.org/web/20120611110953/mailto:ukpmc%40bl.uk) and my email is [Philip.Vaughan@bl.uk](https://web.archive.org/web/20120611110953/http://bl.uk/).\n","doi":"https://doi.org/10.53731/dzr4d0a-anr8e6y","guid":"62d42bbd41e317003df48dc8","id":"5b28627b-1ef1-452e-bfe7-388e3d61a28b","image":"https://blog.front-matter.io/content/images/2022/08/web.jpeg","indexed_at":1,"language":"en","published_at":1257292800,"reference":[],"relationships":[],"summary":"PubMed Central was launched in February 2000 by the U.S. National Institutes of Health (NIH) as a free digital archive of journal articles. Just as PubMed, PubMed Central covers research in the life sciences, but not other areas of research, e.g. engineering, physical sciences or astronomy.\n","tags":["Interview"],"title":"UK PubMed Central: Interview with Phil Vaughan","updated_at":1660721362,"url":"https://blog.front-matter.io/posts/uk-pubmed-central-interview-with-phil-vaughan"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/thoughts-on-the-pubmed-redesign","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"It was [Anna Kushnir](https://web.archive.org/web/20120611025631/http://network.nature.com/people/U2929A0EA/profile) who started it all. Frustrated with the limitations of PubMed when finishing her PhD thesis, she wrote a blog post in March 2008 ([I Am Not Yelling. Not Out Loud.](https://web.archive.org/web/20120611025631/http://network.nature.com/people/U2929A0EA/blog/2008/03/22/i-am-not-yelling-not-out-loud)) about her experience. The blog post created quite a stir in the blogosphere, especially among [science librarians](https://web.archive.org/web/20120611025631/http://mbanks.typepad.com/my_weblog/2008/04/the-anna-kushni.html). At the heart of the controversy was Anna\\'s complaint that PubMed is too complicated to use, and that some science librarians felt PubMed simply is complicated and that users such as Anna should take better advantage of the resources available to better use PubMed. David Lipman, director of the [NCBI](https://web.archive.org/web/20120611025631/http://www.ncbi.nlm.nih.gov/) and responsible for PubMed, said:\n\n> Although the current engine works well for some users and some queries, I understand Anna\\'s frustration and we are in the midst of a number of changes that will make PubMed work better for her and many other users.\n\nIn May 2009 a PubMed redesign [was shown](https://web.archive.org/web/20120611025631/http://www.nlm.nih.gov/pubs/techbull/mj09/ppt/sunrise_gillikin/sunrise_2009_gillikin.html) at the 2009 Annual Meeting of the Medical Library Association (MLA) in Honolulu, and the presentation explains a lot of the ideas behind the redesign. On September 30 the redesigned PubMed [was unveiled to the public](https://web.archive.org/web/20120611025631/http://www.nlm.nih.gov/pubs/techbull/so09/so09_pm_redesign.html), and as early as next week it will become the default PubMed web interface.\n\n<figure class=\"kg-card kg-image-card\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/35053.png\" class=\"kg-image\" loading=\"lazy\" width=\"196\" height=\"127\" />\n</figure>\n\nSeveral science bloggers have already written about the PubMed redesign, including a [very detailed blog post](https://web.archive.org/web/20120611025631/http://laikaspoetnik.wordpress.com/2009/10/01/pubmed&Acirc;&reg;-redesign-is-here-to-try/) by Jacqueline Limpens.\n\n### What is PubMed?\n\nMEDLINE is a database of more than 19 million citations for biomedical articles, hosted by the U.S. National Library of Medicine. [PubMed](https://web.archive.org/web/20120611025631/http://www.pubmed.gov/) is the freely available Web interface to that database. Not only is the content of PubMed available from other databases (e.g. [Scopus](https://web.archive.org/web/20120611025631/http://www.scopus.com/) or [Web of Science](https://web.archive.org/web/20120611025631/http://thomsonreuters.com/products_services/science/science_products/scholarly_research_analysis/research_discovery/web_of_science)), but PubMed can be searched not only via the Web interface, but also from within other applications, e.g. a reference manager such as [Endnote](https://web.archive.org/web/20120611025631/http://www.endnote.com/) or [Papers](https://web.archive.org/web/20120611025631/http://mekentosj.com/papers). And PubMed doesn\\'t cover all scientific journals, many disciplines (e.g. physics, social sciences) aren\\'t included at all. In other words, the Pubmed web interface is not the only way to find biomedical articles, and in fact will not find literature not related to the life sciences. But the PubMed web interface is probably by far the most popular way to search for biomedical literature.\n\n### What is the target audience?\n\nThe PubMed website is intended for at least 5 different audiences:\n\n-   science librarian\n-   researcher in the life sciences\n-   clinician\n-   patient or patient relative\n-   teacher, high school student, journalist and anybody else interested in life sciences research\n\nBefore PubMed [was announced in June 1997 by the U.S. vice president Al Gore](https://web.archive.org/web/20120611025631/http://www.nlm.nih.gov/archive//20050113/news/press_releases/free_medline.html) as free web-based access to the MEDLINE database, most users were librarians, plus of a small group of academics with paid access (remember [Grateful Med](https://web.archive.org/web/20120611025631/http://www.annals.org/cgi/content/abstract/105/2/321) ?). Now we have a number of target audiences with different experience in literature search strategies and different intentions:\n\n-   librarian vs. academic vs. the general public\n-   basic life sciences research vs. clinical research\n\nAs PubMed is the most popular but not the only interface to the MEDLINE database, the primary target audience will not be a librarian, but someone with less experience in searching the biomedical literature (and less time). I would lump academics together with the general public here, and think that the typical PubMed search should be as simple as the typical Google search. Everything much more complicated than a simple input box should be moved to an **advanced search options** page, or should be done via a different interface to the MEDLINE database.\n\nSearching for clinical literature is very different from searching for basic science research. Here a search is often done to help in the decision making for a particular patient, and [evidence-based medicine](https://web.archive.org/web/20120611025631/http://en.wikipedia.org/wiki/Evidence-based_medicine) is used to find the most relevant scientific literature (with meta-analyses and randomized controlled trials providing the best evidence).\n\n<figure class=\"kg-card kg-image-card\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/91px-Tribolium.castaneum.jpg\" class=\"kg-image\" loading=\"lazy\" width=\"91\" height=\"120\" />\n</figure>\n\nSearching for basic science literature has very different goals. It is either finding the needle in the haystack, e.g. you want to find all the published literature on the [C3PO](https://web.archive.org/web/20120611025631/http://dx.doi.org/10.1126/science.1176325) gene, or you want to find a review article as an overview over a particular field. But basic science review articles don\\'t have the rigourous tools available to evaluate clinical research mentioned above, and here review articles only differ in the personal perspective of the reviewers and completeness and actuality of the primary literature that was covered. Searching for basic science literature should also be tightly integrated with the other databases at the NCBI. This is done via the [Entrez Search Page](https://web.archive.org/web/20120611025631/http://www.ncbi.nlm.nih.gov/sites/gquery), so that a search for **C3PO** also links to the organisms it was described in, e.g. this one:\n\nI don\\'t think that a search interface to MEDLINE can be good at both the clinical and basic science literature. The current PubMed is much closer to the latter, so I think that the primary target audience for PubMed is the **academic or general public interest in basic life sciences research**. A good search interface for the clinical literature would be something very different and has to include both databases of evidence-based evaluations (particularly from the [Cochrane Collaboration](https://web.archive.org/web/20120611025631/http://www.cochrane.org/)) and from ongoing and completed clinical trials (particularly [Clinicaltrials.gov](https://web.archive.org/web/20120611025631/http://clinicaltrials.gov/), just like PubMed also hosted at the NIH).\n\n### Where is Web 2.0? {#where-is-web-2-0}\n\nA PubMed redesign in 2009 can\\'t be complete without looking at what Web 2.0 has to offer. This means that users should be offered a personal PubMed account that links to their libraries for full-text articles, stores common searches, creates RSS outputs, allows sharing of search results with other users, publishes a link to an interesting article on Twitter, and possibly other enhancements (e.g. a public profile page of all your PubMed articles, but that wouldn\\'t work without [author identifiers](https://web.archive.org/web/20120611025631/http://themindwobbles.wordpress.com/2009/08/22/breakout-3-author-identity-creating-a-new-kind-of-reputation-online/)). This also means a clean design, use of Javascript/AJAX for the user interface, a version for mobile users (particularly iPhone), and frequent small updates instead of a big design change every 2-3 years.\n\n### And how is the redesigned PubMed?\n\nAfter this rather long introduction, what do I like about the PubMed Redesign?\n\n### Like\n\n-   Clean, uncluttered design\n-   Saving a search as RSS is faster and more obvious. I hope that this will make many more people use RSS than email alerts for their regular searches ([why I like RSS](https://web.archive.org/web/20120611025631/http://network.nature.com/people/mfenner/blog/2009/06/21/recipe-receiving-journal-table-of-contents-automatically))\n-   Auto suggest: some of the most popular PubMed searches will be displayed based on the terms entered\n-   Some use of Javascript/AJAX\n\n### Dislike\n\n-   The [DOI](https://web.archive.org/web/20120611025631/http://www.doi.org/) (the best unique identifier for a paper and the easiest way to link to the full-text article) is still not displayed in the standard abstract view (you find the DOI in the Medline and XML views)\n-   Small design flaw: no easy way to go back from advanced search to basic search\n-   Layout is now different from MyNCBI and the other NCBI databases (maybe this is work in progress)\n-   (As far as I know) no version for mobile users\n-   No send to CiteULike/Connotea/Twitter/FriendFeed, etc. buttons (popular with many journals)\n\nThe redesign will make it easier for inexperienced users to do quick searches (as mentioned above, probably the target audience). Experienced librarians might like the redesign less, as advanced searches have not become easier. But overall the changes are minor. My biggest complaint is the lack of DOI integration. A wasted opportunity. And -- as mentioned above -- I think we need a different MEDLINE interface for searching the clinical medicine literature.\n\nHow do you like the redesign? Jacqueline Limpens is [doing a poll on her blog](https://web.archive.org/web/20120611025631/http://laikaspoetnik.wordpress.com/2009/10/01/pubmed&Acirc;&reg;-redesign-is-here-to-try/).\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw3a","guid":"62d42bbd41e317003df48dc5","id":"bfa5e7e6-7185-4bc7-bfc6-ce21d50c2c52","image":"https://blog.front-matter.io/content/images/2022/08/web-pubmed.jpeg","indexed_at":1,"language":"en","published_at":1255219200,"reference":[],"relationships":[],"summary":"It was Anna Kushnir who started it all. Frustrated with the limitations of PubMed when finishing her PhD thesis, she wrote a blog post in March 2008 (I Am Not Yelling. Not Out Loud.) about her experience. The blog post created quite a stir in the blogosphere, especially among science librarians.\n","tags":["Feature"],"title":"Thoughts on the PubMed Redesign","updated_at":1660721273,"url":"https://blog.front-matter.io/posts/thoughts-on-the-pubmed-redesign"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/plos-one-interview-with-peter-binfield","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"At [SciBar Camp Palo Alto last month](https://web.archive.org/web/20151002113207/http://network.nature.com/people/mfenner/blog/2009/07/10/i-was-at-scibarcamp-palo-alto), Peter Binfield from [PLoS ONE](https://web.archive.org/web/20151002113207/http://www.plosone.org/) gave a very interesting presentation on [Article-level metrics from the PLoS perspective](https://web.archive.org/web/20151002113207/http://friendfeed.com/scibarcamp/3577ed2e/peter-binfield-article-level-metric-from-plos). Particularly interesting was his announcement that **PLoS** journals will provide usage data (HTML pageviews, PDF and XML downloads) for all their articles in September. Usage data, like [all measures of scientific impact](https://web.archive.org/web/20151002113207/http://dx.doi.org/10.1371/journal.pone.0006022), have their problems, but they are a welcome addition to citation-based metrics.\n\nI've interviewed Pete to ask him not only about article-level metrics, but also about the publishing model of **PLoS ONE** and how these two relate to each other.\n\n### 1. Can you describe what PLoS ONE is and does? {#1-can-you-describe-what-plos-one-is-and-does}\n\n[PLoS ONE](https://web.archive.org/web/20151002113207/http://www.plosone.org/) is an Open Access, scholarly, peer reviewed journal for all of science. We will be three years old in December 2009, but already we are the [third largest journal (of any type) in the world](https://web.archive.org/web/20151002113207/http://poeticeconomics.blogspot.com/2009/07/dramatic-growth-of-plos-one-soon-to-be.html), publishing approximately 4,600 articles in 2009 alone and almost doubling in volume every year. We are online only (publishing in HTML, XML and PDF) and we publish daily (about 20 articles a day at present). In my view **PLoS ONE** is the most dynamic, innovative and exciting journal in the world, and I am proud to work on it.\n\nIn many ways **PLoS ONE** operates like any other journal however it diverges in several important respects. The founding principle of **PLoS ONE** was that there are certain aspects of publishing which are best conducted pre-publication and certain aspects which are best conducted post-publication. The advent of online publishing has allowed us to take a step back and re-evaluate these aspects of how we publish research, without the burden of centuries of tradition. In this way, we have been able to experiment with new ways of doing things which may result in dramatic improvements in the entire process of scholarly publication.\n\nThe most important thing which has come out of this premise is that unlike almost every other journal in the world, we make no judgment call whatsoever on the \"impact\" or \"significance\" or \"interest level\" of any submission. What this means is that if an article appropriately reports on well-conducted science, and if it passes our peer review process (which determines whether it deserves to join the scientific literature) then we will publish it. In this way, no author should ever receive the message that their article is scientifically sound but \"not interesting enough\" for our journal, or that their article is \"only suited to a specialized audience\". As a result, we short circuit the vicious cycle of submit to a \"top tier\" journal; get reviewed; get rejected; submit to the next journal down the list; repeat until accepted and we are therefore able to place good science into the public domain as promptly as possible, with the minimum of burden on the academic community.\n\nThe most recent example of the way in which we separate pre-publication activity from post-publication activity is with the development of our [Article-Level Metrics program](https://web.archive.org/web/20151002113207/http://everyone.plos.org/tag/article-level-metrics/). **Article-level metrics** start from the assumption that the best way to measure the worth of an article is to look at the actual article itself (and not the journal it happens to have been published in). Following from this, it seems obvious that the best way to evaluate any article is to make use of the collective opinion of all experts in the field (and not a small number of peer reviewers, or a small number of people who ultimately go on to cite the article). An evaluation of this type (which requires that people actually read, and then act in a variety of ways, on the article) can only be done after the article is published (and not before, as happens when a journal rejects a paper because it thinks it is not \"impactful\" enough). Therefore, our development of new tools to facilitate the post-publication evaluation of individual articles is a great example of us separating out what is most appropriately conducted pre-publication vs post-publication.\n\nI have gone into some detail on these issues in a recent peer reviewed paper -- [PLoS One: background, future development, and article-level metrics](https://web.archive.org/web/20151002113207/http://conferences.aepic.it/index.php/elpub/elpub2009/paper/view/114) and I would also recommend Shirley Wu's excellent [recent blog post on this topic](https://web.archive.org/web/20151002113207/http://shirleywho.wordpress.com/2009/08/06/the-evolution-of-scientific-impact/).\n\n### 2. Can you describe what Ambra/Topaz is and does? {#2-can-you-describe-what-ambra-topaz-is-and-does}\n\nBasically Ambra is our publishing platform, which runs on top of the [Topaz](https://web.archive.org/web/20151002113207/http://everyone.plos.org/2009/05/13/all-plos-titles-now-on-the-same-publishing-platform/) infrastructure. For the full technical detail, the best information is found [here](https://web.archive.org/web/20151002113207/http://ambraproject.org/).\n\n### 3. Can you talk a little bit more about the post-publication features of Ambra/Topaz? {#3-can-you-talk-a-little-bit-more-about-the-post-publication-features-of-ambra-topaz}\n\nOnce an article is published, our platform allows users to leave feedback directly on the article. We were among the first journals to allow this, and we remain somewhat unique in this respect, although the concept is gaining broader acceptance and similar functionality is starting to appear at other publishers sites. Specifically, we allow users to leave a Note inline with a specific selection of text; or they can leave a general Comment on the entire article; or they can Star rate the article (on a 5 point scale in 3 categories). Comments and Notes form discussion threads, and users can then engage in debate on the points raised.\n\nUsers may not be anonymous, they must follow our guidelines for civilized academic debate, and when leaving feedback they are [asked to declare any competing interests](https://web.archive.org/web/20151002113207/http://www.plosone.org/static/commentGuidelines.action). I want to make it clear that the post-publication functionality that we provide is not intended to provide post-publication peer review -- it is post-publication discourse and feedback. All **PLoS** titles now share this same functionality.\n\n### 4. Are other publishers besides PLoS using the Ambra/Topaz platform? {#4-are-other-publishers-besides-plos-using-the-ambra-topaz-platform}\n\nNone that we are aware of although the NIH has an internal project. But Topaz is open source, so please contact us if you want to use it!\n\n### 5. What article-level metrics does PLoS ONE provide? {#5-what-article-level-metrics-does-plos-one-provide}\n\nAs of today (August 2009), on every article, in every **PLoS** title we provide:\n\n-   Number of citations (as measured by [Scopus](https://web.archive.org/web/20151002113207/http://www.scopus.com/) and [PubMedCentral](https://web.archive.org/web/20151002113207/http://www.pubmedcentral.nih.gov/))\n-   Number of social bookmarks (as recorded by [CiteULike](https://web.archive.org/web/20151002113207/http://www.citeulike.org/) and [Connotea](https://web.archive.org/web/20151002113207/http://www.connotea.org/))\n-   Number of star ratings left by users on our system\n-   Notes, Comments and any replies, as left by users of our system\n-   Number of blog posts written about the article (as counted by the blog aggregators [Postgenomic](https://web.archive.org/web/20151002113207/http://www.postgenomic.com/), [Nature Blogs](https://web.archive.org/web/20151002113207/http://blogs.nature.com/) and [Bloglines](https://web.archive.org/web/20151002113207/http://www.bloglines.com/))\n-   Specific trackbacks to the article from any web page using our trackback protocol\n\nIn September we will be adding additional citation data as measured by [CrossRef](https://web.archive.org/web/20151002113207/http://www.crossref.org/) and, most significantly, the online usage for each article (going back to the original publication date and reported on a monthly basis, broken down by HTML pageviews, PDF downloads, and XML downloads). This development in particular is very exciting -- no other publisher has made this data available for such a large corpus of articles.\n\nAfter this, the next data source we will add will be blog coverage as aggregated by [ResearchBlogging.org](https://web.archive.org/web/20151002113207/http://researchblogging.org/), and in subsequent months we will be adding other metrics as and when we can identify high quality sources which meet our criteria.\n\n**Article-level metrics** are a major development for **PLoS** and we believe that we are unique in the publishing industry with the transparent provision of such a range of **article-level metrics**. No other publisher provides as much (or any, in most cases) article-level data in such a comprehensive and open manner. It is our belief that once we have demonstrated what is possible, as well as the power of these metrics, the academic community will quickly begin to expect, and demand, this level of information from all journals. As a result the very nature of research reporting and evaluation will be improved as a result.\n\n### 6. How do article-level metrics fit in with how PLoS ONE conducts peer review {#6-how-do-article-level-metrics-fit-in-with-how-plos-one-conducts-peer-review}\n\nWe peer review all submissions for their [scientific content](https://web.archive.org/web/20151002113207/http://www.plosone.org/static/review.action), but we do NOT peer review them in order to determine whether they are high or low impact (or interest or significance or relevance etc). Therefore, from the reader's point of view, when you encounter a **PLoS ONE** article you do not necessarily know how impactful, or interesting, or significant, or relevant that article might be (without actually reading it!). In the traditional model, you would have some indication as to the likely importance of an article by a knowledge of the journal in which it was published in (although we argue that this way of determining quality is actually [one of the worst methods you could use](https://web.archive.org/web/20151002113207/http://www.plos.org/cms/node/478)), however in **PLoS ONE** all you know is that the article is scientifically and methodologically sound (which are the only questions that our peer review process asks). Therefore, **article-level metrics** provide the reader with an indication as to the worth of an article once it is published. Until today, people have effectively said: this article was published in journal X, therefore knowing this one fact, I now know that the article is excellent/good/average/poor. I think that any sane person who considered that statement would realize how unscientific it was. With the advent of **article-level metrics**, a reader can now say \"this article was published as part of the scientific literature, it is irrelevant which journal it was published in as I have now been given a variety of information about the article itself which will help me decide whether the article is excellent / good / average / poor for my own purposes\".\n\nTherefore, **article-level metrics** do not supplant peer review and they also do not represent post-publication peer review. However they do provide the reader with new and valuable ways to do the post-publication evaluation and filtering of journal content.\n\n### 7. What are PLoS ONE subject areas or portals? {#7-what-are-plos-one-subject-areas-or-portals}\n\nWe actually have several ways to 'parse' our content by [topic](https://web.archive.org/web/20151002113207/http://www.plosone.org/static/browse.action): All content is assigned to one or more of our 52 topic areas (for example Pathology or Oncology). These topics are assigned by the authors themselves and an article can appear in more than one topic. Having made that classification, readers can then [browse the topics](https://web.archive.org/web/20151002113207/http://www.plosone.org/article/browse.action) or subscribe to [an RSS feed per topic](https://web.archive.org/web/20151002113207/http://www.plosone.org/static/rssFeeds.action).\n\nHowever, we appreciate that this is not a very flexible way to find content that doesn't easily fall under our existing taxonomy structure. Therefore, we also have the ability to aggregate our articles into [Collections](https://web.archive.org/web/20151002113207/http://www.plosone.org/article/browseVolume.action). A Collection is literally just an aggregation tool (post-publication) -- articles are still published as part of the normal run of the journal, but can then be assigned to join a Collection where they will also appear as part of a collection of related articles. For example, right now we have a very popular [Paleontology Collection](https://web.archive.org/web/20151002113207/http://www.plosone.org/article/browseIssue.action?issue=info%3Adoi%2F10.1371%2Fissue.pone.c01.i02). As we publish new Paleontology articles they get added to this Collection to form a single location for all relevant articles in the field. This Collection functionality can also be used for the output of a single research effort, and an example of this is our [Stress-Induced Depression and Comorbidities Collection](https://web.archive.org/web/20151002113207/http://www.plosone.org/article/browseIssue.action?issue=info%3Adoi%2F10.1371%2Fissue.pone.c01.i01) which effectively replicated a \"Special Issue\" of a journal, and contained all the articles we published as written by the EUMOOD Research Consortia. Collections can be static, or can build up over time, and articles can appear in multiple Collections -- as such they represent a very flexible way to re-present our content.\n\nThen we have **PLoS** Hubs, which are under development right now. We see a Hub as a way to aggregate journal articles (along with other types of content) about a given topic into a single location. Once aggregated, we can then provide various community specific tools and services around this content. A Hub should not be thought of as a portal or an overlay journal -- the distinguishing feature will be that a Hub will physically contain (and not just link out to) as much content as possible. Clearly, the easiest way to achieve this is by making the content Open Access, and so we also see Hubs as an opportunity to demonstrate the power of an Open Access copyright license. At the moment there is only one Hub (the [PLoS Clinical Trials Hub](https://web.archive.org/web/20151002113207/http://clinicaltrials.ploshubs.org/home.action)) but this is a rather old implementation of the concept and only contains **PLoS** content -- therefore we are proactively working on a new release which will include more of the functionality described above.\n\nFuture developments to our platform will involve the ability to tag articles (perhaps by some combination of curated and user generated tags) which will provide yet another way to dynamically aggregate the content.\n\n### 8. How has the Ambra/Topaz platform handled the enormous growth of PLoS ONE? {#8-how-has-the-ambra-topaz-platform-handled-the-enormous-growth-of-plos-one}\n\nGreat! We had a few architecture issues in the past due to the bleeding edge nature of the platform, but all seven of our journals have now migrated to the same platform and no substantial issues have come up since the we migrated our Community Journals (back in early 2008).\n\n### 9. What are your responsibilities at PLoS? {#9-what-are-your-responsibilities-at-plos}\n\nI am the Managing Editor of **PLoS ONE** (one of seven titles at **PLoS**). Although this position is an Editorial one, it is the position which is ultimately responsible for everything associated with the journal. By this I mean that although other departments may not report into me, I am ultimately responsible for the marketing, production, operations, web etc of the journal. If we have a problem with any aspect of the journal, it is me that makes sure it gets solved!\n\n### 10. What did you do before starting to work at PLoS? {#10-what-did-you-do-before-starting-to-work-at-plos}\n\nWell, I am a physicist from way back -- I have a first degree in Physics with Astrophysics and a PhD in Underwater Optical Holography (which I always tell people sounds a lot more interesting than it was!). After my PhD I realized I wasn't interested in a life in academia and so I moved into Academic Publishing, which allowed me to stay in touch with academia and also to interact with leading researchers conducting the latest research. I started out at Institute of Physics Publishing, in Bristol UK, doing book acquisitions, then I moved to Holland to work for Kluwer Academic Publishers (KAP) to start up a reference work program for them. Via a series of moves I ended up running the KAP Earth, Environmental and Plant Sciences division -- a large portfolio of books, reference works and journals in those areas. Around the time that KAP merged with Springer I moved into Business Development for a year or so, which was an interesting period working on Springer's [Open Choice](https://web.archive.org/web/20151002113207/http://www.springer.com/open+access/open+choice) program, online reference works and journal acquisitions among others. Then I left Springer, and also Holland, to move to California (my wife is from San Diego) where I worked for SAGE Publications, just North of LA, for 3 years. There I ran the SAGE US Journals division, which was made up of some 200 or so journals, mostly in the Social Sciences. In that position a large part of the job involved bidding on society titles, to publish them under contract. And then, finally, in March 2008 I moved to San Francisco, to work for **PLoS** and run **PLoS ONE**.\n\n### 11. Do you want to talk about future plans for Ambra/Topaz? {#11-do-you-want-to-talk-about-future-plans-for-ambra-topaz}\n\nThe list of upcoming projects includes:\n\n-   More article-level metrics development\n-   RDFa implementation\n-   Automatic article relationships\n-   Semantic enhancement\n-   REST-based API\n-   The ingest and publication of many types of content / data (structured and unstructured)\n-   Tags\n-   Enhanced search and browse functionality\n-   A new process to submit articles directly to PubMed Central and other external repositories\n-   Direct access to our underlying triple store (sparql endpoint, RDFa)\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw36","guid":"62d42bbd41e317003df48dc1","id":"8570f938-38d9-4fb5-9868-a2bec6ee2e65","image":"https://blog.front-matter.io/content/images/2022/08/maxresdefault.jpeg","indexed_at":1,"language":"en","published_at":1250294400,"reference":[],"relationships":[],"summary":"At SciBar Camp Palo Alto last month, Peter Binfield from PLoS ONE gave a very interesting presentation on Article-level metrics from the PLoS perspective. Particularly interesting was his announcement that\n<em>\n <em>\n  PLoS\n </em>\n</em>\njournals will provide usage data (HTML pageviews, PDF and XML downloads) for all their articles in September.\n","tags":["Interview"],"title":"PLoS One: Interview with Peter Binfield","updated_at":1660667301,"url":"https://blog.front-matter.io/posts/plos-one-interview-with-peter-binfield"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/mutation-selection-and-metastasis","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"<figure class=\"kg-card kg-image-card\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/DarwinBadge.gif\" class=\"kg-image\" loading=\"lazy\" width=\"135\" height=\"149\" />\n</figure>\n\nMutation and selection are important concepts in cancer biology. One well-known example is hereditary colon cancer. Patients with mutations in the DNA mismatch repair genes **MLH1** or **MSH2** develop colon cancer because of an increased rate of mutations. And tumors in patients with familial polyposis coli have a growth advantage because of a mutation in the tumor suppressor gene APC. Mutations and selection also help to explain the process of metastasis, the formation of secondary tumor foci at distant sites in the body. Understanding metastasis is important, because it is often this spread of the tumor that makes a previously localized cancer an incurable disease.\n\nIn 1977 a landmark paper in **Science** by Isaiah Fidler and Margaret Kripke (Fidler 1977) described a mouse model of lung metastasis using the syngeneic B16 mouse melanoma cell line. This melanoma cell line originated spontaneously in a C57BL/6 mouse in 1954 and is known to metastasize to the lung. They produced several clones of the B16 cells, each clone originating from a single cell and therefore genetically identical. Cells from these clones were then injected into the tail vein of C57BL/6 mice. The number of lung metastases in these mice varied dramatically between clones and was also different from the parental cell line. Fidler and Kripke concluded that a subpopulation of highly metastatic cells preexists in the parent population and is selected during the metastatic process.\n\nIn 1994 I started to work on a research project that tried to identify molecules responsible for the selection process in this B16 lung metastasis model. This was before microarrays and the sequencing of the mouse genome, and we used a technique called differential display to identify differentially expressed genes in two variant B16 cell lines that created low and high numbers of lung metastases. We identified a novel gene that turned out to be a transcriptional regulator (Shioda 1996) but probably is not that critical for the metastatic process.\n\nIn 2009 we have learned a lot more about the metastatic process, but we still know much more about genes involved in tumor cell proliferation, apoptosis, etc. than the genes critical for the metastatic process. And we still have not come up with a clever way to specifically treat that malignant subpopulation of tumor cells that will later produce metastatic disease.\n\n### References\n\nFidler, I., & Kripke, M. (1977). Metastasis results from preexisting variant cells within a malignant tumor. Science, 197(4306), 893--895. <https://doi.org/10.1126/science.887927>\n\nShioda, T., Fenner, M. H., & Isselbacher, K. J. (1996). msg1, a novel melanocyte-specific gene, encodes a nuclear protein and is associated with pigmentation. Proceedings of the National Academy of Sciences, 93(22), 12298--12303. <https://doi.org/10.1073/pnas.93.22.12298>\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw46","guid":"62d42bbd41e317003df48de1","id":"8bc1ab3e-935f-4963-bcb2-7bc006230c40","image":null,"indexed_at":1,"language":"en","published_at":1234569600,"reference":[{"doi":"https://doi.org/10.1126/science.887927","key":"ref1"},{"doi":"https://doi.org/10.1073/pnas.93.22.12298","key":"ref2"}],"relationships":[],"summary":"Mutation and selection are important concepts in cancer biology. One well-known example is hereditary colon cancer. Patients with mutations in the DNA mismatch repair genes\n<em>\n <em>\n  MLH1\n </em>\n</em>\nor\n<em>\n <em>\n  MSH2\n </em>\n</em>\ndevelop colon cancer because of an increased rate of mutations. And tumors in patients with familial polyposis coli have a growth advantage because of a mutation in the tumor suppressor gene APC.\n","tags":["Feature"],"title":"Mutation, selection and metastasis","updated_at":1660667180,"url":"https://blog.front-matter.io/posts/mutation-selection-and-metastasis"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/interview-with-geoffrey-bilder","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"Almost exactly two years ago, [**CrossRef**](https://web.archive.org/web/20090221213233/http://www.crossref.org/) invited a number of people to discuss unique identifiers for researchers ([**CrossRef Author ID meeting**](https://web.archive.org/web/20090221213233/http://www.crossref.org/CrossTech/2007/02/crossref_author_id_meeting.html)). One year ago Thomson Reuters launched **ResearcherID** ([**Thomson Scientific launches ResearcherID to uniquely identify authors**](https://web.archive.org/web/20090221213233/http://network.nature.com/people/mfenner/blog/2008/01/21/thomson-scientific-launches-researcherid-to-uniquely-identify-authors)). And two months ago Phil Bourne and Lynn Fink wrote about this topic in a \u00a0**PLoS Computational Biology** paper ([**I Am Not a Scientist, I Am a Number**](https://web.archive.org/web/20090221213233/http://dx.doi.org/10.1371/journal.pcbi.1000247)).\n\nSo it comes as no surprise that we also talked about author identifiers at the recent [**ScienceOnline09**](https://web.archive.org/web/20090221213233/http://www.scienceonline09.com/index.php/wiki/) meeting in North Carolina (both in the session [**Impact Factors and researcher incentives**](https://web.archive.org/web/20090221213233/http://www.scienceonline09.com/index.php/wiki/Reputation_authority_and_incentives/) and over drinks afterwards). [**Cameron Neylon**](https://web.archive.org/web/20090221213233/http://network.nature.com/people/U42E63119/profile) wrote down his thoughts after the meeting in a blog post ([**A specialist OpenID service to provide unique researcher IDs?**](https://web.archive.org/web/20090221213233/http://blog.openwetware.org/scienceintheopen/2009/01/20/a-specialist-openid-service-to-provide-unique-researcher-ids/)), and this resulted in [**a very interesting**](https://web.archive.org/web/20090221213233/http://friendfeed.com/e/c1fd00ec-15f9-d894-4ea9-4ffeaac5ae28/A-specialist-OpenID-service-to-provide-unique) discussion on **FriendFeed**. And at about the same time both [**Jan Aerts**](https://web.archive.org/web/20090221213233/http://network.nature.com/people/jandot/profile) ([**Who-o-o are you? Who who? Who who?**](https://web.archive.org/web/20090221213233/http://saaientist.blogspot.com/2009/01/who-o-o-are-you-who-who-who-who.html)) and Christopher Leonard ([**Some thoughts on unique author IDs**](https://web.archive.org/web/20090221213233/http://blogs.openaccesscentral.com/blogs/pmcblog/entry/some_thoughts_on_unique_author)) independently wrote blog posts about the same topic. This week [**Cameron Neylon**](https://web.archive.org/web/20090221213233/http://network.nature.com/people/U42E63119/profile) summarized the discussion in another blog post ([**Contributor IDs -- an attempt to aggregate and integrate**](https://web.archive.org/web/20090221213233/http://blog.openwetware.org/scienceintheopen/2009/02/15/contributor-ids-an-attempt-to-aggregate-and-integrate/)).\n\nScience bloggers have put a lot of thought into the idea of a unique author identifier and I've collected more reading material about author ID at **Connotea** using the tag [**authorid**](https://web.archive.org/web/20090221213233/http://www.connotea.org/tag/authorid). But I was also very curious to learn more about the work that has already been done. That's why I asked [**Geoffrey Bilder**](https://web.archive.org/web/20090221213233/http://network.nature.com/people/gbilder/profile) from **CrossRef** a few questions. In the end Geoffrey talked not only about author identifiers, but also about CrossRef, DOIs and many other aspects of scholarly publishing.\n\n### 1. Can you describe what CrossRef is and does? {#1-can-you-describe-what-crossref-is-and-does}\n\nLet me start with what it does because this is a little less likely to make your eyes glaze-over.\n\nCrossRef was originally founded by scholarly publishers to fight [**link-rot**](https://web.archive.org/web/20090221213233/http://en.wikipedia.org/wiki/Link_rot).\n\nWeb links have a half-life of about six years. That is, after six years a link is likely to break because the content that it pointed to has been moved. To a lay-audience this might be a mere annoyance, but to scholarly and professional publishers broken links are anathema. The scholarly record is built on a foundation of links in the form of citations. If these online citation links break, the online scholarly citation record breaks.\\\n\\\nBut surely fighting link-rot should be simple, right? After all, the glory of the web is its decentralized architecture, one in which the domain name that you own can be used as a namespace for identifiers. [**Tim Berners-Lee**](https://web.archive.org/web/20090221213233/http://en.wikipedia.org/wiki/Tim_Berners-Lee) has said that \"cool URIs never die\". Aren't \"persistent URIs\" merely a matter of being disciplined in the way that you mint URIs and in being conscientious about sensibly redirecting URIs when things change location on your web server?\n\nWell, certainly the majority of broken links on the web are the result of careless web administrators not taking the time to structure and redirect their web site's URIs properly, but there are a significant percentage of links that will break despite the best efforts of webmasters. This is because in some cases the domain name in the link will change, and in these cases the whole \"domain name as URI minting name-space\" starts to crumble. When otherwise sensible technorati refer to \"owning\" a domain name, it makes me want to stick forks in my eyeballs. We do not \"own\" domain names. At best, we only lease them and there are manifold ways in which we could lose control of a domain name -- through litigation, through forgetfulness, through poverty, through voluntary transfer, etc. Once you don't control a domain name anymore, then you can't control your domain-name-based persistent identifiers either.\n\nIncidentally, another technorati meme that makes me want to self-harm with cutlery is the notion that \"persistent identifiers don't matter in the age of the search engine. If a link breaks, we can just find the content again wherever it has moved.\" This, naturally, is the self-serving argument often used by Google and it's starry-eyed acolytes. Even just few minutes' reflection reveals the gaping hole in this approach.\n\nThe hole is this -- how do you cite a specific copy of something if there are multiple **almost identical** copies of it located in different places? For instance, lets say there are 2 copies (X and Y) of an article which only differ in a few paragraphs, but those few paragraphs are crucial and likely to change the reader's interpretation of the work. How, in a world where persistent linking is maintained by search engines, do you create a citation link to article X instead of article Y? To create a search-based link that is more likely to resolve to article X, you would essentially have to encode the entire article in the search URI! Even this wouldn't guarantee you that the link directed a future reader to article X first; it is still possible that article Y might end up getting a higher ranking because more people have linked to it and it therefore has a higher page-rank (or equivalent). Believe me, even variations of the search engine scenario (using document hashes for citations, pingbacks, etc.) quickly unravel after a little reflection.\n\nThis is all a long-winded and ranty way of saying that the issue of persistent identifiers on the web is just a wee bit more complex than most people think. So how does CrossRef address the persistent identifier issue?\n\nFrom our perspective, the persistent identifier problem is much more a social problem than a technical one.\n\nIn fact, the technical part of our service is relatively straightforward. CrossRef provides a level of indirection (i.e. a pointer) between an identifier and a URL. When publishers put something online, they assign a CrossRef [**Digital Object Identifier**](https://web.archive.org/web/20090221213233/http://www.doi.org/) (DOI) to it and submit a record for that item with CrossRef. The record includes the CrossRef DOI, basic bibliographic metadata for the content and a URL that points to the current location of the content. People citing the publisher's content are encouraged to use the CrossRef DOI for the citation instead of the publisher's URL. When a researcher clicks on a CrossRef DOI, the CrossRef service redirects the URL to whatever URL the publisher has currently registered for that CrossRef DOI. This means that the publisher can update their CrossRef DOI record to point to a completely new URI (including a new domain name) and any CrossRef DOI citations will continue to work. We provide a few other services based on this infrastructure too. So, for instance, we can resolve an [**OpenURL**](https://web.archive.org/web/20090221213233/http://www.oclc.org/research/projects/openurl/default.htm) to a CrossRef DOI (by querying the publisher-submitted bibliographic metadata), resolve a free-text query to a CrossRef DOI and we can also return bibliographic metadata instead of redirecting if that is what the user wants.\n\nSo-far, so good, but this isn't anything that couldn't be accomplished using other redirection tools such as [**PURLs**](https://web.archive.org/web/20090221213233/http://www.purl.org/), [**CNRI Handles**](https://web.archive.org/web/20090221213233/http://www.handle.net/), [**XRIs**](https://web.archive.org/web/20090221213233/http://www.oasis-open.org/committees/tc_home.php?wg_abbrev=xri), [**NUmly Numbers**](https://web.archive.org/web/20090221213233/http://numly.com/numly/default.asp), etc.? The crucial question to ask of any such service is, \"what guarantees that the publisher will actually update their URL pointers?\" If the publisher doesn't update these pointers, then the links will break anyway. It isn't enough that a publisher decides to use PURLs, if they then don't update their PURLs- in perpetuity.\n\nThis is where it is important to explain the organizational structure and the social effect that this has on the service.\n\nCrossRef was founded as a non-profit, membership organization for publishers. Note that we are entirely catholic in our definition of what a publisher is, so our membership includes commercial publishers, non-profit publishers, open access publishers, institutional repositories, NGOs and IGOs, Video publishers, Wiki-based publishers, etc. We are also open to publishers of all disciplines (humanities, social sciences, sciences, professional), geographies and content types (journals, books, database records, videos, etc.)\n\nIn practice, what unites our membership is a concern that their content should be considered worthy of trust by professional researchers. One way in which researchers assess the trustworthiness of content is by determining how it sits within the scholarly record. Does it provide evidence for its assertions in citations? Do other people cite it?\n\nWhen a publisher joins CrossRef, they agree to a [**set of enforceable terms and conditions**](https://web.archive.org/web/20090221213233/http://www.crossref.org/02publishers/59pub_rules.html) that govern the way in which they use CrossRef's persistent citation infrastructure. Specifically, they agree to:\n\n-   Register DOIs within a week of something being published online\n-   Update the URLs associated with a DOI when said URLs change\n-   Link citations in their content via the DOI\n\nIn joining CrossRef they also agree that CrossRef can fine them or throw them out of the service if they do not meet the terms and conditions of the service. Note that the penalty of being thrown out can be quite severe as it effectively means that the publisher would become invisible in the online scholarly citation record. In short, the system has a built-in social feedback loop that strongly enforces good citizenship.\n\nAs I said, the technical infrastructure of CrossRef is pretty mundane, and it is the social aspect of the service that does the most to guarantee the persistency of CrossRef citation links.\n\n### 2. What are your responsibilities within CrossRef? {#2-what-are-your-responsibilities-within-crossref}\n\nThinking of, gathering the requirements for, designing and (most importantly) launching new services.\n\nLast year we launched a plagiarism detection service called [**CrossCheck**](https://web.archive.org/web/20090221213233/http://www.crossref.org/crosscheck.html). This year I am working on Contributor ID, another project tentatively named CrossMark and a bunch of smaller projects designed to encourage the use of DOIs in citations.\n\n### 3. What did you do before starting to work for CrossRef? {#3-what-did-you-do-before-starting-to-work-for-crossref}\n\nIn the early nineties Allen Renear and I co-founded Brown University's Scholarly Technology Group, where we were charged with providing advanced consulting and support to Brown's research community. In the mid-nineties I grew tired of the politics, resource constraints and institutional paralysis that seems to grip so many universities and I decided to do something as far away from the academic sphere as possible. In short, I worked at a management consultancy doing R&D for their IT group. In 2000 I was lured into managing the web development efforts for an Information Architecture firm called Dynamic Diagrams. In 2001 we were bought by [**Ingenta**](https://web.archive.org/web/20090221213233/http://www.ingentaconnect.com/) in the UK. I became Ingenta's CTO and I moved to Oxford in 2002. I left Ingenta in 2005, did a brief spell of consulting for publishers in 2006 and joined CrossRef in 2007.\n\n### 4. What are your thoughts on how an author identifier should look like? {#4-what-are-your-thoughts-on-how-an-author-identifier-should-look-like}\n\nFirst of all, I think we need to stop talking about \"author\" identifiers. One of the first requirements we found when interviewing publishers, researchers and librarians is that we would ideally like to be able to identify any party who contributes to the scholarly literature in any way. That is, we would also like to be able to identify reviewers, editors, correspondents, bloggers, commenters, etc. This is why we have taken to calling our project the \"CrossRef Contributor ID\" project. This isn't just playing with words either. For instance, as soon as you start thinking about things like \"how do you accommodate reviewers\" in this system you need to think of things like pseudo-anonymity. That is, you want somebody to be able to get credit for doing reviews in a way that doesn't necessarily reveal who reviewed what. In turn, the pay-off for designing a system whereby anonymous reviewers might be credited with reviews could be profound. It might ultimately result in researchers having much more incentive to review if reviewing were something that could be counted and rated in the same way that authorship is.\n\nSecond, I think that people conflate a lot of issues when they talk about \"author identifiers\" \\[sic\\]. Are they talking about the simple token used (e.g. a unique string or a number assigned to an individual like a social security number), are they talking about an authentication mechanism (e.g. [**OpenID**](https://web.archive.org/web/20090221213233/http://openid.net/what/), [**Shibboleth**](https://web.archive.org/web/20090221213233/http://shibboleth.internet2.edu/)) or are they talking about the profile information associated with an identifier (e.g. publications, affiliation, contact info, etc.)? Obviously, these all overlap in some ways, but how they relate and what you choose to focus on depends largely on your use cases.\n\nThird, speaking of use cases, our requirements gathering has identified two broad categories of use cases that, though related, have profoundly different implementation implications. One category of use cases identified revolves around \"knowledge discovery\" and the other category of cases revolves around \"authentication.\"\n\nThe \"knowledge discovery\" use cases are probably the most obvious things that people would like to be able to do with a contributor ID such as:\n\n-   Determine what IDs authored/edited/reviewed document X\n-   What documents where authored/edited/reviewed by ID Y\n-   What IDs are related to ID Z and what is the nature of that relationship (e.g. co-authored, edited, reviewed)\n-   What (subject to privacy settings) is the profile information for ID Z (e.g. institutional affiliation, email address, etc.)\n-   All the author IDs and their respective publications where the institutional affiliation recorded by the author is X\n-   Etc.\n\nAt this point I feel obliged to point out that the bulk of our requirements gathering has been focused on trying to understand the needs of our member publishers. The reason I mention this here is that the bulk of the \"authentication\" use cases that we identified are all focused around making publisher back-office systems less cumbersome. So, for instance, publishers are interested in using a \"contributor id\" for:\n\n-   [**single sign-on**](https://web.archive.org/web/20090221213233/http://en.wikipedia.org/wiki/Single_sign-on) (SSO) for manuscript tracking systems\n-   Disambiguating contact information for use by editorial offices, royalty payments systems, copyright clearances, etc.\n-   Automatic updating of email addresses for table of contents (TOC) alerts and other automated email communications\n-   Automated tools for detecting potential reviewers, including tools for detecting potential conflicts of interest\n-   Synchronization with publisher web site user profiles and granting researchers customized, privileged access to content based on profiles\n-   Understanding all of the manifold ways in which an individual \"contributes\" to a publisher or a field (e.g. As an editor, reviewer, letter writer, conference chair, etc.).\n-   Etc.\n\nAs I said, these are very publisher-focused use cases, but this is not to say that we are not interested in the use cases posed by librarians, researchers and funding agencies. We have actively been talking to people from each of these constituencies and we are trying to understand if there are ways in which we can help them. For instance, we have recently been speaking to a group of researchers who are interested in using some sort of authenticated contributor ID as a mechanism for controlling who gets trusted access to sensitive genome-wide aggregate genotype data.\n\nThe interesting thing to note about these \"authentication\" use cases is that they have far more stringent requirements than the \"knowledge discovery\" use cases. In other words if you are only trying to address the knowledge discovery problem, it might be fine to use automated techniques to disambiguate authors and assign IDs to them. State-of-the-art mechanisms for automatic disambiguation of authors from a defined corpus can be 96-97% accurate, which sounds pretty good. At least until you realize that CrossRef has \\~200K new article DOIs deposited each month, each of which on average has about 3 authors. This could potentially leave you with upwards of 20K in mis/un-identified authors. This error rate might be an acceptable tradeoff for knowledge discovery type applications, but it certainly isn't suitable for authentication type applications.\n\nSpeaking of authentication, I think the fourth thing to note is that, though I think **OpenID** will probably play an important role in any service we provide, by itself it makes a pretty bad identity token and would provide little utility on its own. This all gets back to some of the issues that I raised above when discussing persistent identifiers: URI-based identifiers are fragile because they depend on the domain name. What happens if your OpenID is tied to a domain that you don't control (e.g. a company, an institution a country)? How can you guarantee that, should you leave that company/institution/country that they will do the right thing and let you maintain or redirect that identifying credential?\n\nThe traditional geeky response to this scenario is \"don't get yourself into that situation. Only tie your **OpenID** to a domain that you own.\" (Insert forks in eyeballs). Again, you do not \"own\" a domain name. You lease it. What happens if you lose control of it due to litigation, forgetfulness, poverty, divorce, death? Death? Yes, what happens when somebody dies? When I die does the not-yet-born Georgia Bilder get to buy \"my\" domain \"gbilder.com\" and make it the basis of her identity? Mmm... Gets kind of complicated doesn't it?\n\nOf course, lots of the same issues can be raised with CrossRef, right? What guarantees that CrossRef won't become evil and co-opt all of our identities? This, of course is the big fear underlining the knee-jerk reaction against \"centralized systems\" in favor of \"distributed systems\". The problem with this, as I mentioned in the [**FriendFeed thread**](https://web.archive.org/web/20090221213233/https://friendfeed.com/e/c1fd00ec-15f9-d894-4ea9-4ffeaac5ae28/A-specialist-OpenID-service-to-provide-unique/) is that my personal and unfashionable observation is that \"distributed\" begets \"centralized.\" For every distributed service created, we've then had to create a centralized service to make it useable again (ICANN, Google, Pirate Bay, CrossRef, DOAJ, ticTocs, WorldCat, etc.). This gets us back to square one and makes me think the real issue is- how do you make the centralized system that eventually emerges accountable? This is, of course, a social issue more than a technical issue and involves making sure that whatever entity emerges has clearly defined data portability policies and a \"living will\" that attempts to guarantee that the service can be run in perpetuity- even if by another organization. For the record, I don't think adopting the slogan \"don't be evil\" is enough ;).\n\nAnyway- I could go on talking about what the contributor ID \"should look like\" for a very, very long time, but I think that the above probably addresses some of the major points that are raised when the topic is discussed.\n\n### 5. What are the benefits (and maybe disadvantages) if CrossRef manages the author identifier? {#5-what-are-the-benefits-and-maybe-disadvantages-if-crossref-manages-the-author-identifier}\n\nI think the biggest potential disadvantage that CrossRef has is that it is a consensus-based organization that is governed by sometimes fierce competitors. This aspect of the organization can sometimes slow things down. On the other hand, this can also be a huge strength for us. Once a consensus is agreed, we can move very quickly and push uptake across the industry.\n\nResearch increasingly transcends institutional, geographic and discipline boundaries, so I think another advantage that we have is that we are well positioned to provide a service that is similarly unconstrained.\n\nFinally, I think that we have a very interesting advantage by virtue of the fact that our infrastructure is already integrated upstream in the publication process. There is a useful property of the system that we are designing in that, as researchers used the CrossRef identifier in their interactions with publishers and this data is fed back into our system via DOI deposits, you could start to develop a trust-metric based on the types of claims attached to an author's profile. For instance, an author profile that consisted of nothing but self-claims (e.g. I claim I wrote paper X) might not be very worthy of trust whereas an author profile that consisted of publications that had been verified by the publisher (by virtue of those publications having been processed along with the CrossRef contributor ID) would have far more credibility. You can start to see an interesting hierarchy of publication claims emerging such as:\n\n-   Proxy claims (Leigh claims Geoffrey wrote article X)\n-   Self Claims (Geoffrey claims Geoffrey wrote article X)\n-   Verified claims (Geoffrey claims Geoffrey wrote article X **and** the \"Journal of Psychoceramics\" confirms this claim)\n-   Verified Proxy Claims (Geoffrey (who has already been verified as an author of article X) claims that Kirsty was also an author of article X)\n\n### 6. How does your author identifier relate to other identifiers, e.g. [ResearcherID](https://web.archive.org/web/20090221213233/http://www.researcherid.com/), [Scopus Author ID](https://web.archive.org/web/20090221213233/http://help.scopus.com/robo/projects/schelp/h_autsrch_intro.htm)or [OpenID](https://web.archive.org/web/20090221213233/http://openid.net/what/)? {#6-how-does-your-author-identifier-relate-to-other-identifiers-e-g-researcherid-scopus-author-idor-openid}\n\nOpenID is a different kettle of fish, and I discussed it already above. As for the others (I'd add [**Author Resolver**](https://web.archive.org/web/20090221213233/http://www.authorresolver.com/), [**RePEC**](https://web.archive.org/web/20090221213233/http://repec.org/), [**SciLink**](https://web.archive.org/web/20090221213233/http://www.scilink.com/start.action), [**MathPeople**](https://web.archive.org/web/20090221213233/http://bibserver.berkeley.edu/cgi-bin/mathweb/index.py), [**Nature Network**](https://web.archive.org/web/20090221213233/http://network.nature.com/), etc.), we've actually been talking to some of these parties in order to understand how they might relate to a CrossRef Contributor ID. One obvious difference is in the use-cases being addressed. All of the above are focused on \"knowledge discovery\" use-cases. None of them pretends to provide any sort of authentication services. It is also interesting to note that in a lot of the above cases, the parties see their author identification functionality as a means to an end. For instance, their primary application is \"creating better metrics\" or \"running a social network\" or \"expert identification\" for recruiting purposes. In these cases they don't necessarily see a CrossRef system as being competitive and, in fact, they think that such a service might even improve their primary application.\n\n### 7. Can you talk about the current status and next planned steps of the ContributorID project? {#7-can-you-talk-about-the-current-status-and-next-planned-steps-of-the-contributorid-project}\n\nWe just ended lengthy period of investigation and requirements gathering. In the process we went down a few blind alleys. Now we are working on a prototype that we will test with a few publishers. It is hard to say how long this will take as we are just in the process of planning this phase.\n\n### 8. Satisfying many different interests is one of the biggest challenges in creating an author identifier. What are the lessons learned from implementing the digital object identifier ([DOI](https://web.archive.org/web/20090221213233/http://www.doi.org/))? {#8-satisfying-many-different-interests-is-one-of-the-biggest-challenges-in-creating-an-author-identifier-what-are-the-lessons-learned-from-implementing-the-digital-object-identifier-doi-}\n\nI'll give you one tactical lesson and one strategic lesson.\n\nThe tactical lesson is foremost in my mind because I have recently been trying to build tools to encourage researchers to use DOIs in their citations. The problem arrises when a researcher occasionally encounters a DOI that is 80 characters long. There is just no way that a researcher is going to insert **that** in a citation. The tactical lesson here is that it is sometimes better to make an identifier opaque and short. This is also a tremendously unfashionable position to take, but I think that one of Clay Shirky's observations about hierarchical categorization systems also applies to identifiers. If you make the identifier human-interpretable and add semantics, then people will be extremely tempted to start hard-coding ontologies into their identifiers. This makes said identifiers both long and inherently brittle. The ontologies will inevitably evolve, and then people will want to change the identifiers- at which point they will either break or you have a giant identifier mapping subsystem to create.\n\nWe see a manifestation of this syndrome already with the DOI. Each DOI has a four-digit \"prefix\" which is effectively a namespace for the assigning publisher. Note that I said the \"assigning\" publisher- this is not necessarily the publisher who currently \"owns\" the DOI with that prefix. What this often means is that, when publisher A acquires publisher B, publisher A will ask CrossRef if we can create new DOIs for all of publisher B's backfiles so that they all have the same prefix! The answer to their request is \"no\", but you wouldn't believe how stroppy publishers can get about this. They somehow imbue this ridiculous four-digit prefix with branding significance. This, of course, is absolutely mental, but it is a predictable form of mental. The French went mad when they had to replace their region-encoded license plates with opaque EU ones. People in the US go mad when they are given new area codes. In short, when people associate semantic significance in identifiers, you will face problems.\n\nThe strategic lesson is basically a recapitulation of the \\\"technical vs \"social\" theme I've been banging on about. I think that, at first, even our membership thought of the CrossRef DOI as being a technical solution to a problem, not a social one. It has become much clearer to us over the years that CrossRef DOIs are only as persistent as CrossRef staff. That is, we sometimes have to bang on lots of heads and threaten members with fines and worse in order to make sure that they are meeting their terms & conditions. The good news is that CrossRef has become essential infrastructure for a wide variety of publishers who are often at each other's throats in any other circumstances. In many ways these \"different interests\" are our strength. Everybody wants it to work better, nobody wants to see it die and nobody wants it to be co-opted. We are working hard to put the social structures into place that will guarantee its longevity. Part of this is making sure that we are fiscally sound (which we are) and part of this is making sure that, even if we do disappear, other stakeholders can run the system if need be.\n\n### 9. What can researchers interested in author identifiers do to help? {#9-what-can-researchers-interested-in-author-identifiers-do-to-help}\n\n-   Feed CrossRef more use cases.\n-   Let CrossRef know what you think will/won't work.\n-   Make sure you let your publishers know if you think this is a good idea. Naturally, I expect you will also let them know if you think it is a bad idea ;-)\n\nI can be reached at **gbilder at crossref dot org**.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cw1h","guid":"62d42bbd41e317003df48d8c","id":"74c52bf9-8eec-44c6-8f81-688299b809de","image":"https://blog.front-matter.io/content/images/2022/08/hNo7lvc0_400x400--1-.jpeg","indexed_at":1,"language":"en","published_at":1234902420,"reference":[],"relationships":[],"summary":"Almost exactly two years ago,\n<strong>\n CrossRef\n</strong>\ninvited a number of people to discuss unique identifiers for researchers (\n<strong>\n CrossRef Author ID meeting\n</strong>\n). One year ago Thomson Reuters launched\n<strong>\n ResearcherID\n</strong>\n(\n<strong>\n Thomson Scientific launches ResearcherID to uniquely identify authors\n</strong>\n). And two months ago Phil Bourne and Lynn Fink wrote about this topic in a\n<strong>\n PLoS Computational\n</strong>\n","tags":["Interview"],"title":"Author Identifiers: Interview with Geoffrey Bilder","updated_at":1660667125,"url":"https://blog.front-matter.io/posts/interview-with-geoffrey-bilder"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/inveniordm-lts-announced","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"The open source research data management platform InvenioRDM [today\nannounced](https://inveniordm.docs.cern.ch/releases/versions/version-v6.0.0/%20%20%20)\nthe first Long-Term Support (LTS) release, usable on production\nservices. And I am joining the effort as a participating partner via\n[Front Matter](https://front-matter.io), the organization I started this\nweek.\n\nInvenioRDM was [first announced in April\n2019](https://inveniosoftware.org/blog/2019-04-29-rdm/):\n\n> Our vision in the next five-years, is to make InvenioRDM a\n> world-leading extensible research data management platform used by\n> research institutions all around the world and with businesses\n> providing services, support and customizations on top of InvenioRDM.\n\nThe first concrete set of goals was defined as\n\n- A stable InvenioRDM platform - A research data management platform\n  based on [Zenodo](https://zenodo.org/) and the [Invenio v3\n  Framework](https://inveniosoftware.org/).\n- A community of public and private institutions to sustain InvenioRDM.\n- Minimum two existing repositories migrated to InvenioRDM, with Zenodo\n  being one of them.\n\nToday\\'s release brings invenioRDM much closer to achieving these goals.\nThe next major milestone for InvenioRDM is to migrate\n[Zenodo](https://zenodo.org) to run on top of InvenioRDM.\n\nIn the coming two months I will not only try to get up to speed with the\ninvenioRDM project and start working with the CERN team and the other\nparticipating partners, but I also have the specific task of making sure\ninvenioRDM fully supports the data citation roadmap for scholarly data\nrepositories, work done by the [Force11 DCIP\nproject](https://www.force11.org/group/dcip) with Merce Crosas and me as\nco-leads, and described in a 2019 *Scientific Data* paper (Fenner *et\nal*. 2019):\n\n### Guidelines for Repositories (1-5 required, 6-9 recommended, 10-11 optional)\n\n1.  All datasets intended for citation must have a globally unique\n    persistent identifier that can be expressed as an unambiguous URL.\n2.  Persistent identifiers for datasets must support multiple levels of\n    granularity, where appropriate.\n3.  The persistent identifier expressed as an URL must resolve to a\n    landing page specific for that dataset, and that landing page must\n    contain metadata describing the dataset.\n4.  The persistent identifier must be embedded in the landing page in\n    machine-readable format.\n5.  The repository must provide documentation and support for data\n    citation.\n6.  The landing page should include metadata required for citation, and\n    ideally also metadata facilitating discovery, in human-readable and\n    machine-readable format.\n7.  The machine-readable metadata should use schema.org markup in\n    JSON-LD format.\n8.  Metadata should be made available via HTML meta tags to facilitate\n    use by reference managers.\n9.  Metadata should be made available for download in BibTeX and/or\n    another standard bibliographic format.\n10. Content negotiation for schema.org/JSON-LD and other content types\n    may be supported so that the persistent identifier expressed as URL\n    resolves directly to machine-readable metadata.\n11. HTTP link headers may be supported to advertise content negotiation\n    options\n\nSeveral of these recommendations are of course already addressed by\ninvenioRDM, but there is more work needed in the details, e.g. how\nmetadata are exposed in dataset landing pages using schema.org. And\nthese recommendations have evolved, e.g. as described in the output of\nthe [Research Data Alliance (RDA) Research Metadata Schemas Working\nGroup](https://www.rd-alliance.org/groups/research-metadata-schemas-wg)\npublished in June (Wu *et al.* 2021).\n\nPlease reach out to me in the comments or via email if you have any\nquestions or suggestions regarding this upcoming work, or more generally\nmy new involvement in invenioRDM.\n\n### References\n\nFenner, M., Crosas, M., Grethe, J. S., Kennedy, D., Hermjakob, H.,\nRocca-Serra, P., Durand, G., Berjon, R., Karcher, S., Martone, M., &\nClark, T. (2019). A data citation roadmap for scholarly data\nrepositories. *Scientific Data*, *6*(1).\n<https://doi.org/10.1038/S41597-019-0031-8>\n\nWu, M., Juty, N., RDA Research Metadata Schemas WG , Collins, J., Duerr,\nR., Ridsdale, C., Shepherd, A., Verhey, C., & Castro, L. J. (2021).\n*Guidelines for publishing structured metadata on the Web*.\n<https://doi.org/10.15497/RDA00066>\n","doi":"https://doi.org/10.53731/r8c26t1-97aq74v-ag66m","guid":"62d42bbd41e317003df48f10","id":"7e425fc7-49ea-4174-a05b-78c64bb45455","image":"https://blog.front-matter.io/content/images/2022/07/docs-site.png","indexed_at":1,"language":"en","published_at":1628183749,"reference":[{"doi":"https://doi.org/10.1038/S41597-019-0031-8","key":"ref1"},{"doi":"https://doi.org/10.15497/RDA00066","key":"ref2"}],"relationships":[],"summary":"The open source research data management platform InvenioRDM today announced the first Long-Term Support (LTS) release, usable on production services. And I am joining the effort as a participating partner via Front Matter, the organization I started this week.\n","tags":["News"],"title":"First InvenioRDM Long-Term Support (LTS) version released today \u2013 and Front Matter is joining as a participating partner","updated_at":1660590424,"url":"https://blog.front-matter.io/posts/inveniordm-lts-announced"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/support-open-source","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"Two years ago GitHub introduced the ability to sponsor an open source\ncontributor -- person or organization. They handle (and pay for) the\npayment logistics for a one-time or regular contribution. A [blog post\nfrom June\n2019](https://github.blog/2019-06-12-faq-with-the-github-sponsors-team/)\ndescribes the thinking of the GiHub Sponsors team that went into this\nservice, and the practicalities of using the service are documented\n[here](https://docs.github.com/en/sponsors/sponsoring-open-source-contributors/sponsoring-an-open-source-contributor).\n\nIn my [last blog\npost](https://blog.front-matter.io/mfenner/how-readers-can-support) I\ntalked about a similar concept, supporting this blog via a one-time\ndonation or small monthly contribution. Similar to GitHub sponsors this\nis also a small voluntary contribution rather than a required payment,\nand it depends on a backend service that can handle small contributions\nof just a few dollars/euros.\n\n<figure class=\"kg-card kg-image-card kg-card-hascaption\">\n<img\nsrc=\"https://blog.front-matter.io/content/images/2022/07/Bildschirmfoto-2021-08-12-um-16.06.31.png\"\nclass=\"kg-image\" loading=\"lazy\"\nsrcset=\"https://blog.front-matter.io/content/images/size/w600/2022/07/Bildschirmfoto-2021-08-12-um-16.06.31.png 600w, https://blog.front-matter.io/content/images/size/w1000/2022/07/Bildschirmfoto-2021-08-12-um-16.06.31.png 1000w, https://blog.front-matter.io/content/images/2022/07/Bildschirmfoto-2021-08-12-um-16.06.31.png 1070w\"\nsizes=\"(min-width: 720px) 720px\" width=\"1070\" height=\"555\" />\n<figcaption>Front Matter GitHub sponsoring</figcaption>\n</figure>\n\nReaders of this blog know that I am a big fan of dog food (the\n[saying](https://en.wikipedia.org/wiki/Eating_your_own_dog_food) not the\nfood). In this case it means that Front Matter should become a GitHub\nsponsor for open source software it depends on. As a small startup you\nhave to start somewhere, and the pick for the first organization to\nsupport was an easy one: [Citation Style\nLanguage](https://citationstyles.org/) (CSL). For practical reasons\nFront Matter sponsors Rintze Zelle, one of the main contributors to CSL:\n\nThe reason I picked CSL is that I have never seen an open source project\ncontributing to scholarly infrastructure so much with so few resources.\nCSL is everywhere (see the list of software products using CSL\n[here](https://citationstyles.org/)), and has been for many years. And\nthere is no big organization standing behind CSL that pays a salary that\nallows one or more developers to work on CSL, a common pattern with\nimportant open source software. So a big thank you to [Bruce\nD\\'Arcus](https://twitter.com/bdarcus), [Simon\nKornblith](https://twitter.com/skornblith), [Frank\nBennett](https://twitter.com/fgbjr), [Rintze\nZelle](https://twitter.com/rintzezelle), [Sebastian\nKarcher](https://twitter.com/adam42smith), [Sylvester\nKeil](https://twitter.com/1nukshuk), [Johannes\nKrtek](https://twitter.com/johanneskrtek), Liam Magee, [Charles\nParnot](https://twitter.com/cparnot), Carles Pina, Andrea Rossato, [Dan\nStillman](https://twitter.com/danstillman), and [Philipp\nZumstein](https://twitter.com/zuphilip), to name just a few of the many\ncontributors to CSL. You can thank them yourself in the [CSL discussion\nforum](https://discourse.citationstyles.org/), but if your own software\ndepends on CSL, please consider GitHub sponsorship.\n\nGitHub sponsors and donations and memberships for the Front Matter blog\nare of course flavors of\n[crowdfunding](https://en.wikipedia.org/wiki/Crowdfunding), which has an\ninteresting history and many success stories you can learn from, and\nmistakes to avoid.\n","doi":"https://doi.org/10.53731/r8n4c91-97aq74v-ag6v9","guid":"62d42bbd41e317003df48f12","id":"e5f325b7-d0d0-4495-aea0-0d4572cfaa5e","image":"https://blog.front-matter.io/content/images/2022/07/images.png","indexed_at":1,"language":"en","published_at":1628780202,"reference":[],"relationships":[],"summary":"Two years ago GitHub introduced the ability to sponsor an open source contributor \u2013 person or organization. They handle (and pay for) the payment logistics for a one-time or regular contribution. A blog post from June 2019 describes the thinking of the GiHub Sponsors team that went into this service, and the practicalities of using the service are documented here.\n","tags":["Feature"],"title":"Support open source software as a GitHub sponsor","updated_at":1660590397,"url":"https://blog.front-matter.io/posts/support-open-source"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/the-front-matter-blog-now-uses-dois","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"Yesterday I started registering DOIs for all Front Matter blog posts. I\nhave registered 100 blog posts by now, and will have completed the\nregistration process for all 450 blog posts on Monday. The DOIs are\nregistered with Crossref which Front Matter joined in August. The blog\nposts are registered as [posted\ncontent](https://www.crossref.org/documentation/content-registration/content-types-intro/posted-content-includes-preprints),\nand this is done via the metadata in [schema.org](https://schema.org/)\nformat exposed on each blog page. Besides the required metadata we also\nregister some optional metadata: currently abstract, keywords, license\nand author ORCID ID -- which Crossref uses to automatically push the\nblog post metadata into the ORCID record. The main metadata missing are\nreferences, but that is much more work and something I want to address\nin 2022. All the required metadata are available from the blogging\nplatform ([Ghost](https://ghost.org/) in our case), with a little bit of\nextra work needed for some:\n\n- DOIs are generated from the prefix assigned to Front Matter (10.53731)\n  combined with a suffix auto-generated from the database ID for the\n  blog post -- using the\n  [uuid-encoder](https://github.com/salieri/uuid-encoder) javascript\n  library to turn the ID into a shorter string in base32 format. This\n  for example turns the ID 6125186c149d573936a81d1b into the DOI\n  10.53731/r9531p1-97aq74v-ag78v.\n- The ORCID ID from each author is pulled from the `homepage` field in\n  the author database.\n- The keyword(s) are taken from the tags configured for the blog and\n  used in a particular post.\n- The abstract is the beginning of the full text (stripping all tags\n  with the exception of \\<b\\>, \\<i\\>, \\<em\\> and \\<strong\\>, and limited\n  to 250 characters).\n- The license is the same for every blog post, Creative Commons\n  Attribution 4.0 International ([CC-BY\n  4.0](https://creativecommons.org/licenses/by/4.0/)).\n\nAs you can see in the Crossref participating reports, this approach\ncompares favorably with other Crossref members in terms of metadata\ncompleteness\n\n<figure class=\"kg-card kg-image-card kg-card-hascaption\">\n<img\nsrc=\"https://blog.front-matter.io/content/images/2022/07/Bildschirmfoto-2021-10-14-um-15.34.06.png\"\nclass=\"kg-image\" loading=\"lazy\"\nsrcset=\"https://blog.front-matter.io/content/images/size/w600/2022/07/Bildschirmfoto-2021-10-14-um-15.34.06.png 600w, https://blog.front-matter.io/content/images/size/w1000/2022/07/Bildschirmfoto-2021-10-14-um-15.34.06.png 1000w, https://blog.front-matter.io/content/images/2022/07/Bildschirmfoto-2021-10-14-um-15.34.06.png 1023w\"\nsizes=\"(min-width: 720px) 720px\" width=\"1023\" height=\"1091\" />\n<figcaption>Participation report Front Matter October 14,\n2021.</figcaption>\n</figure>\n\nThe current focus is on registering all existing blog posts, going\nforward we will put a workflow in place that automatically registers a\nDOI when a new blog post is published. This DOI registration will be\ntriggered by a webhook, and I am working on a freely available [GitHub\nAction](https://github.com/features/actions) for this. If you have an\naccount with Crossref or DataCite, and your blog exposes the required\nDOI metadata as schema.org, you will be able to use this webhook. But if\nyou rather don\\'t want to get into the technical details but focus on\nwriting meaningful blog posts, [reach out to Front\nMatter](mailto:info@front-matter.io) and we can set up a blog for you\nthat automatically registers a DOI for each blog post, together with\nsome other unique features such as a full-text search.\n","doi":"https://doi.org/10.53731/rb7xw01-97aq74v-ag7qh","guid":"62d42bbd41e317003df48f17","id":"72a17bc5-acd9-4e6f-8b64-1bc73cdd0734","image":"https://blog.front-matter.io/content/images/2022/07/Schema_org.png","indexed_at":1,"language":"en","published_at":1634219028,"reference":[],"relationships":[],"summary":"Yesterday I started registering DOIs for all Front Matter blog posts. I have registered 100 blog posts by now, and will have completed the registration process for all 450 blog posts on Monday. The DOIs are registered with Crossref which Front Matter joined in August. The blog posts are registered as posted content, and this is done via the metadata in schema.org format exposed on each blog page.\n","tags":["News"],"title":"The Front Matter blog now uses DOIs","updated_at":1660590386,"url":"https://blog.front-matter.io/posts/the-front-matter-blog-now-uses-dois"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/farewell-to-datacite","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"After six years as DataCite Technical Director, I am both sad and\nexcited to announce that I will be leaving DataCite, beginning a new\nadventure as an independent developer for the\n[invenioRDM](https://inveniosoftware.org/products/rdm/) project on\nAugust 1st. My focus will remain on research data management, but with a\ndifferent angle.\n\nA lot has changed since 2015 at DataCite in general, and the DataCite\ntechnical architecture in particular. Rather than describe the work on\nDataCite infrastructure over the past six years in more detail, I want\nto provide a snapshot of where the DataCite infrastructure is with its\ncore services, and what considerations the team is taking into account\ngoing forward.\n\n### Content registration\n\nDataCite members can register DOIs and metadata for content using the\nMetadata Store (MDS). The MDS API hasn't changed much for users since\n2012, although the technology powering the API has been replaced more\nthan once, and the metadata schema is constantly evolving. We have added\na JSON REST API and web frontend ([Fabrica](https://doi.datacite.org/))\nstarting in 2017. Going forward we hope to see more adoption of the JSON\nREST API, e.g. by finalizing and promoting the JSON schema. And we may\nwant to explore other ways to register content, namely by embedding\nmetadata in landing pages using schema.org in combination with sitemaps\nfiles.\n\n### Discovery\n\nIn October 2020 DataCite launched [DataCite\nCommons](https://commons.datacite.org/) as a new discovery platform,\nfollowed by an announcement to retire DataCite Search by the end of\n2021. DataCite Commons enables the discovery of connections between\ncontent, people, and organizations. DataCite Commons uses the existing\nDataCite backend infrastructure with relational databases and\nElasticsearch in combination with a new [GraphQL](https://graphql.org/)\nAPI. Going forward we will see whether this approach scales\nappropriately, or whether a different technology is needed to power\nDataCite Commons. This would include the exploration of graph database\ntechnologies such as neo4j with or without GraphQL. Further, we will\nwork to track the adoption of GraphQL and our REST API architecture.\n\n### Backend services\n\nDataCite as an infrastructure provider has always focussed on backend\nAPIs and related services. As part of this work, DataCite has migrated\nto a Docker container-based cloud architecture. There is still work\nahead, from migrating to [Kubernetes](https://kubernetes.io/) to service\nmeshes and better monitoring and handling of service loads.\n\n### Frontend services\n\nThe DataCite frontend service architecture has gradually evolved over\nthe last six years, with the new services Fabrica and DataCite Commons\nusing modern Javascript frameworks (Ember.js and Next.js, respectively).\nOne side effect of this gradual evolution is a rather complex mix of\ntechnologies. Going forward, rewriting outdated services, and\nconsolidating the various technologies are important goals. Combined\nwith this could be the broader use of [serverless\narchitectures](https://www.serverless.com/) which we started using in\nDataCite Commons.\n\n### Looking ahead\n\nDataCite is in a good position to handle our technology projects during\nthis transition. I have been working closely with the DataCite team to\ntransition responsibilities and will continue to be involved in\ncommunity initiatives. Matt will publish a blog post next week that will\ncover the future team structure.\n\n*This blog post was [originally\npublished](https://doi.org/10.5438/zx3k-3923) on the DataCite Blog.*\n","doi":"https://doi.org/10.53731/r79qwf1-97aq74v-ag4j1","guid":"62d42bbd41e317003df48edd","id":"7aeab9eb-9296-40ae-993e-edb8b7c2ab92","image":"https://blog.front-matter.io/content/images/2022/07/photo-1529268209110-62be1d87fe75.jpeg","indexed_at":1,"language":"en","published_at":1625845140,"reference":[],"relationships":[],"summary":"After six years as DataCite Technical Director, I am both sad and excited to announce that I will be leaving DataCite, beginning a new adventure as an independent developer for the invenioRDM project on August 1st. My focus will remain on research data management, but with a different angle. A lot has changed since 2015 at DataCite in general, and the DataCite technical architecture in particular.\n","tags":["News"],"title":"Farewell to DataCite","updated_at":1660590365,"url":"https://blog.front-matter.io/posts/farewell-to-datacite"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/step-forward-for-software-citation","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"On August 19, [GitHub\nannounced](https://github.blog/2021-08-19-enhanced-support-citations-github/)\nsoftware citation support in GitHub repositories. Citation information\nprovided by users (using a CITATION.cff YAML file in the root directory\nof the default branch) is parsed and made available as bibtex file or\nformatted citation, currently supporting the APA citation style. The APA\nstyle is a good start as it is the only popular citation style that\nlabels software with the string `[Computer software]` but we hope to see\nsupport for more citation styles -- including those popular in computer\nscience -- going forward. Going forward we also hope to see support for\nbiblatex and potentially `@software` as the bibtex entry type.\n\n<figure class=\"kg-card kg-image-card kg-card-hascaption\">\n<img\nsrc=\"https://blog.front-matter.io/content/images/2022/07/Bildschirmfoto-2021-08-24-um-18.16.55.png\"\nclass=\"kg-image\" loading=\"lazy\"\nsrcset=\"https://blog.front-matter.io/content/images/size/w600/2022/07/Bildschirmfoto-2021-08-24-um-18.16.55.png 600w, https://blog.front-matter.io/content/images/2022/07/Bildschirmfoto-2021-08-24-um-18.16.55.png 792w\"\nsizes=\"(min-width: 720px) 720px\" width=\"792\" height=\"626\" />\n<figcaption>Cite this repository GitHub example</figcaption>\n</figure>\n\n    @misc{Haines_Ruby_CFF_Library_2021,\n      author = {Haines, Robert and {The Ruby Citation File\n      Format Developers}},\n      doi = {10.5281/zenodo.1184077},\n      month = {8},\n      title = {{Ruby CFF Library}},\n      url = {https://github.com/citation-file-format/ruby-cff},\n      year = {2021}\n    }\n\nThis is an important step forward for wider software citation adoption,\nas it allows software authors to provide the required information\nnecessary for citing software directly in a GitHub code repository, and\nfor tools and workflows to integrate with this information. Within days\nof the initial GitHub announcement via a tweet by GitHub CEO Nat\nFriedman, we saw support for this new workflow by the scholarly\nrepository\n[Zenodo](https://twitter.com/ZENODO_ORG/status/1420357001490706442) and\nthe reference manager\n[Zotero](https://twitter.com/zotero/status/1420515377390530560) (see\nbelow). The\n[swh-indexer](https://docs.softwareheritage.org/devel/swh-indexer/metadata-workflow.html)\nby [Software Heritage](https://www.softwareheritage.org/) (SWH) already\nindexed and supported searching over the CITATION.cff files available on\nthe HEAD/master branch of a repository archived in SWH.\n\n<figure class=\"kg-card kg-embed-card\">\n<blockquote>\n<p>We\u2019ve added support for GitHub\u2019s new citation feature. When saving\nGitHub repos to your library, Zotero can now use the enhanced metadata\nprovided by developers.<br />\n<br />\nIf there\u2019s no citation file, Zotero will continue to use the existing\nrepo metadata (Company, Prog. Language, etc.). <a\nhref=\"https://t.co/Q34zPBRGFj\">https://t.co/Q34zPBRGFj</a></p>\n<p>\u2014 Zotero (@zotero) <a\nhref=\"https://twitter.com/zotero/status/1420515377390530560?ref_src=twsrc%5Etfw\">July\n28, 2021</a></p>\n</blockquote>\n</figure>\n\nWe also see hundreds of repositories adding CITATION.cff files every\nweek since the initial announcement -- you can track the adoption via\n[this](https://github.com/search?o=desc&p=1&q=CITATION.cff&s=committer-date&type=Commits)\nGitHub query.\n\n<figure class=\"kg-card kg-image-card kg-card-hascaption\">\n<img\nsrc=\"https://blog.front-matter.io/content/images/2022/07/Bildschirmfoto-2021-08-24-um-18.24.19.png\"\nclass=\"kg-image\" loading=\"lazy\"\nsrcset=\"https://blog.front-matter.io/content/images/size/w600/2022/07/Bildschirmfoto-2021-08-24-um-18.24.19.png 600w, https://blog.front-matter.io/content/images/size/w1000/2022/07/Bildschirmfoto-2021-08-24-um-18.24.19.png 1000w, https://blog.front-matter.io/content/images/size/w1600/2022/07/Bildschirmfoto-2021-08-24-um-18.24.19.png 1600w, https://blog.front-matter.io/content/images/2022/07/Bildschirmfoto-2021-08-24-um-18.24.19.png 2000w\"\nsizes=\"(min-width: 720px) 720px\" width=\"2000\" height=\"964\" />\n<figcaption>Tracking Citation.CFF files via GitHub query</figcaption>\n</figure>\n\nWhile a citation pointing to the GitHub code repository is a great\nstart, ideally the software author wants to perform an important\nadditional step: archive the source code in a long-term archive either\nvia the Software Heritage universal software archive (detailed\ninstructions\n[here](https://www.softwareheritage.org/save-and-reference-research-software/),\nand automatable from the GitHub repository with a [GitHub\nAction](https://github.com/marketplace/actions/save-to-software-heritage)),\nand/or the scholarly repository Zenodo via the the *Making Your Code\nCitable* workflow described\n[here](https://guides.github.com/activities/citable-code/), which will\nuse the metadata provided in a CITATION.cff file.\n\nOne particular challenge with citing software is versioning, where there\nare multiple use cases to be supported, including the need to cite a\nspecific version, and to aggregate the citations of all versions in a\nsingle place. There is more work needed to link [GitHub\nreleases](https://docs.github.com/en/github/administering-a-repository/releasing-projects-on-github/managing-releases-in-a-repository)\nto the version information provided in this new GitHub feature, and to\nsupport the generic citation without a specific version -- what Zenodo\ncalls a *concept DOI*, and the Functional Requirements for Bibliographic\nRecords (FRBR) call an\n[*expression*](https://en.wikipedia.org/wiki/Functional_Requirements_for_Bibliographic_Records)*.*\n\nMany software authors also want to link to a publication describing\ntheir software from the GitHub repository, and the [Citation File\nFormat](https://citation-file-format.github.io/) (CFF) supports this via\na\n'[preferred-citation](https://github.com/citation-file-format/citation-file-format/blob/main/schema-guide.md#credit-redirection)'\nfield. Additionally, authors can cite the software (and other works)\ntheir software builds on in a\n'[references](https://github.com/citation-file-format/citation-file-format/blob/main/schema-guide.md#referencing-other-work)'\nsection in CFF files. Software authors are expected to provide the\nrelevant information in a CITATION.cff file in\n[YAML](https://en.wikipedia.org/wiki/YAML) format that follows the\n[Citation File Format](https://citation-file-format.github.io/)\nspecification. An example CITATION.cff file can be found\n[here](https://github.com/citation-file-format/ruby-cff/blob/main/CITATION.cff).\n\nSome software authors might want to use tools to help generate the\nCITATION.cff file. A starting point is the CFF Initializer available\n[here](https://citation-file-format.github.io/cff-initializer-javascript/),\nand a list of available tools for working with CFF files\n[here](https://github.com/citation-file-format/citation-file-format/blob/main/README.md#tools-to-work-with-citationcff-files-wrench);\nwe expect more tools to appear over time. There are many standards for\ndescribing software (we already mentioned bibtex and DOI metadata), and\n[CodeMeta](https://codemeta.github.io/) also plays a particularly\nimportant role by providing\n[crosswalks](https://codemeta.github.io/crosswalk/) and tools for\nconverting between the various metadata standards for software. Going\nforward we expect to see more metadata conversion workflows, in\nparticular via [GitHub Actions](https://docs.github.com/en/actions),\nadding to the already existing\n[cffconvert](https://github.com/marketplace/actions/cffconvert) and\n[CodeMeta2CFF](https://github.com/marketplace/actions/codemeta2cff)\nGitHub Actions. We also hope to see similar software citation support\nappear in the GitLab platform.\n\n*[Cross-posted](https://www.force11.org/blog/step-forward-software-citation-githubs-enhanced-software-citation-support)\nfrom the FORCE11 blog. Authors: Martin Fenner, Stephan Druskat, Neil\nChue Hong, Daniel S. Katz, Morane Gruenpeter, Arfon Smith, Tom Morell\nand Robert Haines*  \n","doi":"https://doi.org/10.53731/r9531p1-97aq74v-ag78v","guid":"62d42bbd41e317003df48f14","id":"1aa440e2-fd22-4dbe-b144-b3d7daa29043","image":"https://blog.front-matter.io/content/images/2022/07/github-citation-screenshot.png","indexed_at":1,"language":"en","published_at":1629824244,"reference":[],"relationships":[],"summary":"On August 19, GitHub announced software citation support in GitHub repositories. Citation information provided by users (using a CITATION.cff YAML file in the root directory of the default branch) is parsed and made available as bibtex file or formatted citation, currently supporting the APA citation style.\n","tags":["News"],"title":"A step forward for software citation: GitHub's enhanced software citation support","updated_at":1660590314,"url":"https://blog.front-matter.io/posts/step-forward-for-software-citation"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/editorial-by-more-than-200-call-for-emergency-action-to-limit-global-temperature-increases-restore-biodiversity-and-protect-health","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"More than 200 health journals today published an editorial calling for\nurgent action to keep average global temperature increases below 1.5\u00b0C,\nhalt the destruction of nature, and protect health. The editorial can be\nread for example [here](https://doi.org/10.1136/bmj.n1734) (published\nunder a CC-BY Open Access license), and the full list of participating\njournals can be found\n[here](https://www.bmj.com/content/full-list-authors-and-signatories-climate-emergency-editorial-september-2021).\n\n> The greatest threat to global public health is the continued failure\n> of world leaders to keep the global temperature rise below 1.5\u00b0C and\n> to restore nature. Urgent, society-wide changes must be made and will\n> lead to a fairer and healthier world. We, as editors of health\n> journals, call for governments and other leaders to act, marking 2021\n> as the year that the world finally changes course.\n\nThe COVID Pandemic is currently taking up all our attention. But we\nshould not loose time addressing the environmental crisis triggered by\nclimate change, and having a significant negative impact on global\nhealth, both via direct effects of global heating and extreme weather\nevents, and indirectly via reduced food production.\n\nThis joint editorial by more than 200 health journals worldwide is yet\nanother clear sign of the urgency of the situation, and the need for\naction. And we should not forget that health is just one aspect of how\nthe climate crisis is seriously affecting all our lives, in particular\nthose most vulnerable.\n\nThe editorial makes a strong point that the time for action is now, and\nthat wealthy nations must do much more, and much faster. It is also an\nopportunity to think about what we as individuals can do, whether it is\nabout re-evaluating our individual carbon footprint, thinking about what\npolitical parties we support (Germany where I live for example has a\nfederal election in three weeks), and whether the organizations we work\nfor can do more to slow down global warming.\n","doi":"https://doi.org/10.53731/r9nqx6h-97aq74v-ag7bw","guid":"62d42bbd41e317003df48f15","id":"a251a725-2903-48bf-9fec-5a5dda8fde6b","image":"https://blog.front-matter.io/content/images/2022/07/photo-1578403881967-084f9885be74.jpeg","indexed_at":1,"language":"en","published_at":1630914605,"reference":[],"relationships":[],"summary":"More than 200 health journals today published an editorial calling for urgent action to keep average global temperature increases below 1.5\u00b0C, halt the destruction of nature, and protect health.\n","tags":["News"],"title":"Editorial by more than 200 health journals: Call for emergency action to limit global temperature increases, restore biodiversity, and protect health","updated_at":1660590292,"url":"https://blog.front-matter.io/posts/editorial-by-more-than-200-call-for-emergency-action-to-limit-global-temperature-increases-restore-biodiversity-and-protect-health"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/on-readability","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"> **Readability** is the ease with which a reader can understand a\n> written text. --\n> [Wikipedia](https://en.wikipedia.org/wiki/Readability)\n\nReadability is obviously important for any kind of scholarly\ncommunication, from writing papers to blog posts. I have written about\nscientific writing before (e.g. [Scientific writers can help publish\ngood papers](https://doi.org/10.53731/r294649-6f79289-8cw9n), [Books\nabout Science Writing](https://doi.org/10.53731/r294649-6f79289-8cw8s),\n[Do you know the Flesch score of your\npapers?](https://doi.org/10.53731/https://doi.org/10.53731/r294649-6f79289-8cw92)),\nand writing scholarly content that is understandable is something that\ncan be taught and learned.\n\nSomething simple that can help is providing feedback in the form of\nreadability scores, generated automatically with formulas that for\nexample use the average sentence length (*ASL*) and average number of\nsyllables per word (*ASW*), as in the Flesch Reading Ease score first\npublished in 1948:\n\n> *206.835 - 1.015 x ASL - 84.6 x ASW*\n\nThe score can be anywhere between 0 and 100, with a higher scores\nmeaning better readability.\n\n| **Score\u00a0** | **Notes**                                                              |\n|------------|------------------------------------------------------------------------|\n| 90-100     | very easy to read, easily understood by an average 11-year-old student |\n| 80-90      | easy to read                                                           |\n| 70-80      | fairly easy to read                                                    |\n| 60-70      | easily understood by 13- to 15-year-old students                       |\n| 50-60      | fairly difficult to read                                               |\n| 30-50      | difficult to read, best understood by college graduates                |\n| 0-30       | very difficult to read, best understood by university graduates        |\n\nThe Flesch Reading Ease score has been researched extensively, with a\nparticular influence on journalism, showing that higher scores can\nincrease readership.\n\nMany writing tools have the Flesch Reading Ease score built in,\nincluding [Microsoft\nWord](https://support.microsoft.com/en-us/office/get-your-document-s-readability-and-level-statistics-85b4969e-e80a-4777-8dd3-f7fc3c8b3fd2)\nand [Grammerly](https://www.grammarly.com/blog/readability-scores/). And\nthere are open source libraries in a number of languages. This week the\nFront Matter blog started calculating and displaying the Flesch Reading\nEase score (*readability score* for short) using the\n[readability-cyr](https://www.npmjs.com/package/readability-cyr)\njavascript library. You can see the score in the byline at the top of\nindividual posts, or in listings of blog posts.\n\n<figure class=\"kg-card kg-image-card\">\n<img\nsrc=\"https://blog.front-matter.io/content/images/2022/07/Bildschirmfoto-2021-11-03-um-17.25.18.png\"\nclass=\"kg-image\" loading=\"lazy\" width=\"547\" height=\"221\" />\n</figure>\n\nI will do a more systematic analysis at some point (the numbers are in\nour database index), for now I will highlight the Front Matter posts\nwith the highest and lowest readability scores:\n\n- [Having an impact (factor) and other stories from Gregory\n  Petsko](https://doi.org/10.53731/r294649-6f79289-8cw85) 72.3\n- [More Gobbledygook at PLoS\n  Blogs](https://doi.org/10.53731/r294649-6f79289-8cw80) 71.3\n- [Researchers' reasons for publishing their\n  work](https://doi.org/10.53731/r294649-6f79289-8cw7s) 70.5\n- \\...\n- [We need your feedback: Aligning the CodeMeta vocabulary for\n  scientific software with\n  schema.org](https://doi.org/10.53731/r79r1nh-97aq74v-ag4k9) 17.0\n- [German Genetics Society Meeting 2009: Session\n  VI](https://doi.org/10.53731/r294649-6f79289-8cwbs) 14.6\n- [Neelie Kroes talks Open\n  Science](https://doi.org/10.53731/294649-6f79289-8cw2c) 12.3\n\nMost posts have a score between 30 and 50, lower than most newspapers\nand novels, but higher than highly specialized scientific papers. Blog\nposts that have a score much higher or lower are particularly\ninteresting, as we might learn something that can improve our writing.\nBut take the readability score with a grain of salt, as other factors\nnot really in our control might influence the score.\n\n*P.S. This post has a readability score of 52.4.*\n","doi":"https://doi.org/10.53731/rc2nchn-tzg61kj-7ztfa","guid":"62d42bbd41e317003df48f1a","id":"89f1a126-0b42-44ea-b09e-fe55c6d0672d","image":"https://blog.front-matter.io/content/images/2022/07/photo-1491309055486-24ae511c15c7.jpeg","indexed_at":1,"language":"en","published_at":1635958397,"reference":[],"relationships":[],"summary":"<strong>\n Readability\n</strong>\nis the ease with which a reader can understand a written text. \u2013 Wikipedia Readability is obviously important for any kind of scholarly communication, from writing papers to blog posts.\n","tags":["Feature"],"title":"On Readability","updated_at":1660589901,"url":"https://blog.front-matter.io/posts/on-readability"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/dryad-interview-jen-gibson","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"In October Jen Gibson started as the new Executive Director for the\nDryad Data Repository. I used the opportunity to ask Jen a few questions\nabout Dryad, challenges with data sharing, and ideas about moving Dryad\nforward. I was particularly interested in the interview as I served on\nthe Dryad Board of Directors from 2013 to 2016. In fact, one post on\nthis blog is about a presentation I gave in 2013 ([Metrics and\nattribution: my thoughts for the panel at the ORCID-Dryad symposium on\nresearch attribution](https://doi.org/10.53731/r294649-6f79289-8cw1x)).\n\n### 1. Can you describe what Dryad is?\n\nDryad is an open data publishing platform and community committed to the\nopen availability and routine re-use of all research data. We're a\ngeneralist, curated data repository -- working with researchers across\ndisciplines to assemble details about their work and their data to\nincrease its discoverability and use by others. We're a non-profit\ninitiative working in partnership with other systems and communities\nworking to advance open research.\n\n### 2. Are there data that should not be submitted to Dryad?\n\nDryad is designed to support openly accessible and fully re-usable data,\nand publishes under a Creative Commons Public Domain License (CC0). So,\nwe're not able to publish data with incompatible licensing terms. We\nalso don't accept datasets that contain personally identifiable human\nsubject information or specific locations for endangered species -- but\nour team of curators will work with researchers to see if the data can\nbe made appropriate for sharing.\n\n### 3. Are there limits in the number or size of files in a data submission?\n\nWe can accept up to 300GB per dataset and thousands of files, but\ncurators are looking for the most accessible file types and downloads to\nsupport re-use. So, we ask that files be small and zipped when possible.\nUsers with files larger than 300GB are asked simply to contact us to\ncoordinate.\n\n### 4. Does Dryad also accept software submissions?\n\nNo, Dryad only publishes data. So, we've partnered with\n[Zenodo](https://zenodo.org) so that users can load software and other\nsupplementary information at the same time that they load data to Dryad.\nSoftware can then be made available under a different, more appropriate\nlicense and be given its own citation, but is also linked from the data\npublication at Dryad.\n\n### 5. Does a data submission to Dryad cost money?\n\nYes. Often the cost to researchers is covered or discounted through an\narrangement with their institution, publisher, or funder. Where there is\nnot yet an arrangement in place, the submitting researcher is asked to\npay \\$120 -- with overage fees if the data is larger than 300GB. Waivers\nare, of course, available. Publication fees, memberships, and\npartnerships with institutions, publishers and funders help cover our\ncosts for data curation and long-term preservation.\n\n### 6. What are the main challenges for authors?\n\nThere are so many challenges for researchers with respect to open\nsharing of data -- and they're different in every discipline. There are\nbehaviour changes, and workflow changes and culture changes to overcome\n-- although several disciplines have carved a path, including astronomy\nand ecology. I hope that the open data-sharing around COVID will help\ninspire more people to follow suit.\n\nDryad helps to overcome these challenges, of course. We help first of\nall by helping to make it *possible* to share data properly -- openly,\nwith a CC0 license, and second by making it *easy* to share data through\nour friendly user interface and our integrations with publishers and\npartners such as Zenodo. (With the terms 'possible, easy, rewarding and\nnormative,' I'm invoking Brian Nosek's [Strategy for Culture\nChange](https://www.cos.io/blog/strategy-for-culture-change)).\n\nWe're helping to make data sharing *rewarding* by standardising usage\nmetrics (through [Make Data Count](https://makedatacount.org/) -- an\nimportant, community-led initiative to develop metrics for open research\ndata assessment) and encouraging citation, though these are just a\ncouple of the pieces needed to put data and data sharing at the centre\nof research assessment.\n\nFinally, what I'm very much looking forward to doing with Dryad is\nsupporting and building communities that share and re-use data to make\nthis practice *normative*. Connecting people with people -- and people\nwith data -- is key in nurturing and normalising the regular exchange\nand re-use of data.\n\n### 7. Why should authors submit their data to Dryad?\n\nAuthors whose communities don't already rely on a domain repository for\ndata, such as WormBase or the Protein Data Bank, should publish their\ndata with Dryad because:\n\n- Our curation service increases the quality and discoverability of new\n  data, by ensuring key descriptive information (metadata) is available\n  alongside the data itself\n- Our curation service increases the integrity of new data, by ensuring\n  it's readable and usable by other users\n- We put data in context, with links to publications, software,\n  institutions, funders and more\n- Data published in Dryad is citable and accessible via a persistent DOI\n- As a non-profit and open-source initiative, our values are closely\n  aligned with the research community\n- It's easy, and affordable\n\n### 8. How can authors give feedback, e.g. to report problems or request features?\n\nWe are an open source project and our work is driven by researchers\\'\nneeds. Get in touch with the help desk to discuss feature needs with our\nproduct team or leave a ticket on our public [Github product\nboard](https://github.com/CDL-Dryad/dryad-product-roadmap/projects/1).\n\n### 9. What did you do before starting to work for Dryad?\n\nI've worked in open research since 2005, when I joined\n[SPARC](https://sparcopen.org/) -- the Scholarly Publishing and Academic\nResources Coalition -- to work on open-access advocacy and policy\nefforts. Immediately before Dryad I was a founding member of the team\nfor eLife -- the open-access journal for biology and medicine and\ninitiative from three of the largest, most prestigious, private\nbiomedical research funders to put science publishing back in the hands\nof science. I'd say my main contributions so far have been in building\ncommunities (among librarians, open science advocates, students,\nearly-career or late-stage researchers, and others), advocacy (for open\nresearch practice at different levels of practice and policy), and\nadoption strategies (for researchers in particular).\n\n### 10. Do you want to talk about future plans for Dryad?\n\nAbsolutely. Beyond my near-term objectives for optimising operations, I\nexpect us to be:\n\n- Leveraging support from institutions and expanding our membership\n  program.\n- Working with our publisher partners to attract as much data as\n  possible.\n- More actively diversifying our profile -- specifically reaching out to\n  different geographic and disciplinary communities.\n- Expanding our roadmap for modeling data publishing into the future,\n  building on our progress over the last couple of years.\n\nLonger term, I'm enthusiastic about the potential for pushing data to\nthe forefront of discovery, and taking steps to facilitate re-use and\nextend credit. Like Make Data Count, Dryad is committed to making data a\nfirst-class citizen in research and research assessment, and I\\'ll be\nreally pleased if we're able to help properly reward researchers for\ntheir data publications. We're going to need to, to really accelerate\ndiscovery and build that open, global network for the exchange of\nresearch objects.\n","doi":"https://doi.org/10.53731/rceh7pn-tzg61kj-7zv63","guid":"62d42bbd41e317003df48f1c","id":"a05a6635-3316-40c7-9a43-3d331032b9af","image":"https://blog.front-matter.io/content/images/2022/07/jgibson.png","indexed_at":1,"language":"en","published_at":1636973522,"reference":[],"relationships":[],"summary":"In October Jen Gibson started as the new Executive Director for the Dryad Data Repository. I used the opportunity to ask Jen a few questions about Dryad, challenges with data sharing, and ideas about moving Dryad forward. I was particularly interested in the interview as I served on the Dryad Board of Directors from 2013 to 2016.\n","tags":["Interview"],"title":"Dryad: Interview with Jen Gibson","updated_at":1660589787,"url":"https://blog.front-matter.io/posts/dryad-interview-jen-gibson"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/book-review-bad-science-by-ben-goldacre","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"**Ben Goldacre: Bad Science. Published September 2008 by Fourth Estate Ltd. Paperback, 352 pages, ISBN 0007240198**\n\n[Ben Goldacre](https://web.archive.org/web/20150922174108/http://network.nature.com/people/UA495AB88/profile), blogger of the **Bad Science**\\[1\\] column in the Guardian newspaper, in September published a book based on material from his blog. Just like the newspaper column, the book is primarily intended for a general audience rather than the trained scientist or medical doctor. And it helps to live in Great Britain, where most of the examples of bad science given in the book happened.\n\nBut the book is not really a collection of scary and sometimes hilarious bad science stories. Ben Goldacre takes these examples and tries to teach the reader evidence-based medicine. Evidence-based medicine^[2](https://web.archive.org/web/20150922174108/http://blogs.plos.org/mfenner/2008/10/24/book_review_bad_science_by_ben_goldacre/#fn2)^ or EBM uses the scientific method to make decisions about the care of individual patients. It is funny how many people -- including medical doctors -- throw away all the research evidence that is available and instead rely on personal experiences. And evidence-based medicine helps to distinguish good research from bad research, e.g. by stressing the importance of randomized controlled trials. The book was very stimulating reading for me, including the chapter about the placebo effect^[3](https://web.archive.org/web/20150922174108/http://blogs.plos.org/mfenner/2008/10/24/book_review_bad_science_by_ben_goldacre/#fn3)^. But I\\'m a medical doctor, and I don\\'t know whether Ben Goldacre succeeded in every reader with this teaching mission. Even so, most readers will look much more carefully at science stories in the media after finishing the book. And that is a good thing.\n\nMore reviews of the book can be found in these fine publications:\n\n-   [Daily Telegraph](https://web.archive.org/web/20150922174108/http://www.telegraph.co.uk/arts/main.jhtml?xml=%2Farts%2F2008%2F09%2F27%2Fbogol127.xml)\n-   [TimeOut London](https://web.archive.org/web/20150922174108/http://www.newscientist.com/channel/opinion/mg20026772.600-review-ibad-sciencei-by-ben-goldacre.html)\n-   [British Medical Journal](https://web.archive.org/web/20150922174108/http://dx.doi.org/10.1136/bmj.a1856)\n-   [New Scientist](https://web.archive.org/web/20150922174108/http://www.newscientist.com/channel/opinion/mg20026772.600-review-ibad-sciencei-by-ben-goldacre.html)\n\nfn1. [Bad Science](https://web.archive.org/web/20150922174108/http://www.badscience.net/)\n\nfn2. [Evidence-based Medicine Wikipedia entry](https://web.archive.org/web/20150922174108/http://en.wikipedia.org/wiki/Evidence-based_medicine)\n\nfn3. [Placebo programme on BBC Radio 4](https://web.archive.org/web/20150922174108/http://www.badscience.net/2008/08/my-placebo-programme-on-bbc-radio-4/)\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cwba","guid":"62d42bbd41e317003df48ec5","id":"d3a75815-caae-47d4-9903-8a8a781b3ea2","image":"https://blog.front-matter.io/content/images/2022/08/51YX1oB8D-L._SX328_BO1-204-203-200_.jpg","indexed_at":1,"language":"en","published_at":1224806400,"reference":[],"relationships":[],"summary":"<em>\n <em>\n  Ben Goldacre: Bad Science. Published September 2008 by Fourth Estate Ltd. Paperback, 352 pages, ISBN 0007240198\n </em>\n</em>\nBen Goldacre, blogger of the\n<em>\n <em>\n  Bad Science\n </em>\n</em>\n[1] column in the Guardian newspaper, in September published a book based on material from his blog. Just like the newspaper column, the book is primarily intended for a general audience rather than the trained scientist or medical doctor.\n","tags":["Book Review"],"title":"Book Review: Bad Science by Ben Goldacre","updated_at":1660575516,"url":"https://blog.front-matter.io/posts/book-review-bad-science-by-ben-goldacre"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/someone-who-should-have-won-a-nobel-prize","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"The 2008 Nobel Prizes will be announced next week, starting with the Nobel Prize in Physiology or Medicine on Monday. There will be a live webcast on Monday at 9:30 AM GMT for those interested^[1](https://web.archive.org/web/20150922174101/http://blogs.plos.org/mfenner/2008/10/05/someone_who_should_have_won_a_nobel_prize/#fn1)^. As every year just before the announcement, speculation about this year\\'s winners is in full swing. [M. William Lensch](https://web.archive.org/web/20150922174101/http://network.nature.com/people/U113B3294/profile), here on Nature Network correctly predicted last year\\'s winners^[2](https://web.archive.org/web/20150922174101/http://blogs.plos.org/mfenner/2008/10/05/someone_who_should_have_won_a_nobel_prize/#fn2)^, and this year he is trying it again^[3](https://web.archive.org/web/20150922174101/http://blogs.plos.org/mfenner/2008/10/05/someone_who_should_have_won_a_nobel_prize/#fn3)^. Thomson Reuters uses scientific methods for their predictions (including citation counts over 30 years and other awards), and they nominate^[4](https://web.archive.org/web/20150922174101/http://blogs.plos.org/mfenner/2008/10/05/someone_who_should_have_won_a_nobel_prize/#fn4)^ these three discoveries:\n\n-   Toll-like receptors and innate immunity\n-   the role of microRNAs in gene regulation\n-   the development of meta-analysis and application to clinical medicine\n\nThere will be of course many more blog posts about the Nobel Prizes this week, both on Nature Network^[5](https://web.archive.org/web/20150922174101/http://blogs.plos.org/mfenner/2008/10/05/someone_who_should_have_won_a_nobel_prize/#fn5)^ and elsewhere. But in this blog post I want to talk about someone who will not win a Nobel Prize, but who would very much have deserved to do so. I am talking about **Judah Folkman** who invented the field of angiogenesis research and worked on it for more than 35 years. But the prize can only be awarded to living people, and Judah Folkman passed away this January. A **Nature** obiturary^[6](https://web.archive.org/web/20150922174101/http://blogs.plos.org/mfenner/2008/10/05/someone_who_should_have_won_a_nobel_prize/#fn6)^ and recent **PNAS** article^[7](https://web.archive.org/web/20150922174101/http://blogs.plos.org/mfenner/2008/10/05/someone_who_should_have_won_a_nobel_prize/#fn7)^ summarize his life and scientific achievements. Here I want to explain my personal reasons why I think he would have deserved a Nobel Prize.\n\n### Angiogenesis reseach is hypothesis-driven\n\nFolkman first published his concept of tumor angiogenesis in 1971^[8](https://web.archive.org/web/20150922174101/http://blogs.plos.org/mfenner/2008/10/05/someone_who_should_have_won_a_nobel_prize/#fn8)^. He postulated that the recruitment of dedicated blood vessels is essential to tumor growth. It took 25 years of experimental work by Folkman and others until the concept of angiogenesis became widely accepted. Interestingly, another hypothesis that changed our understanding of cancer biology was also published that year: Knudson\\'s two-hit hypothesis of tumor suppressor genes^[9](https://web.archive.org/web/20150922174101/http://blogs.plos.org/mfenner/2008/10/05/someone_who_should_have_won_a_nobel_prize/#fn9)^. Judah Folkman often said **Science goes where you imagine it.** A lot of today\\'s research is not at all about proving an important hypothesis, and some people even mistakenly propose that concepts are no longer needed^[10](https://web.archive.org/web/20150922174101/http://blogs.plos.org/mfenner/2008/10/05/someone_who_should_have_won_a_nobel_prize/#fn10)^.\n\n### Angiogenesis research is full of failures\n\nThe story of angiogenesis research is a very complicated one. Not only took it Judah Folkman a long time and a lot of subbornness before his views became accepted, but there were many failures and setbacks along the way. Some scientific breakthroughs were an instant success, e.g. RNA interference awarded a Nobel Prize in 2006^[11](https://web.archive.org/web/20150922174101/http://blogs.plos.org/mfenner/2008/10/05/someone_who_should_have_won_a_nobel_prize/#fn11)^, but most research is just very complicated, including medical research. A September **Science** article about medical interventions found a median interval of 24 years between first description and earliest highly cited article^[12](https://web.archive.org/web/20150922174101/http://blogs.plos.org/mfenner/2008/10/05/someone_who_should_have_won_a_nobel_prize/#fn12)^.\n\n### Angiogenesis research has had an impact\n\nThe number of Pubmed citations is one good indicator for the research activity in a given field. Pubmed today lists 37,482 publications about angiogenesis, including 19985 publications from the last five years. This compares favorably to research about telomerase (8040 publications), and microRNA (3541 publications), two areas of research mentioned in the discussions about potential 2008 winners. Impact can be also measured in other ways, but it is clear that the concept of angiogenesis has not only profoundly changed cancer research, but is also important in many other diseases, as summarized in a 2005 **Nature** article[^13^](https://web.archive.org/web/20150922174101/http://blogs.plos.org/mfenner/2008/10/05/someone_who_should_have_won_a_nobel_prize/#fn13).\n\n### Angiogenesis research is medical research\n\nAs the name already suggests, the Nobel Prize for Physiology or Medicine is actually two prizes in one. It is a Nobel Prize in Biology, awarded for major achievements in our understanding of all aspects of biology. But is also a Nobel Prize in Medicine, where major advances in our understanding of human disease are awarded. The 2005 Nobel Prize to Barry Marshall and Robin Warren for the role of Helicobacter pylori in gastric disease^[14](https://web.archive.org/web/20150922174101/http://blogs.plos.org/mfenner/2008/10/05/someone_who_should_have_won_a_nobel_prize/#fn14)^ is a good recent example of the latter category.\\\nThe research by Folkman and others has changed the way we think about cancer, but also the way we treat cancer. Each year, more than one million patients with colon, lung or breast cancer are treated with the anti-VEGF antibody bevacizumab. Other drugs targeting angiogenesis are either already in clinical use (e.g. sunitinib for renal cancer) or in development. This makes angiogenesis research a prime example for translational research. I very much agree with the views expressed in a set of articles in **Nature** this June^[15](https://web.archive.org/web/20150922174101/http://blogs.plos.org/mfenner/2008/10/05/someone_who_should_have_won_a_nobel_prize/#fn15)^, that more has to be done to connect our much better understanding of fundamental biological processes to the way we diagnose, prevent and treat diseases. And a Nobel Prize would be a strong signal.\n\nfn1. [Announcement of the Nobel Prize in Physiology or Medicine](https://web.archive.org/web/20150922174101/http://nobelprize.org/prize_announcements/medicine/index.html)\n\nfn2. [Nobel Redux](https://web.archive.org/web/20150922174101/http://network.nature.com/people/U113B3294/blog/2007/09/15/nobel-redux)\n\nfn3. [Nobels 2008](https://web.archive.org/web/20150922174101/http://network.nature.com/people/U113B3294/blog/2008/10/03/nobels-2008)\n\nfn4. [2008 Nobel Predictions](https://web.archive.org/web/20150922174101/http://scientific.thomsonreuters.com/nobel/)\n\nfn5. [Collective Blogging -- Nobel Prize announcements](https://web.archive.org/web/20150922174101/http://network.nature.com/groups/nnbloggername/forum/topics/3062)\n\nfn6. **Nature** 2008 [doi:10.1038/451781a](https://web.archive.org/web/20150922174101/http://dx.doi.org/10.1038/451781a)\n\nfn7. **PNAS** 2008 [doi:10.1073/pnas.0806582105](https://web.archive.org/web/20150922174101/http://dx.doi.org/10.1073/pnas.0806582105)\n\nfn8. **N Engl J Med** 1971 [Tumor angiogenesis: therapeutic implications](https://web.archive.org/web/20150922174101/http://www.ncbi.nlm.nih.gov/pubmed/4938153?dopt=abstract)\n\nfn9. **PNAS** 1971 [Mutation and Cancer: Statistical Study of Retinoblastoma](https://web.archive.org/web/20150922174101/http://www.pnas.org/content/68/4/820)\n\nfn10. [The End of Theory: The Data Deluge Makes the Scientific Method Obsolete](https://web.archive.org/web/20150922174101/http://www.wired.com/science/discoveries/magazine/16-07/pb_theory)\n\nfn11. [Nobel Prize in Physiology or Medicine 2006](https://web.archive.org/web/20150922174101/http://nobelprize.org/nobel_prizes/medicine/laureates/2006/index.html)\n\nfn12. **Science** 2008 [doi:10.1126/science.1160622](https://web.archive.org/web/20150922174101/http://dx.doi.org/10.1126/science.1160622)\n\nfn13. **Nature** 2005 [doi:10.1038/nature04478](https://web.archive.org/web/20150922174101/http://blogs.plos.org/dx.doi/org/10.1038/nature04478)\n\nfn14. [Nobel Prize in Physiology or Medicine 2005](https://web.archive.org/web/20150922174101/http://nobelprize.org/nobel_prizes/medicine/laureates/2005/index.html)\n\nfn15. **Nature** 2008 [doi:10.1038/453839a](https://web.archive.org/web/20150922174101/http://dx.doi/org/10.1038/453839a)\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cwb8","guid":"62d42bbd41e317003df48ec3","id":"d0436102-9f63-4eb5-8a28-d6ae68ce8651","image":null,"indexed_at":1,"language":"en","published_at":1223164800,"reference":[],"relationships":[],"summary":"The 2008 Nobel Prizes will be announced next week, starting with the Nobel Prize in Physiology or Medicine on Monday. There will be a live webcast on Monday at 9:30 AM GMT for those interested\n<sup>\n 1\n</sup>\n. As every year just before the announcement, speculation about this year's winners is in full swing. M. William Lensch, here on Nature Network correctly predicted last year's winners\n<sup>\n 2\n</sup>\n, and this year he is trying it again\n<sup>\n 3\n</sup>\n.\n","tags":["Feature"],"title":"Someone who should have won a Nobel Prize","updated_at":1660575462,"url":"https://blog.front-matter.io/posts/someone-who-should-have-won-a-nobel-prize"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/interview-with-alexander-griekspoor","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"Good software solves a problem. When one journal after another switched to PDF as electronic document format, and journals started to appear only in electronic form, storing papers as printouts in folders became impractical. But the PDF files will soon start to clutter the hard drive, despite efforts to organize them by topic, year or author. At least for Macintosh users, [Papers](https://web.archive.org/web/20150924053037/http://mekentosj.com/papers/) is one practical and elegant solution to this problem. I talked with Papers author [Alexander Griekspoor](https://web.archive.org/web/20150924053037/http://network.nature.com/people/mekentosj/profile) not only about Papers, but also about his career switch from cell biologist to software developer.\n\n### 1. Can you describe what Papers is and does? {#1-can-you-describe-what-papers-is-and-does}\n\nThe tag-line we coined for Papers is \"your personal library of science\", a play-of-words on the well-known PLoS acronym. And this program for the Mac provides exactly that, it helps you manage and organize your personal scientific literature library. It provides a complete workflow for finding new articles using built-in search engines, browsing the publisher's website using the built-in Safari web browser, downloading, archiving and renaming the PDF files, and organizing and indexing these articles. Finally, it allows you to easily read the papers and share them with colleagues.\n\n### 2. How is Papers different from other Macintosh bibliography tools? {#2-how-is-papers-different-from-other-macintosh-bibliography-tools}\n\nPapers distinguishes itself from other bibliography tools in that it is not a typical reference manager to begin with. The Mac has had several good reference management applications for a long time already, but when I created Papers I wanted to make a different application, one that didn't exist yet and one there was clearly a need for, one to manage all those PDF files that people were downloading. In the years before, the publishing industry had introduced PDFs as a replacement for sending articles by regular mail and it was a great success in that it made access to the literature much easier.\n\nStill, their support of the researcher ended the moment you pressed the download button. Your web browser would save some cryptically named PDF file on your hard disk, which soon quickly filled up with dozens of these files. So whereas PDFs were introduced to save us from the messy file cabinets with hundreds of paper copies of your articles, we were now facing the digital equivalent of that on our desktop.\n\nThat was when it struck me that Apple had already solved this issue for MP3 files a few years earlier, iTunes had allowed us to stop bothering about managing MP3s and instead allowed us to focus on the songs. Papers was designed to do exactly the same when it comes to managing PDFs and instead lets us focus on the articles. Obviously, now the have seen how things can be different you notice that most reference managers on the Mac have started to play catch up, and are introducing PDF management features as well. Still, for us this has always been the key element and is just the start of many exciting things to come.\n\n### 3. What recommendations do you give Windows and Linux users? {#3-what-recommendations-do-you-give-windows-and-linux-users}\n\nThe most obvious answer is to buy a Mac of course \ud83d\ude09 But more seriously, at the moment I'm not aware of a program on Windows or Linux that offers the same feature set and user experience that Papers offers. But like the other reference management tools on the Mac there's a similar trend of adopting\\\nthese kind of features in bibliography tools on Linux and Windows as well.\n\n### 4. What did you do before working on Papers? {#4-what-did-you-do-before-working-on-papers}\n\nPerhaps surprisingly I'm a cell biologist of training and not a computer scientists or IT person. I studied medical biology at the Free University in Amsterdam and ended up doing my PhD at the Netherlands Cancer Institute in Amsterdam as well, where I studied the immune system using [live-cell fluorescence microscopy](https://web.archive.org/web/20150924053037/http://dx.doi.org/10.1016/j.mib.2005.04.007).\n\n### 5. How did you get involved in writing Macintosh software? {#5-how-did-you-get-involved-in-writing-macintosh-software}\n\nIt all started out as a hobby driven by a long-time interest for both design and technology. I was introduced to the Mac when my dad brought home one of these \"portable\" classic Macs when I was about 14 years old, and almost immediately I started experimenting with Photoshop et al. During university I earned some money in my spare time by designing and building websites, but it wasn't until about the time I started by PhD that Apple introduced Mac OS X and with it came the free set of developer tools that finally made it easy enough for someone without the classical IT background to start building his/her own Mac applications. Together with my best friend and fellow PhD student Tom Groothuis we started building a number of tools for molecular biologists ([EnzymeX](https://web.archive.org/web/20150924053037/http://mekentosj.com/enzymex/)), which we distributed for free under our \"mek en tosj\" monicker. It didn't take long before the hobby started to get out of hand as the popularity of our programs started to soar.\n\n### 6. You talked about your postdoc choice in a 2007 [Nature Jobs article](https://web.archive.org/web/20150924053037/http://dx.doi.org/10.1038/nj7130-948b). What made you decide to move from postdoc to company founder? {#6-you-talked-about-your-postdoc-choice-in-a-2007-nature-jobs-article-what-made-you-decide-to-move-from-postdoc-to-company-founder}\n\nWhen the time came to pick a postdoc I knew one thing for sure, the programming was something I was so passionate about that it should be part of the postdoc rather than a spare time project. That's why I picked the text mining group at the [European Bioinformatics Institute](https://web.archive.org/web/20150924053037/http://www.ebi.ac.uk/) in Cambridge UK, also driven by an interest in the changes that were/are ongoing in the scientific publishing industry. I applied for a two year EU Marie Curie fellowship which I was fortunate to get, however it would take a few months between the end of my PhD and all the bureaucracy before I could get started in Cambridge. This was when I decided to build Papers. I got the idea for this \"iTunes for PDF files\" already two years earlier, but never had the time to do it. I did tell everybody I knew about it, but no one had done it and now finally I had some spare time on my hands.\n\nThe first beta of the program was released right at the time I started my postdoc and it was a success right from the start. In fact it was so successful and offered so many opportunities that it was soon difficult to focus on my actual postdoc and after a year I realized that this was the thing I was really passionate about and was what I wanted to concentrate fully on. That was when I decided to quit my job and become the company founder of Mekentosj Inc. \ud83d\ude09\n\n### 7. Do you want to talk about future plans for Papers? {#7-do-you-want-to-talk-about-future-plans-for-papers}\n\nIt's still to early to talk in many details but like I said, for us the current version of Papers has always been the foundation on which we can build many exciting things we envision. We're working hard on the next major release of Papers which will definitely be a big step up. And obviously the introduction of the iPhone is something that also brings very exciting possibilities, so many things to look forward to!\n\n**Alex, thanks a lot for this interview. For more information, you can read an [interview](https://web.archive.org/web/20150924053037/http://www.macresearch.org/interview_with_alexander_griekspoor_from_mekentosj) from two years ago, or visit the [Mekentosj Papers Nature Network Forum](https://web.archive.org/web/20150924053037/http://network.nature.com/groups/papers/forum/topics). And please tell me how you manage all these PDF files and how you use these references when writing a paper yourself.**\n","doi":"https://doi.org/10.53731/fy8ppqw-wctn03p","guid":"62d42bbd41e317003df48ec2","id":"091811b4-ac71-4b8b-b3f1-6715c00c0aa7","image":"https://blog.front-matter.io/content/images/2022/08/StoryPic7.jpg","indexed_at":1,"language":"en","published_at":1222992000,"reference":[],"relationships":[],"summary":"Good software solves a problem. When one journal after another switched to PDF as electronic document format, and journals started to appear only in electronic form, storing papers as printouts in folders became impractical. But the PDF files will soon start to clutter the hard drive, despite efforts to organize them by topic, year or author. At least for Macintosh users, Papers is one practical and elegant solution to this problem.\n","tags":["Interview"],"title":"Papers: Interview with Alexander Griekspoor","updated_at":1660575430,"url":"https://blog.front-matter.io/posts/interview-with-alexander-griekspoor"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/interview-with-victor-henning-from-mendeley","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"In the last few months we have seen an ever increasing number of new social networking (Web 2.0) sites for scientists. Good Web 2.0 tools for scientists primarily try to solve a problem. But by adding a social aspect, they will gain useful features that would otherwise not be possible. [**Eva Amsen**](https://web.archive.org/web/20080920001317/http://network.nature.com/profile/U27CE62BB) has recently written a great blog post about this^[**1**](https://web.archive.org/web/20080920001317/http://network.nature.com/people/mfenner/blog/2008/09/05/interview-with-victor-henning-from-mendeley#fn1)^. Many of these new services have overlapping functions, e.g. almost all of them allow the user to maintain a list of contacts. This raises two questions:\n\n1.  Which of these sites has (or have) the features that I'm most interested in?\n2.  Do any of these sites work with the commonly used desktop tools and with each other, so that I don't have to maintain duplicate information, e.g. the list of my publications?\n\n[**Cameron Neylon**](https://web.archive.org/web/20080920001317/http://network.nature.com/profile/U42E63119) in August posted an open letter to the developers of these sites^[**2**](https://web.archive.org/web/20080920001317/http://network.nature.com/people/mfenner/blog/2008/09/05/interview-with-victor-henning-from-mendeley#fn2)^ and also started a comprehensive list^[**3**](https://web.archive.org/web/20080920001317/http://network.nature.com/people/mfenner/blog/2008/09/05/interview-with-victor-henning-from-mendeley#fn3)^. [**Gerry McKiernan**](https://web.archive.org/web/20080920001317/http://network.nature.com/profile/http-network-nature-comprofilegerrymck) collects information about social networking sites for scientists on his SciTechNet blog^[**4**](https://web.archive.org/web/20080920001317/http://network.nature.com/people/mfenner/blog/2008/09/05/interview-with-victor-henning-from-mendeley#fn4)^. Mendeley^[**5**](https://web.archive.org/web/20080920001317/http://network.nature.com/people/mfenner/blog/2008/09/05/interview-with-victor-henning-from-mendeley#fn5)^ is one of these new Web 2.0 sites for scientists (they launched in August), and I spoke with [**Victor Henning**](https://web.archive.org/web/20080920001317/http://network.nature.com/profile/U4C4A58A2%5B6), one of the founders of Mendeley, about it.\n\n**1. Can you describe what Mendeley is and does?**\\\nMendeley is actually two things: Mendeley Desktop and Mendeley Web. Mendeley Desktop is free academic software (available for Windows, Mac and Linux) for managing & sharing research papers. Mendeley Web lets you back up your research papers online, shows you research trends in your academic discipline, and connects you to like-minded researchers.\n\n**2. What is the connection to Last.fm?**\\\nThere is a conceptual as well as a personal connection. Conceptually, in the long run Mendeley aims to do for research what Last.fm did for music. For those of your readers who don't know Last.fm, this is how it works: When you install Last.fm's desktop software on your computer, it will monitor which music you listen to and automatically build a profile of your musical taste on the Last.fm website. The website then recommends you music that you might like, shows you statistics about the most popular songs and artists in your favourite genre, and lets you discover people with a similar taste in music. By aggregating the listening habits and tags of its 20 million users, Last.fm has managed to create the largest ontological classification (and the largest open database) of music in the world -- it would be great if we could achieve the same for research papers.\n\nSo, if you install Mendeley Desktop on your computer, you can manage and share research papers on your machine, but you can also upload your papers to your private account on Mendeley Web to access them online. Mendeley Web anonymously aggregates the metadata of these papers to generate statistics about the most popular authors and papers in your research discipline, and -- in the future -- generates recommendations for papers which you might like. One thing that we handle very differently from Last.fm is privacy: The Last.fm website lets everyone know which music you listen to, whereas Mendeley Web keeps all your research data in your private account which can't be accessed by anyone else. The conceptual parallels between Last.fm and Mendeley are outlined in more detail in a talk I gave both at the EuroScience Open Forum 2008 in Barcelona and at the Southampton Open Science Workshop^[**7**](https://web.archive.org/web/20080920001317/http://network.nature.com/people/mfenner/blog/2008/09/05/interview-with-victor-henning-from-mendeley#fn7)^.\n\n<figure class=\"kg-card kg-image-card\">\n<img src=\"https://blog.front-matter.io/content/images/2022/08/2822784112_f01ed9673b_o.jpg\" class=\"kg-image\" loading=\"lazy\" srcset=\"https://blog.front-matter.io/content/images/size/w600/2022/08/2822784112_f01ed9673b_o.jpg 600w, https://blog.front-matter.io/content/images/2022/08/2822784112_f01ed9673b_o.jpg 640w\" width=\"640\" height=\"400\" />\n</figure>\n\nBesides the conceptual similarities, the personal connection to Last.fm is Dr. Stefan Gl\u00e4nzer. He was Last.fm's first investor and executive chairman, and now has the same role at Mendeley. My co-founder Jan and I first met him back in 2003, when he was a guest lecturer in Entrepreneurship at our university, the WHU Vallendar^[**8**](https://web.archive.org/web/20080920001317/http://network.nature.com/people/mfenner/blog/2008/09/05/interview-with-victor-henning-from-mendeley#fn8)^, and we contributed a case study to the book he published together with our professors. So when we were looking for funding, we approached him again in June 2007, he was fascinated by the idea of Mendeley and luckily decided to join us. He also brought us in touch with the former founding engineers of Skype, who became investors as well.\n\n**3. What are your responsibilities within Mendeley?**\\\nI do most of the conceptual work behind Mendeley and write the specifications for our developers: What is the vision of Mendeley Desktop and Mendeley Web in the long term, which features should we develop next to get there, how does each feature work in detail, right down to questions like \"where do we place this button and how do we label it?\". So you can blame me for all the usability problems you might encounter.\n\nI'm also responsible for staying in touch with the academic community and incorporating its wishes into the Mendeley development roadmap, which has the enjoyable side effect that I get to travel to all these wonderful academic conferences. Next week, I'll be at the Science in the 21st Century conference at the Perimeter Institute for Theoretical Physics, Waterloo/Ontario^[**9**](https://web.archive.org/web/20080920001317/http://network.nature.com/people/mfenner/blog/2008/09/05/interview-with-victor-henning-from-mendeley#fn9)^.\n\n**4. What did you do before starting to work for Mendeley?**\\\nUntil a little more than a year ago, I thought I'd pursue an academic career -- I'm currently finishing my Ph.D. on decision-making and choice at the Bauhaus-University of Weimar. I've been saying \"currently finishing\" for almost a year now, but I'm hopeful that I'll manage to submit my thesis by the end of this year :-) Prior to that, I've worked in film production and the music industry a lot, and I opened a caf\u00e9/bar^[**10**](https://web.archive.org/web/20080920001317/http://network.nature.com/people/mfenner/blog/2008/09/05/interview-with-victor-henning-from-mendeley#fn10)^ opposite the WHU in parallel to writing my master's thesis. I actually left Vallendar the day after the opening night to pursue my Ph.D. in Weimar, so I had all of the work and little of the fun of owning a caf\u00e9/bar!\n\n**5. What is your policy regarding users sharing their PDF files of publications with others?**\\\nI think it's important to point out that we're not a \"Napster for research papers\" -- i.e. no free-for-all peer-to-peer filesharing. Quite a lot of people are disappointed when I tell them that! Sharing is currently limited to \"Shared Document Groups\" of max. 10 people (e.g. a lab, or collaborators on a research paper), although you can create and join as many Shared Document Groups as you like. Also, as we state in our terms of use^[**11**](https://web.archive.org/web/20080920001317/http://network.nature.com/people/mfenner/blog/2008/09/05/interview-with-victor-henning-from-mendeley#fn11)^, you may only share PDFs with the permission of the copyright owner -- e.g. your own articles or working papers, articles from Open Access databases, articles under a Creative Commons/Scientific Commons license, or perhaps when you and the person you are sharing the PDF with both have licensed access to the database the PDF was taken from.\n\nWe also encourage users to post their own papers and working papers on their Mendeley profiles -- depending on whether they have permission to do so from their publishers. As you can imagine, we're big fans of Open Access!\n\n**6. How is Mendeley different from other desktop reference managers such as Endnote?**\\\nThere are a number of things that make Mendeley Desktop unique, but I'd probably highlight the collaboration aspect, the \"automatic metadata extraction\", the online back-up/multi-machine support, and the cross-platform support:\n\n-   As far as I know, Mendeley Desktop is the only desktop reference management software that lets you share and collaboratively annotate research papers. We're also working on a \"groups\" feature in Mendeley Web which labs can use for discussions, sharing files, setting up a lab blog/wiki etc. -- all of this will tie into the reference management seamlessly.\n-   The \"automatic metadata extraction\" is quite unique as well: When you drop your PDFs into Mendeley Desktop, it will automatically extract the full-text to make it searchable, try to guess the correct metadata from the full-text (author, title, journal, volume, issue etc.) so you don't have to type it in manually, and also parse each documents' cited references, so you can add them to your library as well.\n-   Due to the integration with Mendeley Web, you can back-up your entire library for online access through simple drag & drop in Mendeley Desktop. Also, this means that you can install Mendeley Desktop on multiple computers and easily synchronize your PDF library across them via the Mendeley Online Library.\n-   Last but not least, Mendeley Desktop is the only desktop reference manager that is available on all three major platforms (Windows, Mac, and Linux).\n\nNot to mention that, in comparison to solutions such as EndNote, RefMan, RefWorks etc., which cost hundreds of Euros per license, Mendeley Desktop is completely free.\n\n**7. How is Mendeley different from other social networking sites for scientists?**\\\nWhile social networking is an aspect of Mendeley Web, we don't see ourselves primarily as a social network. We don't believe that social networking in itself is the killer feature that researchers are looking for -- rather we're using a social network to enable researchers to share their data. I think that [**Neil Saunders**](https://web.archive.org/web/20080920001317/http://network.nature.com/profile/neilfws), who is also here on Nature Network, said it best: \"Really, it's our data that needs to be social, not ourselves\". So we've tried to develop a research tool which is useful without any network effects, and which uses networking as a means rather than an end.\n\nTo invoke the analogy to Last.fm again: Even though people have profiles on Last.fm and can connect to each other, Last.fm is not primarily a social network. Last.fm connects the music first, and networks of people form around the music as a second step.\n\n**8. Does Mendeley integrate with other social networking sites and services for scientists, e.g. Connotea or CiteULike? Does it integrate with desktop reference managers?**\\\nAt the moment we're focusing on increasing the speed and stability of Mendeley, as well as introducing more features which make Mendeley useful as a standalone software. However, compatibility with Connotea or CiteULike is something we'll be working on in the near future.\n\nRegarding integration with other desktop reference managers: At the Science Blogging Conference^[**11**](https://web.archive.org/web/20080920001317/http://network.nature.com/people/mfenner/blog/2008/09/05/interview-with-victor-henning-from-mendeley#fn11)^ I briefly spoke to [**Alexander Griekspoor**](https://web.archive.org/web/20080920001317/http://network.nature.com/profile/mekentosj), the developer of the Mac software Papers^[**12**](https://web.archive.org/web/20080920001317/http://network.nature.com/people/mfenner/blog/2008/09/05/interview-with-victor-henning-from-mendeley#fn12)^, whether we couldn't make our software compatible so that Papers users and Mendeley Desktop users could share and synchronize their collections online. As for EndNote: It's already possible to import/export data to/from Mendeley in the EndNote XML format -- but, sadly, I don't think that EndNote's developers would be inclined to enable online sharing between EndNote and Mendeley.\n\n**9. Do you want to talk about future plans for Mendeley?**\\\nSure! Besides speed and stability, which I already mentioned, we'll be working on two main issues to better integrate Mendeley into the research workflow. First, there will be a \"cite-while-you-write\" plugin for Microsoft Word (or Open Office, if our users would prefer that), so that you can generate reference lists from your Mendeley library automatically. Similarly, we'll improve the integration with LaTeX by automating the BibTeX file export from Mendeley Desktop. Second, we'll introduce a \"bookmarklet\" like the ones CiteULike or Connotea have, which lets you import metadata/papers from websites into your Mendeley Online Library with a single click. This metadata will then be automatically synchronized with the Mendeley Desktop library on your computer.\n\nThe Microsoft Word/LaTeX integration and the online bookmarklet will be available very soon. Over the coming months, we'll also introduce OCR to Mendeley Desktop, so that you can extract metadata, full-text and references from older scanned-image documents; we'll integrate Mendeley Desktop with external databases such as PubMed, Scopus, and Web of Science; we'll implement the groups/lab management feature on Mendeley Web that I already mentioned; there will be much more detailed research trend statistics on Mendeley Web; we'll introduce the recommendation engine for academic papers, and many more little goodies. For example, a frequent user request has been automatic PDF file renaming based on the metadata -- so that's going to be in one of the next versions.\n\n**10. If a user is interested to learn more about Mendeley or give feedback, who should he contact?**\\\nYou can always contact me directly at [**victor.henning@mendeley.com**](https://web.archive.org/web/20080920001317/mailto:victor.henning@mendeley.com). There is also a Mendeley team blog on which there is plenty of behind-the-scenes information^[**13**](https://web.archive.org/web/20080920001317/http://network.nature.com/people/mfenner/blog/2008/09/05/interview-with-victor-henning-from-mendeley#fn13)^. You can also submit feature requests or bug reports on our homepage (the buttons on the top left).\n\nVictor, thank you very much for giving me this interview.\n\n^1^ [**How to get scientists to adopt web 2.0 technologies**](https://web.archive.org/web/20080920001317/http://network.nature.com/blogs/user/U27CE62BB/2008/08/19/how-to-get-scientists-to-adopt-web-2-0-technologies)\n\n^2^ [**An open letter to the developers of social network and web 2.0 tools for scientists**](https://web.archive.org/web/20080920001317/http://blog.openwetware.org/scienceintheopen/2008/08/06/an-open-letter-to-the-developers-of-social-network-and-%E2%80%98web-20%E2%80%99-tools-for-scientists)\n\n^3^ [**A critical analysis Google Docs**](https://web.archive.org/web/20080920001317/http://docs.google.com/View?docid=dhs5x5kr_572hccgvcct)\n\n^4^ [**SciTechNet**](https://web.archive.org/web/20080920001317/http://scitechnet.blogspot.com/)\n\n^5^ [**Mendeley**](https://web.archive.org/web/20080920001317/http://www.mendeley.com/)\n\n^6^ [**Victor Henning's profile on Mendeley**](https://web.archive.org/web/20080920001317/http://www.mendeley.com/profiles/victor-henning)\n\n^7^ [**A Last.fm for Research**](https://web.archive.org/web/20080920001317/http://www.youtube.com/watch?v=UzJbrA9EY7A)\n\n^8^ [**WHU Otto Beisheim School of Management**](https://web.archive.org/web/20080920001317/http://www.whu.edu/cms/index.php?id=1959&amp;L=1&amp;1354)\n\n^9^ [**Science in the 21st Century**](https://web.archive.org/web/20080920001317/http://www.science21stcentury.org/)\n\n^10^ [**Korova Bar**](https://web.archive.org/web/20080920001317/http://www.korova-bar.de/korova/)\n\n^11^ [**Mendeley terms of use**](https://web.archive.org/web/20080920001317/http://www.mendeley.com/terms/)\n\n^12^ [**Science Blogging 2008: London**](https://web.archive.org/web/20080920001317/http://www.nature.com/natureconferences/sciblog2008/index.html)\n\n^13^ [**Papers**](https://web.archive.org/web/20080920001317/http://mekentosj.com/papers/)\n\n^14^ [**Mendeley blog**](https://web.archive.org/web/20080920001317/http://www.mendeley.com/blog)\n","doi":"https://doi.org/10.53731/eewgt6b-bh097qd","guid":"62d42bbd41e317003df48d90","id":"5451d9ba-aac1-432c-a6d4-c03bb8578bfb","image":"https://blog.front-matter.io/content/images/2022/08/2822759480_c330822084_o.jpg","indexed_at":1,"language":"en","published_at":1220595480,"reference":[],"relationships":[],"summary":"In the last few months we have seen an ever increasing number of new social networking (Web 2.0) sites for scientists. Good Web 2.0 tools for scientists primarily try to solve a problem. But by adding a social aspect, they will gain useful features that would otherwise not be possible.\n","tags":["Interview"],"title":"Mendeley: Interview with Victor Henning","updated_at":1660575153,"url":"https://blog.front-matter.io/posts/interview-with-victor-henning-from-mendeley"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/london-science-tour-in-pictures","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"Pictures missing\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cwb5","guid":"62d42bbd41e317003df48ec0","id":"1b0b5ca2-9ba2-470e-a42e-4f6242ab0530","image":"https://images.unsplash.com/photo-1572299240425-9ecc0a7cb826?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDQ0fHxsb25kb24lMjBhbmQlMjBzY2llbmNlfGVufDB8fHx8MTY2MDU3NDkyNg&ixlib=rb-1.2.1&q=80&w=2000","indexed_at":1,"language":"en","published_at":1219968000,"reference":[],"relationships":[],"summary":"Pictures missing\n","tags":["Meeting Report"],"title":"London Science Tour in Pictures","updated_at":1660574977,"url":"https://blog.front-matter.io/posts/london-science-tour-in-pictures"},{"abstract":null,"archive_url":"https://wayback.archive-it.org/22096/20231101172748/https://blog.front-matter.io/posts/science-blogging-in-german","authors":[{"name":"Martin Fenner","url":"https://orcid.org/0000-0003-1419-2405"}],"blog":{"api":true,"archive_prefix":"https://wayback.archive-it.org/22096/20231101172748/","authors":null,"backlog":0,"canonical_url":null,"category":"computerAndInformationSciences","created_at":1672561153,"current_feed_url":"https://blog.front-matter.io/atom/","description":"The Front Matter Blog covers the intersection of science and technology since 2007.","favicon":"https://blog.front-matter.io/favicon.png","feed_format":"application/atom+xml","feed_url":"https://blog.front-matter.io/atom","filter":null,"funding":null,"generator":"Ghost","generator_raw":"Ghost 5.52","home_page_url":"https://blog.front-matter.io","id":"74659bc5-e36e-4a27-901f-f0c8d5769cb8","indexed":null,"issn":"2749-9952","language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://mozilla.social/@martin","plan":"Team","prefix":"10.53731","relative_url":null,"ror":null,"secure":true,"slug":"front_matter","status":"active","title":"Front Matter","updated_at":1707741118,"use_api":true,"use_mastodon":true,"user_id":"8498eaf6-8c58-4b58-bc15-27eda292b1aa","version":"https://jsonfeed.org/version/1.1"},"blog_name":"Front Matter","blog_slug":"front_matter","content_text":"Most scientific papers are now published in English, and I believe that [this trend](https://web.archive.org/web/20120611040415/http://network.nature.com/blogs/user/mfenner/2008/01/16/should-all-papers-be-published-in-english) is good for international collaboration. Therefore I believe that blogs intended for scientists should also be written in English. The topics and discussions in German language science blogs are often similar to what we discuss in English, and it makes the audience much smaller if we restrict ourselves to a particular language (the same could be said about French, Italian, Spanish, Japanese or Chinese blog posts).\n\nBut there are good reasons to write German language science blogs, and the German science blogosphere is indeed very active. For those understanding German, I\\'ve listed some of the more popular blogs and blog hostings sites below:\n\n-   [ScienceBlogs.de](https://web.archive.org/web/20120611040415/http://www.scienceblogs.de/). 29 blogs from the German language sister of [ScienceBlogs](https://web.archive.org/web/20120611040415/http://www.scienceblogs.com/)\n-   [SciLogs](https://web.archive.org/web/20120611040415/http://www.scilogs.de/) A collection of science blogs, hosted by publisher [Spektrum der Wissenschaft](https://web.archive.org/web/20120611040415/http://www.spektrumverlag.de/)\n-   [academics.de](https://web.archive.org/web/20120611040415/http://www.academics.de/blog/). The blog by the academic job portal\n-   [scholarz.blog](https://web.archive.org/web/20120611040415/http://blog-de.scholarz.net/) by the social networking site scholarz.net\n-   [SciBlog](https://web.archive.org/web/20120611040415/http://www.sciblog.at/). An Austrian blog about science communication\n-   [Wissenswerkschaft](https://web.archive.org/web/20120611040415/http://www.wissenswerkstatt.net/) by Marc Scheloske\n-   [Begrenzte Wissenschaft](https://web.archive.org/web/20120611040415/http://kamenin.wordpress.com/) by Sven Ke\u00c3\u0178en\n-   [Fischblog](https://scilogs.spektrum.de/fischblog/) by Lars Fischer\n-   [medinfo](https://www.medinfo-agmb.de/) by [Oliver Obst](https://web.archive.org/web/20120611040415/http://network.nature.com/profile/obst)\n-   [infob ib](https://infobib.de/) by [Christian Hauschke](https://web.archive.org/web/20120611040415/http://network.nature.com/profile/U351AAAEA) and four other authors.\n","doi":"https://doi.org/10.53731/r294649-6f79289-8cwb3","guid":"62d42bbd41e317003df48ebe","id":"eee4d48f-6b92-4d61-b1f6-a56b48a3356f","image":null,"indexed_at":1,"language":"en","published_at":1218931200,"reference":[],"relationships":[],"summary":"Most scientific papers are now published in English, and I believe that this trend is good for international collaboration. Therefore I believe that blogs intended for scientists should also be written in English.\n","tags":["Feature"],"title":"Science Blogging in German","updated_at":1660574766,"url":"https://blog.front-matter.io/posts/science-blogging-in-german"}],"total-results":327}
